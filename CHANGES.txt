# DEADLINE!
5월 17일 까지 제작하여 accuaracy 뽑아내기
May. 5. 2022 (B. InSung)
- Linear 모델 까지 통과, 이제 정상 비트냐 이소성 비트냐만 결과 도출하면 끝

May. 19. 2022 (B. InSung)
- 아래 Todo 를 진행하였다. 문제는 확률에도 큰 변화가 없다는 것을 발견. 이를 올리기 위해서는 개인적인 생각으로는 전처리 과정이 굉장히 많이 요구 되는 것으로 보임. 이를 해결하기 위해서는 이전에 활용 했던 방법으로 해야할거 같은 느낌.
    - 개인적으로 열차내에서 진행해볼 예정.
- Late thursday.
    - 새로운 matlab 데이터 셋으로 구성된 내용을 읽어와 학습진행.
    - 현재 사이즈 매치가 되지 않아 오류 발생. 백업 커밋

May. 18. 2022 (B. InSung)
- SVM Train을 한번에 동시에 돌리자 Out of bounds 오류 발생. 이를 해결하기 위해 디버깅 진행 중.
    - 현재 작업 파일 명: cuda_model_csv_cheese.ipynb
- 말이 안됨; 100%가 나왔다.
- cuda_model_csv_cheese.ipyn에서 새로운 네트워크를 구성하는 중.
    - cuda_model_csv_cheese.ipynb 사망함.
- cuda_model_csv_cheese copy.ipynb 에서는 기존 네트워크에서 잘 나온 모델 저장.
# TODO
    // - SVM Input 이전 표준화.
    // - Normal을 제외, q 제외, 학습하기.
    - EPOCH = 200 으로 늘리기
    - Visible Layer 의 갯수 187
    - 180, 80, 200 BB-DBN Hidden Layer의 갯수
    - 100, 250, 120 GB-DBN Hidden Layer의 유닛 갯수.

May. 17. 2022 (B. InSung)
- Late Tuesday Session
- SVM Linear 학습 진행은 완료됨. 다만 문제는 accuaracy 확인 불가. 일단 테스트 까지 하고 결과를 볼 예정.

May. 15. 2022 (B. InSung)
- Sunday session is now on.
- 일단 학습 정확율이 90% 까지는 올라왔는데 이게 맞나? 아니 근데 갑자기 이렇게 된것도 이상하고 90.0, 80.0 이렇게 딱 떨이지는 것도 이상한거 같다.
- 본인 허리가 지금 너무 아픔. 일단 백업 커밋을 올린다만, 현재까지 진행 사항
    - gb dbn 에서 나온 값들을 정리하고 의미하는 바 작성하여 보고서 적기.
    - SVM 내에서 나온 값을 그래프와 시키고 시각화 진행 중에 train 함수와 plot 함수를 merge 진행

May. 14. 2022 (B. InSung)
- 아ㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏ 졸려요. 배고프고.
- 일단 모델은 돌아가는거 같은데 cuda 로 돌리고 있다. 유감스럽게도 cpu로 하면 한 비트당 50초 씩 걸린다...
아무튼 일단 전체 bbrbm, gbrbm 돌리고 결과값과 함께 커밋 예정. (1:17am)
- 정말 드는 의문점 하나. 아니 왜 쿠다로 돌리는데 cpu가 제일 바쁘고 gpu 리소스가 왜 0이지?
- loss가 50을 넘지를 못한다. bbrbm 이후 gbrbm에서의 변화를 기대...
- 아침이 밝았습니다... 아침입니다 열어분... 지금 일단 gbrbm 에서 넘어가는 과정 중에서 cuda 오류 발생. 이건 고치고 가야한다... 너무 많이 시간을 잡아먹는다...
================================================
- 자 현재까지의 진행 사항. 
    - 일단 지금까지 해왔던 Train이 맞는가? 일단 아닌듯. 형이랑 얘기를 해보니 전에 돌린거는 얘따로 쟤따로 놀고 있는데 기강이 풀린듯. 한번에 싹 집합 시켜서 학습시켜서 정신차리게 하는중.

May. 13. 2022 (B. InSung)
- First BBRBM은 작동 여부 확인. 이를 Second BBRBM까지 이어 갈수 있는지는 아직 확인중.
- Second BBRBM으로 변환 하는 과정 중에 확률 분포 에러 발생. 백업 커밋.
- 사이즈 오류로 인해 생기는 모델 input data 오류 제거.
    - Second BBRBM 레이어를 통과시키는 것을 이제 주 목적.
- BBRBM, GBRBM 설계 완료. 테스트 진행 예정. 커밋.

May. 12. 2022 (B. InSung)
- 내가 뭘 했는지는 몰라도 일단 뭐 되긴 된거 같다. 연산 중에 오류로 torch.mv 함수 내에서 벡터와 텐서 연산 오류 외에는 아직 큰 문제는 없음.
- torch.mv 함수 내에서 matmul 과정 중에서 오류 발생. 아마도 13000000 텐서와 10 벡터를 연산을 하는데 텐서를 10 * 1300000으로 맞춰 줘야하는거 같다.
    - .view(10, 1300000) 함수로 변환시 오류 없음. torch.mv 에서 적용 후 검토 예정
    RuntimeError: size mismatch, got 10, 10x1300000,10 
- 사이즈를 반대로 적용. 1300000 * 10 으로 적용하여 값 확인
    - 오류 해결됨. 커밋.
    ===============================================
- MSI 연구실 컴퓨터로 작업 시작.
    - 기존 데이터를 입력할때 맞지 않게 입력을 했음.
- 일단 first bbrbm은 확인. 전체 다 돌리고 결과를 볼 예정. 커밋.

May. 11. 2022 (B. InSung)
- 모델을 재구성하는중.
    - 기존에 모델의 가장 크나큰 문제는 일단 제대로 된 값이 하나도 없었던 거 같으며 라벨 처리를 따로 안함. 현재 문제도 거의 동일하여 라벨 처리를 제대로 못해주고 있긴하다만,
    지금은 조금 다른 문제에서 난관을 겪고 있음.
    - 데이터의 총 길이 값이 1,300,000 개로 이루워져 있어서 output 값을 지정할려면 1, 1300000으로 해줘야하나 메모리 할당에서 오류 발생
    - 멘탈이 나가뒤져가는데 일단 커밋은 해야할거 같다.
- Output size도 맞게 한거 같고 다 맞게 한거 같은데 이상하게 계속 안되고 있음. 원인을 알 수 없는 1로 인해 Output 사이즈가 자꾸 맞춰지지 않음.
    - 아ㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏ
h_bias를 제거함. 근데 다른 문제 생김.
->  0x167276600 <+928>: st1.4s { v0, v1 }, [x10], #32
    0x167276604 <+932>: add    x9, x22, #0x10
    0x167276608 <+936>: st1.4s { v2, v3 }, [x10]

    0x16727660c <+940>: add    x8, x8, #0x40
오버플로우남. 뒤질까
- 나는 멍청하다..
    - 진짜 멍청했다. 왜 backward를 하면 순서가 랜덤해질거라고 생각했지. 크기는 그ㅐㄹ..ㅇㅁ러민ㅇ러ㅏㅇ라어라ㅏㅓㅇ푸ㅠ유ㅜㅠㅜㅠㅜ유ㅜ류ㅜ유ㅜㅜㅠㅠㅜ 
 
may. 10. 2022 (b.insung)
- 아ㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏ
취중코디ㅣㅣㅣㅣㅣㅣㅣㅣㅣㅣㅣㅣㅇㅇㅇㅇㅇㅇㅇㅇ이ㅣ잉이이ㅣㅣ이이ㅣ이이이이ㅣㅣㅇㅇ
죄송합니다. 정말 진짜......하 이럴거면 술을 왜 마신거지
- 취중 코딩 중에 일단 한 짓 정리는 하자곱곱ㄱ
    - 일단 리스트 그대로 때려박았더니 리스트에서 overflow 발생. 
```
->  0x1798ca0dc <+424>: stp    q1, q0, [x9, #-0x20]
    0x1798ca0e0 <+428>: stp    q3, q2, [x9], #0x40
    0x1798ca0e4 <+432>: add    x22, x22, #0x8
    0x1798ca0e8 <+436>: cmp    x22, x26
Target 0: (python) stopped.
```

May. 9. 2022 (B. InSung)
- 나는 멍청하다... 어찌 라벨링 없이 구분을 할려고 했을까
- 하ㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏㅏ

May. 8. 2022 (B. InSung)
- Sunday Home session start.
- 이전에 짜둔 linear 코드는 SVM 을 거치지 않고 그냥 선형만 거치는 코드였다. 문제를 파악하고 새로운 SVM.py 코드 생성
    - RBM과 마찬가지로 메소드로 끌어와 작성할 예정

May. 6. 2022 (B. InSung)
- Friday Session start.

May. 4. 2022 (B. InSung)
- BBRBM 3개, GBRBM 3개 모두 쌓아서 Train Code 완성. AWS 내에서 테스트 할 예정
- 학습과정 중에 실수가 있었음. 실수로 인한 오류가 많아서 주피터 노트북으로 이전하여 부분적 디버깅으로 진행 예정.
- 현재 테스트 코드 작성 중. BBRBM 3개와 GBRBM을 어떻게 한번에 돌릴지를 궁리해야함. 이는 수업 끝나고 진행 예정.

May. 3. 2022. (B. InSung)
- Tuesday Session Start and want to sleep.
- 일단 새로운 모델로 서버에서 돌려 테스트 결과를 볼 예정.
- 논문에 따르면...
    - "Number of neurons for the first layer were varied within the set {180, 200, 250} and for the second layer, it varies in range {80, 100, 120}. All of them produce similar performance when the other hyper parameters are chosen accordingly."
    G., S., T., K.P. & V., K.K. Classification of ECG beats using deep belief network and active learning. Med Biol Eng Comput 56, 1887–1898 (2018). https://doi.org/10.1007/s11517-018-1815-2
        - 에서 레이어의 갯수를 정해주고 있다. 일단은 그에 맞게 출력을 해야하니 다시 해보자고...
- 일단 레이어 수는 맞췄음, 지금부터는 레이어수와 함께 그리고 loss 값을 토대로 입력을 해야함. 최종 결과 값은 AWS 내에서 돌려서 확인 후 출력 값으로 결정할 예정.
- BBRBM 레이어 성공. 추후 계획은 아래에
    - GBRBM을 설계하고 Testset으로 accuaracy 측정하여 결과값 보기.

May. 2. 2022. (B. InSung)
- Monday Session Start!
- Torch tensor size error. Target Size가 [1, 1] 이면 Tensor Size가 [1, 10] 으로 맞지가 않음.
    - Tensor size를 1, 1로는 줄일수가 없음. Input 이미 입력된 사이즈가 정해져 있기 때문에 따로 변경이 어려움. 그렇기에 이를 변형을 하던가 하나씩 넣어야하는데...
    문제는 그렇게 하면 선형 연산이 되질 않음. 사이즈 변형을 함부로 할 수 없는 상태. 3차원으로 가도 Size가 맞지 않음.
- StackOverflow를 통해 얻은 지식... https://stackoverflow.com/questions/72081872/runtimeerror-output-with-shape-1-doesnt-match-the-broadcast-shape-10/
    - Mandias 의 말에 따르면 F.linear() 에 들어가 있는 Parameters 중에 self.W (이.하. w) 의 크기가 [1, 10] 으로 되어 있기 때문에 Input 1을 넣어 Output 10을 요구하는 것이라고 한다. 
    Mandias는 이를 해결하기 위해서 self.W.squeeze를 말했다만, 이는 나의 코드에서도 동일한 오류가 발생한다. 분명 모든 사이즈와 차원이 1차원이라면... 오류가 날 이유가 없다...
    
- 만일 Input이 1이고 Ouput이 10이여서 문제라면 10, 10 으로 변경하면...?
    - 성공적으로 코드는 돌아감. 다른 오류가 생김. 역시나 이게 바로 인공지능인가 싶다. 허ㅏ어하ㅓ아ㅣ허민어히ㅏㅓ;ㅓㅇㅎ어ㅓㅏㅇ하ㅓㅏ
    - 몰라 일단 오늘 끝이야.

May. 1. 2022 (B. InSung)
- Sunday and May is start!
- Tensor dimension 및 여러문제를 맞춰주니 다른 문제가 발생함.
    - Sample_data 와 weight의 크기가 10, 1로 달라 선형 연산이 안됨. 이에 대한 해결책은 모색중이나 대부분 MNIST에서 오류가 발생
        - MNIST에서 이미지 데이터를 갖고올때 3차원이 아닌 4차원으로 변형이 되어버림. 즉, 그로 인해 잘못된 데이터를 갖고 옮.
- README 수정. RBM.py 변경 사항을 수정함.
- h_to_v 또차원.. 오류 발생
    - Non-singleton dimension 1 오류 발생. 서로 맞지 않은 사이즈의 오류 
    - RuntimeError: The expanded size of the tensor (1) must match the existing size (10) at non-singleton dimension 1.  Target sizes: [1, 1].  Tensor sizes: [1, 10]

Apr. 30. 2022 (B. InSung)
- Saturday Session Start!
- 아예 새롭게 RBM 모델을 세움. 
    - 어차피 BBRBM (RBM) -> GBRBM 으로 제작하면 되니 BBRBM이 성공하면 확률분포만 Gaussian으로 바꾸면 된다 라는게 나의 생각.

Apr. 29. 2022 (B. InSung)
- Friday Session Start.
- GBRBM 에서 BBRBM와 같은 오류가 발생함.
    - RuntimeError: The size of tensor a (180) must match the size of tensor b (80) at non-singleton dimension 1.
    - Dimension unmatching 오류 발생.
    - torch.flatten 을 통해 dimension을 0으로 통합하면 80 * 180 으로 된 텐서는 14400 * 1 텐서로 변형됨.
      텐서 사이즈가 맞지 않아 오류 발생.
- p_h_given_v matmul dimension 오류
    - 현저히 같은 이슈. weight와 visible layer 의 input에서 tensor size가 맞지 않아서 충돌이 발생함.
    - 180 * 80 mul 180 * 80
          ^---w        ^---v
    - torch.matmul을 통해서 사이즈를 맞춰줌. 허나, 이유는 모르겠으나 180 * 80와 80 * 180 사이즈 텐서를 넣었는데 (180 * 180) * (80 * 1) 텐서로 들어감.
    - 수학적인 연산에 대한 내용으로 추측됨. 혹여 모를 사태를 대비해 일단 또 커밋. 멘탈이 나가면 안되닌까..
    
Apr. 28. 2022 (B. InSung)
- Drunk night session...
- GBRBM 에서 오류 발생
    - RuntimeError: The size of tensor a (180) must match the size of tensor b (80) at non-singleton dimension 1
    - size의 unmatching 귀찮으니 내일의 나를 믿어야지.

Apr. 27. 2022 (B. InSung)
- Wensday Session Start... but feels like Tuesday...
- BBRBM sample_h_given_v 의 return 값 오류발생
    - RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x80 and 14400x14400)
- 개발자 본인 지금 몬스터 마시고 밤샘을 달리는중.
    - changes에 의미가 있을지 모르겠으니 일단 뭐라도 적는다. 지금 bbrbm에서 안되거든? 일단 어캐든 잘 고쳐보는데 v_data가 길이가 안 맞는거임. 그러니 그거 맞춰주셈.
    - 14400 * 14400 으로 되어있다. 코드도 여기 있음
```
def p_h_given_v(self, v):
        index_tensor = torch.Tensor.long(torch.ones(self.vis_num, 0))
        w_t = (self.w.t().clone()).scatter_(0, index_tensor, (self.w.t().clone())).unsqueeze(1)
        v = (v.clone()).view(1, self.vis_num)
        print("w_t size\t\t: ", w_t.size(), "\tw_t numel\t\t: ", torch.numel(w_t))
        print("v size\t\t: ", v.size(), "\tv numel\t\t: ", torch.numel(v))
        
        '''
        w_t dimension setting up results..
            0 : [1, 80, 180]
            1 : [80, 1, 180]
        '''
        
        return torch.sigmoid(
            torch.matmul(v, w_t) + self.b
        )
```
        - 3:25:10의 박인성

- okay. 3:39. Im still alive. log file becoming like survive diary...
    - dear diary, here is so cold and hungry....그만하고, 현재 문제는 epoch = 0, 즉, 1번째 트레인 과정에서는 수월하게 넘어감.
    - 두번째 (epoch = 1) 부터는 v data가 overload 발생. 에러 내용은 아래와 같음..
        - RuntimeError: shape '[80, 180]' is invalid for input of size 207360000

- Bernoulli-Bernoulli RBM First Train WAS TERRIBLY FAILED
- 기존 ISSUE (Loss 값이 확 떨어지는 현상) 의 문제를 해결하고자 scikit_learn을 활용함.
    - scikit learn으로 data split

Apr. 26. 2022 (B. InSung)
- Tuesday Session Start!
- Reconstruce 과정 중에 오류 발생
    - RuntimeError: The size of tensor a (14400) must match the size of tensor b (1152000) at non-singleton dimension 0
    - Dimension 이 맞지 않아 생기는 오류로 앞에서 연산된 testing_tensor의 크기가 3D로 되어 있어 이를 flatten으로 변환 중 오류 발생.
- 22:32:10 결과
```
mbda6'()::operator()() const::'lambda'(at::vec::(anonymous namespace)::Vectorized<float>)&&, long long)::'lambda'(char**, long long const*, long long) const&)::'lambda'(char**, long long const*, long long, long long)>:
->  0x177f425f0 <+912>: ld1.4s { v0, v1 }, [x9], #32
    0x177f425f4 <+916>: ld1.4s { v2, v3 }, [x9]
    0x177f425f8 <+920>: mov    x23, x11
    0x177f425fc <+924>: add    x12, x10, #0x40
Target 0: (python) stopped.
```
    - lldb를 통해 디버깅한 결과, 변수 값이 너무 커서 Memory를 다 할당시키지 못함. 코드 상의 알고리즘 오류 발생.

Apr. 25. 2022 (B. InSung)
- Monday Session Start!
- BBRBM.py : w_t + self.b 에서 dimension 불일치 오류 발생
- BBRBM p_v_given_h 함수 오류 발생
    - RuntimeError: mat1 and mat2 shapes cannot be multiplied (80x180 and 1x180)
    - w_t + self.b 의 크기를 변경 예정. 1x180 -> 180x1
- 기존 Tensor의 사이즈와 맞지 않음. 즉, Overflow와 같은 현상이 발생하게 되어서 이를 변경하는 쪽으로 가야함.
- 기존 코드는 Epoch 0 에만 적합. 0 이후의 숫자 (1, 2, 3 ...) 에는 아직 고려 되지 않음. 아래는 해당 에러 본문.
    - RuntimeError: shape '[14400]' is invalid for input of size 1152000

Apr. 24. 2022 (B. InSung)
- stats_pos, stats_neg 문제 해결
    - 각각의 matmul을 위한 사이즈와 src (scatter 사이즈로 맞춰줌.) 이로 인해 문제해결
- BBRBM p_h_given_v 함수 내에서 오류 발생
    - sigmoid 함수에 parameter로 넣으면서 맞지 않은 데이터 형식으로 오류남.
        - RuntimeError: shape '[14400]' is invalid for input of size 80
    - v_i = v.clone().view(180 * 80)를 하면 180의 input은 존재, 허나 14400개를 채울게 없음
    - 이로 인해 에러 발생. 고쳐야하는데... 멘탐 좀 나감.

Apr. 22. 2022 (B. InSung)
- Torch 에서 같은 문제로 충돌하게 됨. 모종의 이유로 Tensorflow로 다시 시작해봄...
    - 사실상 처음부터 다시한 느낌이다만, 그래도 Pre-processing을 객체로 끌어와서 다행
- Tensorflow 내에서 어떻게 입력을 해줘야할지에서 논의중
    - 강아지 궁뎅이 그리워요

Apr. 21. 2022 (B. InSung)
- Torch.scatter 함수를 통해서 2D Tensor를 1D Tensor로 변환
- 막상 생각해보닌까 진짜 문제는 따로 있었음.
    - 80과 180, 1D로 되어 있는걸 Matmul 이 가능한가? 안되지 않나?

Apr. 20. 2022 (B. InSung)
- Tada... I'm back.
- 기존 에러에서의 문제점 확인
    - BBRBM에서 sample_h_given_v 함수에서 (h_prob > r) 를 상수 형태로 리턴
        - torchdot 으로 환산되어 반환.
        - src means "TORCH.TENSOR.SCATTER"
        - const 형태에서 non-const 형태로 변경 성공 (실패)
            - torch.gt() 함수는 큰 의미는 없음. 3. 와 같이 뒤에 .은 소수점을 의미.
    - 이로 인해서 변형이 불가. h_prob 와 맞지 않는 형태
    - 허나 이 또한 아직까지 확실하지 않음. 지속적인 수정을 진행할 예정.
        - 참고하기 https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_

Apr. 13. 2022 (B. InSung)
- Matrix Multiple compute 오류 발생.
    - 가우시안 분포를 해야하는데 Bernoulli 분포를 활용해버림. 뒤질거 같아요. 살려줘

- 뭔가 될거 같은데 자꾸 뭐가 안돼요.
    - ㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅜㅠㅠㅜㅠㅜㅠㅜㅜㅠㅜ흐아ㅡㅔ어레ㅓ우ㅠㅠㅜㅜㅠㅜㅠ

Apr. 12. 2022 (B. InSung)
- 모델에 데이터 입력에서 아직 문제 발생
    - 하다하다 빡쳐서 그냥 PyTorch로 변경.
    - Matrix ISSUE!

Apr. 11. 2022 (B. InSung)
- 데이터 신호 처리 문제 발견. 수정 진행 중. [SOLVED]
- 모델에 신호 넣기
    - medain_filtering_class 에서 바로 list로 넘김
    - 기존 코드 일부 제거 (파일 정리)
- 신호 처리 후 tensorflow 내에서 모델 구성에서의 데이터 타입 문제 발생

Apr. 10. 2022 (B. InSung)
- 논문에서 말하는 모델 방식에 수정 필요.
    - 첫번째 Visible layer 에는 GB-RBM을 활용하고, 두번째 Hidden layer 에는 BB-RBM을 활용.
    - 시간상 모델 제작을 위해서 https://github.com/meownoid/tensorflow-rbm 에서 코드 활용.
- filtering code 수정 완료.
    - 35hz filter reference
        : https://www.delftstack.com/howto/python/low-pass-filter-python/
        : https://medium.com/analytics-vidhya/how-to-filter-noise-with-a-low-pass-filter-python-885223e5e9b7
- model train data 및 test data tuple 추출.
- model.py에서의 train, cross, test dataset 입력 오류
    - reference : https://www.tensorflow.org/tutorials/load_data/numpy

Apr. 08. 2022 (B. InSung)
- GB-DBN 설계 시도 (다시 해보겠습니다...)
    - GB-DBN 보다는 GB-RBM 설계를 먼저해보고 그 다음에 GDBN (GB-DBN) 을 설계 하는 방향으로 갈 예정

Apr. 07. 2022 (B. InSung)
- so_again_median_filter.py 코드로 신호 처리는 일부 마무리. 단, MLII 컬럼만 읽어올 수 있다는 문제 발생.
- 라이센스 및 README, LOG.txt 추가
- so_again_median_filter.py 에서 주 코드 내용을 class로 변경. 
