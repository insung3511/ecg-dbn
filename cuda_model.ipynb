{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions.distribution as D\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import data.read_samples as rs\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import datetime\n",
    "import ignite\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "\n",
    "print(datetime.datetime.now(), \"model.py code start\")\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "EPOCH = 20\n",
    "LEARNING_RATE = 0.2\n",
    "ANNEALING_RATE = 0.999\n",
    "VISIBLE_UNITS = [180, 200, 250]\n",
    "HIDDEN_UNITS = [80, 100, 120]\n",
    "K_FOLD = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "print(torch.cuda.get_device_name(device))\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM(nn.Module): \n",
    "    with torch.cuda.device(0):\n",
    "        def __init__(self, n_vis, n_hid, k, batch):\n",
    "            super(RBM, self).__init__()\n",
    "            self.W      = nn.Parameter(torch.randn(1, batch, device=device) * 1e-2)\n",
    "            self.n_vis  = n_vis\n",
    "            self.n_hid  = n_hid\n",
    "            self.k      = k\n",
    "            self.batch  = batch\n",
    "            self.v_bias = nn.Parameter(torch.zeros(n_vis, device=device))\n",
    "            self.h_bias = nn.Parameter(torch.zeros(n_hid, device=device))\n",
    "        \n",
    "        def sample_from_p(self, p):\n",
    "            return F.relu(\n",
    "                torch.sign(\n",
    "                    p - Variable(torch.randn(p.size(), device=device))\n",
    "                )\n",
    "            ).to(device=device)\n",
    "\n",
    "        ''' ISSUE PART '''\n",
    "        def v_to_h(self, v):\n",
    "            w = (self.W.clone())\n",
    "\n",
    "            p_h = F.sigmoid(\n",
    "                # F.linear(v, w, self.h_bias)\n",
    "                F.linear(v, w)\n",
    "            ).to(device=device)\n",
    "\n",
    "            sample_h = self.sample_from_p(p_h)\n",
    "            return p_h, sample_h\n",
    "\n",
    "        def h_to_v(self, h):\n",
    "            w = self.W.t().clone()\n",
    "\n",
    "            p_v = F.sigmoid(\n",
    "                # F.linear(h, w, self.v_bias)\n",
    "                F.linear(h, w)\n",
    "            ).to(device=device)\n",
    "\n",
    "            sample_v = self.sample_from_p(p_v)\n",
    "            return p_v, sample_v\n",
    "        \n",
    "        def forward(self, v):\n",
    "            pre_h1, h1 = self.v_to_h(v)\n",
    "            h_ = h1\n",
    "\n",
    "            for _ in range(self.k):\n",
    "                pre_v_, v_ = self.h_to_v(h_)\n",
    "                pre_h_, h_ = self.v_to_h(v_)\n",
    "            return v, v_\n",
    "        \n",
    "        def get_weight(self):\n",
    "            return self.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM(nn.Module):\n",
    "    def __init__ (self, epoch, n_feat, n_out, batch=10, lr=0.999, c=0.01):\n",
    "        super(SVM, self).__init__()\n",
    "        self.epoch = epoch\n",
    "        self.n_feat = n_feat\n",
    "        self.n_out = n_out\n",
    "        self.batch = batch\n",
    "        self.lr = lr\n",
    "        self.c = c\n",
    "\n",
    "    def get_accuracy(self, model, data):\n",
    "            loader = torch.utils.data.DataLoader(data, batch_size=self.batch)\n",
    "            correct, total = 0, 0\n",
    "\n",
    "            for xs, ts in loader:\n",
    "                zs = model(xs)\n",
    "                pred = zs.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(ts.view_as(pred)).sum().item()\n",
    "                total += int(ts.shape[0])\n",
    "                return correct / total        \n",
    "    \n",
    "    def plot(self, xl, yl, xls, yls, label, title=\"Linear SVM Model Result\"):\n",
    "        plt.title(title)\n",
    "        plt.plot(xl, yl, label)\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(\"Training Curve (batch_size={}, lr={})\".format(self.batch, self.lr))\n",
    "        plt.plot(xls, yls, label=\"Train\")\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "\n",
    "    def train(self, x):\n",
    "        iters, loss_ = [], []\n",
    "        iters_sub, train_acc = [], []\n",
    "        \n",
    "        model = nn.Linear(self.n_feat, self.n_out)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adagrad(model.parameters(), lr=self.lr, weight_decay=self.c)\n",
    "        \n",
    "        weight, bias = list(model.parameters())\n",
    "        y = torch.sigmoid(model(x))\n",
    "        print(\"weight shape: {}\\tbias shape: {}\".format(weight.shape, bias.shape))\n",
    "\n",
    "        svm_train_dataloader = DataLoader(x,\n",
    "                                          batch_size=self.batch,\n",
    "                                          shuffle=True)\n",
    "        \n",
    "        n = 0\n",
    "        for epoch in range(self.epoch):\n",
    "            for xs, ts in iter(svm_train_dataloader):\n",
    "                if len(ts) != self.batch:\n",
    "                    continue\n",
    "                zs = model(xs)\n",
    "\n",
    "                loss = criterion(zs, ts)\n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                iters.append(n)\n",
    "                loss_.append(float(loss) / self.batch)\n",
    "                train_acc.append(self.get_accuracy(model, x))\n",
    "                n += 1\n",
    "        \n",
    "        self.plot(iters, loss_, iters_sub, train_acc, label=\"Train\")\n",
    "        torch.save(model, \"svm_model.pth\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[MODL] Model main code is starting....\")\n",
    "\n",
    "print(\"[INFO] Read train data, cross-vaildation data and test data from median filtering code\")\n",
    "db1_sig, db1_label, db2_sig, db2_label, db3_sig, db3_label = rs.return_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_map = {\n",
    "#     0:  \"N\",\n",
    "#     1:  \"S\",\n",
    "#     2:  \"V\",\n",
    "#     4:  \"F\",\n",
    "#     5:  \"A\",\n",
    "#     6:  \"+\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MapDataset(torch.utils.data.Dataset):\n",
    "#     def __len__(self):\n",
    "#         return len(db1_sig + db2_sig)\n",
    "#     def __getitem__(self, idx):\n",
    "#         return {\n",
    "#             \"input\" : torch.tensor([db1_sig + db2_sig], dtype=torch.float32),\n",
    "#             \"label\" : torch.tensor(label_map[db1_label + db2_label], dtype=torch.float32)\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_data = MapDataset()\n",
    "\n",
    "# point_sampler = torch.utils.data.RandomSampler(map_data)\n",
    "# batch_sampler = torch.utils.data.BatchSampler(point_sampler, 3, False)\n",
    "\n",
    "# dataloader = torch.utils.data.DataLoader(map_data, batch_sampler=batch_sampler)\n",
    "# for data in dataloader:\n",
    "#     print(data['input'])\n",
    "#     print(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "cross_dataset = []\n",
    "test_dataset = []\n",
    "\n",
    "for i in range(len(db1_sig)):\n",
    "    train_dataset.append([db1_sig[i], db1_label[i]])\n",
    "\n",
    "for i in range(len(db2_sig)):\n",
    "    cross_dataset.append([db2_sig[i], db2_label[i]])\n",
    "\n",
    "for i in range(len(db3_sig)):\n",
    "    test_dataset.append([db3_sig[i], db3_label[i]])\n",
    "\n",
    "train_dataloader = DataLoader(db1_sig,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              num_workers=0, \n",
    "                              collate_fn=lambda x: x,\n",
    "                              shuffle=True)\n",
    "\n",
    "cross_dataloader = DataLoader(db2_sig,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              num_workers=0,\n",
    "                              collate_fn=lambda x: x,\n",
    "                              shuffle=True)  \n",
    "                            \n",
    "test_dataloader = DataLoader(db3_sig,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             num_workers=0, \n",
    "                             collate_fn=lambda x: x,\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm_first = RBM(n_vis=VISIBLE_UNITS[0], n_hid=HIDDEN_UNITS[0], k=K_FOLD, batch=BATCH_SIZE).to(device=device)\n",
    "rbm_second = RBM(n_vis=VISIBLE_UNITS[1], n_hid=HIDDEN_UNITS[1], k=K_FOLD, batch=BATCH_SIZE).to(device=device)\n",
    "rbm_third = RBM(n_vis=VISIBLE_UNITS[2], n_hid=HIDDEN_UNITS[2], k=K_FOLD, batch=BATCH_SIZE).to(device=device)\n",
    "\n",
    "first_train_op = optim.Adagrad(rbm_first.parameters(), LEARNING_RATE)\n",
    "second_train_op = optim.Adagrad(rbm_second.parameters(), LEARNING_RATE)\n",
    "third_train_op = optim.Adagrad(rbm_third.parameters(), LEARNING_RATE)\n",
    "\n",
    "gb_first_train_op = optim.Adagrad(rbm_first.parameters(), LEARNING_RATE)\n",
    "gb_second_train_op = optim.Adagrad(rbm_second.parameters(), LEARNING_RATE)\n",
    "gb_third_train_op = optim.Adagrad(rbm_third.parameters(), LEARNING_RATE)\n",
    "\n",
    "output_from_first = list()\n",
    "output_from_second = list()\n",
    "output_from_third = list()\n",
    "\n",
    "omse_loss = list()\n",
    "mse_loss = nn.MSELoss()\n",
    "best_acc = float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Train Part'''\n",
    "\n",
    "loss_ = []\n",
    "for epoch in range(EPOCH):\n",
    "    run_acc = float()\n",
    "    start = time.time()\n",
    "    '''First bbrbm'''\n",
    "    for i, (data) in enumerate(train_dataloader):\n",
    "        data = Variable(\n",
    "                torch.tensor(data, dtype=torch.float32)\n",
    "        ).uniform_(0, 1)\n",
    "        \n",
    "        sample_data = torch.bernoulli(data).view(-1, 10).to(device=device)\n",
    "\n",
    "        # tensor binary\n",
    "        vog_first, v1 = rbm_first(sample_data)\n",
    "        omse_loss = mse_loss(vog_first, v1)\n",
    "\n",
    "        first_train_op.zero_grad()\n",
    "        first_train_op.step()\n",
    "        omse_loss.backward()\n",
    "        run_acc += (torch.bernoulli(data).view(-1, 10).to(device=device) == v1).sum().item()\n",
    " \n",
    "    acc = (run_acc / v1.size()[0])\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "\n",
    "    path = \"./saveMode_BBRBM1.pth\"\n",
    "    torch.save(rbm_first.state_dict(), path)\n",
    "\n",
    "    output_from_first.append(v1.tolist())\n",
    "    print(\"1ST BBrbm_first Training loss for {0} epoch {1}\\tEstimate time : {2}\\tAcc : {3}\\tBest Acc : {4}\" \\\n",
    "        .format(epoch + 1, \n",
    "                omse_loss, \n",
    "                time.time() - start,\n",
    "                acc, \n",
    "                best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_from_first = torch.tensor(output_from_first)\n",
    "print(output_from_first.size())\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    '''Secnd bbrbm'''\n",
    "    start = time.time()\n",
    "    run_acc = float()\n",
    "    for _, (data) in enumerate(output_from_first): \n",
    "        data = Variable(\n",
    "                torch.tensor(data, dtype=torch.float32)\n",
    "        ).uniform_(0, 1)\n",
    "\n",
    "        sample_data = torch.bernoulli(data).view(-1, 10).to(device=device)\n",
    "\n",
    "        # tensor binary\n",
    "        vog_second, v2 = rbm_second(sample_data)\n",
    "        omse_loss = mse_loss(vog_second, v2)\n",
    "\n",
    "        second_train_op.zero_grad()\n",
    "        omse_loss.backward()\n",
    "        second_train_op.step()\n",
    "        run_acc += (torch.bernoulli(data).view(-1, 10).to(device=device) == v2).sum().item()\n",
    "\n",
    "    acc = (run_acc / v2.size()[0]) * 100 / 500\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "\n",
    "    path = \"./saveMode_BBRBM_2.pth\"\n",
    "    torch.save(rbm_second.state_dict(), path)\n",
    "\n",
    "    output_from_second.append(v2.tolist())\n",
    "    print(\"2ST BBrbm_first Training loss for {0} epoch {1}\\tEstimate time : {2}\\tAcc : {3}\\tBest Acc : {4}\" \\\n",
    "        .format(epoch + 1, \n",
    "                omse_loss, \n",
    "                time.time() - start,\n",
    "                acc, \n",
    "                best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_from_second = torch.tensor(output_from_second)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    '''Third bbrbm'''\n",
    "    run_acc = float()\n",
    "\n",
    "    for _, (data) in enumerate(output_from_second):\n",
    "        start = time.time()\n",
    "        data = Variable(\n",
    "                torch.tensor(data, dtype=torch.float32)\n",
    "        ).uniform_(0, 1)\n",
    "\n",
    "        sample_data = torch.bernoulli(data).view(-1, 10).to(device=device)\n",
    "\n",
    "        vog_third, v3 = rbm_third(sample_data)\n",
    "        omse_loss = mse_loss(vog_third, v3)\n",
    "        \n",
    "        third_train_op.zero_grad()\n",
    "        omse_loss.backward()\n",
    "        third_train_op.step()\n",
    "        run_acc += (torch.bernoulli(data).view(-1, 10).to(device=device) == v3).sum().item()\n",
    "\n",
    "    acc = (run_acc / v3.size()[0]) * 100 / 500\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "\n",
    "    path = \"./saveMode_BBRBM_3.pth\"\n",
    "    torch.save(rbm_third.state_dict(), path)\n",
    "\n",
    "    output_from_third.append(v3.tolist())\n",
    "    print(\"3ST BBrbm_first Training loss for {0} epoch {1}\\tEstimate time : {2}\\tAcc : {3}\\tBest Acc : {4}\" \\\n",
    "        .format(epoch + 1, \n",
    "                omse_loss, \n",
    "                time.time() - start,\n",
    "                acc, \n",
    "                best_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbm_first = RBM(n_vis=VISIBLE_UNITS[0], n_hid=HIDDEN_UNITS[0], k=K_FOLD, batch=BATCH_SIZE).to(device=device)\n",
    "# rbm_second = RBM(n_vis=VISIBLE_UNITS[1], n_hid=HIDDEN_UNITS[1], k=K_FOLD, batch=BATCH_SIZE).to(device=device)\n",
    "# rbm_third = RBM(n_vis=VISIBLE_UNITS[2], n_hid=HIDDEN_UNITS[2], k=K_FOLD, batch=BATCH_SIZE).to(device=device)\n",
    "\n",
    "output_from_first = list()\n",
    "output_from_second = list()\n",
    "\n",
    "omse_loss = list()\n",
    "mse_loss = nn.MSELoss()\n",
    "gaussian_std = torch.arange(1, 0, -0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ** ISSUE PART ** '''\n",
    "\n",
    "loss_ = []\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    '''First gbrbm'''\n",
    "    run_acc = float()\n",
    "\n",
    "    for i, (data) in enumerate(output_from_third):\n",
    "        data = Variable(\n",
    "                torch.tensor(data, dtype=torch.float32)\n",
    "        ).uniform_(0, 1)\n",
    "        \n",
    "        sample_data = torch.normal(mean=data, std=gaussian_std).view(-1, 10).to(device=device)\n",
    "\n",
    "        # tensor binary\n",
    "        vog_first, v1 = rbm_first(sample_data)\n",
    "        omse_loss = mse_loss(vog_first, v1)\n",
    "\n",
    "        first_train_op.zero_grad()\n",
    "        first_train_op.step()\n",
    "        omse_loss.backward()\n",
    "        run_acc += (torch.bernoulli(data).view(-1, 10).to(device=device) == v1).sum().item()\n",
    "\n",
    "    acc = (run_acc / v1.size()[0]) * 100 / 500\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        \n",
    "    path = \"./saveMode_GBRBM_1.pth\"\n",
    "    torch.save(rbm_third.state_dict(), path)\n",
    "\n",
    "    output_from_first.append(v1.tolist())\n",
    "    print(\"1ST GBrbm_first Training loss for {0} epoch {1}\\tEstimate time : {2}\\tAcc : {3}\\tBest Acc : {4}\" \\\n",
    "        .format(epoch + 1, \n",
    "                omse_loss, \n",
    "                time.time() - start,\n",
    "                acc, \n",
    "                best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_from_first = torch.tensor(output_from_first)\n",
    "output_from_third = list()\n",
    "print(output_from_first.size())\n",
    "\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    '''Secnd gbrbm'''\n",
    "    run_acc = float()\n",
    "    start = time.time()\n",
    "    for _, (data) in enumerate(output_from_first): \n",
    "        data = Variable(\n",
    "                torch.tensor(data, dtype=torch.float32)\n",
    "        ).uniform_(0, 1)\n",
    "\n",
    "        sample_data = torch.normal(mean=data, std=gaussian_std).view(-1, 10).to(device=device)\n",
    "\n",
    "        # tensor binary\n",
    "        vog_second, v2 = rbm_second(sample_data)\n",
    "        omse_loss = mse_loss(vog_second, v2)\n",
    "\n",
    "        second_train_op.zero_grad()\n",
    "        omse_loss.backward()\n",
    "        second_train_op.step()\n",
    "        run_acc += (torch.bernoulli(data).view(-1, 10).to(device=device) == v2).sum().item()\n",
    "\n",
    "    acc = (run_acc / v2.size()[0]) * 100 / 500\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "    \n",
    "    path = \"./saveMode_GBRBM_2.pth\"\n",
    "    torch.save(rbm_third.state_dict(), path)\n",
    "\n",
    "    output_from_second.append(v2.tolist())\n",
    "    print(\"2ST GBrbm_first Training loss for {0} epoch {1}\\tEstimate time : {2}\\tAcc : {3}\\tBest Acc : {4}\" \\\n",
    "        .format(epoch + 1, \n",
    "                omse_loss, \n",
    "                time.time() - start,\n",
    "                acc, \n",
    "                best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_from_second = torch.tensor(output_from_second)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    '''Third gbrbm'''\n",
    "    run_acc = float()\n",
    "    for _, (data) in enumerate(output_from_second):\n",
    "        start = time.time()\n",
    "        data = Variable(\n",
    "                torch.tensor(data, dtype=torch.float32)\n",
    "        ).uniform_(0, 1)\n",
    "\n",
    "        sample_data = torch.bernoulli(data).view(-1, 10).to(device=device)\n",
    "\n",
    "        vog_third, v3 = rbm_third(sample_data)\n",
    "        omse_loss = mse_loss(vog_third, v3)\n",
    "        \n",
    "        third_train_op.zero_grad()\n",
    "        omse_loss.backward()\n",
    "        third_train_op.step()\n",
    "        run_acc += (torch.bernoulli(data).view(-1, 10).to(device=device) == v3).sum().item()\n",
    "\n",
    "    acc = (run_acc / v3.size()[0]) * 100 / 500\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        \n",
    "    path = \"./saveMode_GBRBM_3.pth\"\n",
    "    torch.save(rbm_third.state_dict(), path)\n",
    "\n",
    "    output_from_third.append(v3.tolist())\n",
    "    print(\"3ST GBrbm_first Training loss for {0} epoch {1}\\tEstimate time : {2}\\tAcc : {3}\\tBest Acc : {4}\" \\\n",
    "        .format(epoch + 1, \n",
    "                omse_loss, \n",
    "                time.time() - start,\n",
    "                acc, \n",
    "                best_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_from_third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Last Accuracy : \", acc, \"%\")\n",
    "svm = SVM(EPOCH, len(output_from_third), 5, batch=BATCH_SIZE, lr=LEARNING_RATE)\n",
    "\n",
    "svm.train(\n",
    "    output_from_third[0][0][0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (data) in enumerate(test_dataloader):\n",
    "        data = Variable(\n",
    "                torch.tensor(data, dtype=torch.float32)\n",
    "        ).uniform_(0, 1)\n",
    "        \n",
    "        sample_data = torch.bernoulli(data).view(-1, 10).to(device=device)\n",
    "\n",
    "        # tensor binary\n",
    "        vog_first, v1 = rbm_first(sample_data)\n",
    "        omse_loss = mse_loss(vog_first, v1)\n",
    "\n",
    "        first_train_op.zero_grad()\n",
    "        first_train_op.step()\n",
    "        omse_loss.backward()\n",
    "        run_acc += (torch.bernoulli(data).view(-1, 10).to(device=device) == v1).sum().item()\n",
    " \n",
    "acc = (run_acc / v1.size()[0])\n",
    "if acc > best_acc:\n",
    "        best_acc = acc\n",
    "\n",
    "print(\"loss : {0}\\tEstimate time : {1}\\tAcc : {2}\\tBest Acc : {3}\" \\\n",
    "    .format(omse_loss, time.time() - start, acc, best_acc))\n",
    "\n",
    "'''GUIDE'''\n",
    "\n",
    "for i, (data) in enumerate(v1):\n",
    "        data = Variable(\n",
    "                torch.tensor(data, dtype=torch.float32)\n",
    "        ).uniform_(0, 1)\n",
    "        \n",
    "        sample_data = torch.bernoulli(data).view(-1, 10).to(device=device)\n",
    "\n",
    "        # tensor binary\n",
    "        vog_second, v2 = rbm_first(sample_data)\n",
    "        omse_loss = mse_loss(vog_second, v2)\n",
    "\n",
    "        second_train_op.zero_grad()\n",
    "        second_train_op.step()\n",
    "        omse_loss.backward()\n",
    "        run_acc += (torch.bernoulli(data).view(-1, 10).to(device=device) == v2).sum().item()\n",
    " \n",
    "acc = (run_acc / v2.size()[0])\n",
    "if acc > best_acc:\n",
    "        best_acc = acc\n",
    "\n",
    "print(\"loss : {0}\\tEstimate time : {1}\\tAcc : {2}\\tBest Acc : {3}\" \\\n",
    "    .format(omse_loss, time.time() - start, acc, best_acc))\n",
    "    \n",
    "'''GUIDE'''\n",
    "\n",
    "for i, (data) in enumerate(v2):\n",
    "        data = Variable(\n",
    "                torch.tensor(data, dtype=torch.float32)\n",
    "        ).uniform_(0, 1)\n",
    "        \n",
    "        sample_data = torch.bernoulli(data).view(-1, 10).to(device=device)\n",
    "\n",
    "        # tensor binary\n",
    "        vog_second, v3 = rbm_first(sample_data)\n",
    "        omse_loss = mse_loss(vog_second, v3)\n",
    "\n",
    "        second_train_op.zero_grad()\n",
    "        second_train_op.step()\n",
    "        omse_loss.backward()\n",
    "        run_acc += (torch.bernoulli(data).view(-1, 10).to(device=device) == v3).sum().item()\n",
    " \n",
    "acc = (run_acc / v3.size()[0])\n",
    "if acc > best_acc:\n",
    "        best_acc = acc\n",
    "\n",
    "print(\"loss : {0}\\tEstimate time : {1}\\tAcc : {2}\\tBest Acc : {3}\" \\\n",
    "    .format(omse_loss, time.time() - start, acc, best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, (data) in enumerate(v3): \n",
    "        data = Variable(\n",
    "                torch.tensor(data, dtype=torch.float32)\n",
    "        ).uniform_(0, 1)\n",
    "\n",
    "        sample_data = torch.normal(mean=data, std=gaussian_std).view(-1, 10).to(device=device)\n",
    "\n",
    "        # tensor binary\n",
    "        vog_second, v1 = rbm_first(sample_data)\n",
    "        omse_loss = mse_loss(vog_second, v1)\n",
    "\n",
    "        second_train_op.zero_grad()\n",
    "        omse_loss.backward()\n",
    "        second_train_op.step()\n",
    "        run_acc += (torch.bernoulli(data).view(-1, 10).to(device=device) == v1).sum().item()\n",
    "\n",
    "print(\"loss : {0}\\tEstimate time : {1}\\tAcc : {2}\\tBest Acc : {3}\" \\\n",
    "    .format(omse_loss, time.time() - start, acc, best_acc))\n",
    "\n",
    "for _, (data) in enumerate(v1): \n",
    "        data = Variable(\n",
    "                torch.tensor(data, dtype=torch.float32)\n",
    "        ).uniform_(0, 1)\n",
    "\n",
    "        sample_data = torch.normal(mean=data, std=gaussian_std).view(-1, 10).to(device=device)\n",
    "\n",
    "        # tensor binary\n",
    "        vog_second, v2 = rbm_second(sample_data)\n",
    "        omse_loss = mse_loss(vog_second, v2)\n",
    "\n",
    "        second_train_op.zero_grad()\n",
    "        omse_loss.backward()\n",
    "        second_train_op.step()\n",
    "        run_acc += (torch.bernoulli(data).view(-1, 10).to(device=device) == v2).sum().item()\n",
    "\n",
    "print(\"loss : {0}\\tEstimate time : {1}\\tAcc : {2}\\tBest Acc : {3}\" \\\n",
    "    .format(omse_loss, time.time() - start, acc, best_acc))\n",
    "\n",
    "'''GUIDE'''\n",
    "\n",
    "for _, (data) in enumerate(v2): \n",
    "        data = Variable(\n",
    "                torch.tensor(data, dtype=torch.float32)\n",
    "        ).uniform_(0, 1)\n",
    "\n",
    "        sample_data = torch.normal(mean=data, std=gaussian_std).view(-1, 10).to(device=device)\n",
    "\n",
    "        # tensor binary\n",
    "        vog_second, v3 = rbm_third(sample_data)\n",
    "        omse_loss = mse_loss(vog_second, v3)\n",
    "\n",
    "        second_train_op.zero_grad()\n",
    "        omse_loss.backward()\n",
    "        second_train_op.step()\n",
    "        run_acc += (torch.bernoulli(data).view(-1, 10).to(device=device) == v1).sum().item()\n",
    "\n",
    "print(\"loss : {0}\\tEstimate time : {1}\\tAcc : {2}\\tBest Acc : {3}\" \\\n",
    "    .format(omse_loss, time.time() - start, acc, best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_cp = torch.load(\"svm_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVM(epoch=EPOCH, n_feat=v3.size()[0], n_out=5, batch=BATCH_SIZE, lr=LEARNING_RATE)\n",
    "svm_optim = optim.Adagrad(svm_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "svm_model.load_state_dict(svm_model_cp['model_state_dict'])\n",
    "svm_optim.load_state_dict(svm_model_cp['optimizer_state_dict'])\n",
    "epoch = svm_model_cp['epoch']\n",
    "loss = svm_model_cp['loss']\n",
    "\n",
    "svm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c3cabcf2f29820bdd7faae982b59d335e0d215fb5382d93f3312fa3292e9b7f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
