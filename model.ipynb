{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-08 15:57:20.677823 model.py code start\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import torch.distributions.distribution as D\n",
    "import data.medain_filtering_class as mf\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from SVM import svm_model\n",
    "import torch.nn as nn\n",
    "from RBM import RBM\n",
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "\n",
    "print(datetime.datetime.now(), \"model.py code start\")\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "EPOCH = 90\n",
    "LEARNING_RATE = 0.2\n",
    "ANNEALING_RATE = 0.999\n",
    "VISIBLE_UNITS = [180, 200, 250]\n",
    "HIDDEN_UNITS = [80, 100, 120]\n",
    "K_FOLD = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODL] Model main code is starting....\n",
      "[INFO] Read train data, cross-vaildation data and test data from median filtering code\n",
      "[INFO] Read file and indexing start...\n",
      "[INFO]\tfinal_db1 direcotry found.\n",
      "......\t...................i\tCurrent_Index\tFrom_Index\n",
      "[IWIP]\tfinal_db1 reading... 0 0 200\n",
      "[IWIP]\tfinal_db1 reading... 1 200 400\n",
      "[IWIP]\tfinal_db1 reading... 2 400 600\n",
      "[IWIP]\tfinal_db1 reading... 3 600 800\n",
      "[IWIP]\tfinal_db1 reading... 4 800 1000\n",
      "[IWIP]\tfinal_db1 reading... 5 1000 1200\n",
      "[IWIP]\tfinal_db1 reading... 6 1200 1400\n",
      "[IWIP]\tfinal_db1 reading... 7 1400 1600\n",
      "[IWIP]\tfinal_db1 reading... 8 1600 1800\n",
      "[IWIP]\tfinal_db1 reading... 9 1800 2000\n",
      "[IWIP]\tfinal_db1 reading... 10 2000 2200\n",
      "[IWIP]\tfinal_db1 reading... 11 2200 2400\n",
      "[IWIP]\tfinal_db1 reading... 12 2400 2600\n",
      "[IWIP]\tfinal_db1 reading... 13 2600 2800\n",
      "[IWIP]\tfinal_db1 reading... 14 2800 3000\n",
      "[IWIP]\tfinal_db1 reading... 15 3000 3200\n",
      "[IWIP]\tfinal_db1 reading... 16 3200 3400\n",
      "[IWIP]\tfinal_db1 reading... 17 3400 3600\n",
      "[IWIP]\tfinal_db1 reading... 18 3600 3800\n",
      "[IWIP]\tfinal_db1 reading... 19 3800 4000\n",
      "[IWIP]\tfinal_db1 reading... 20 4000 4200\n",
      "[IWIP]\tfinal_db1 reading... 21 4200 4400\n",
      "[INFO]\tfinal_db2 direcotry found.\n",
      "....\t...................i Current_Index From_Index\n",
      "[IWIP]\tfinal_db2 reading... 0 4400 4600\n",
      "[IWIP]\tfinal_db2 reading... 1 4600 4800\n",
      "[IWIP]\tfinal_db2 reading... 2 4800 5000\n",
      "[IWIP]\tfinal_db2 reading... 3 5000 5200\n",
      "[IWIP]\tfinal_db2 reading... 4 5200 5400\n",
      "[IWIP]\tfinal_db2 reading... 5 5400 5600\n",
      "[IWIP]\tfinal_db2 reading... 6 5600 5800\n",
      "[IWIP]\tfinal_db2 reading... 7 5800 6000\n",
      "[IWIP]\tfinal_db2 reading... 8 6000 6200\n",
      "[IWIP]\tfinal_db2 reading... 9 6200 6400\n",
      "[IWIP]\tfinal_db2 reading... 10 6400 6600\n",
      "[ERRR]\t\t\t11th RECORD is not work. Maybe problem with columns stuff.\n",
      "[IWIP]\tfinal_db2 reading... 12 6600 6800\n",
      "[IWIP]\tfinal_db2 reading... 13 6800 7000\n",
      "[IWIP]\tfinal_db2 reading... 14 7000 7200\n",
      "[ERRR]\t\t\t15th RECORD is not work. Maybe problem with columns stuff.\n",
      "[IWIP]\tfinal_db2 reading... 16 7200 7400\n",
      "[IWIP]\tfinal_db2 reading... 17 7400 7600\n",
      "[IWIP]\tfinal_db2 reading... 18 7600 7800\n",
      "[IWIP]\tfinal_db2 reading... 19 7800 8000\n",
      "[IWIP]\tfinal_db2 reading... 20 8000 8200\n",
      "[IWIP]\tfinal_db2 reading... 21 8200 8400\n",
      "[IWIP]\tfinal_db2 reading... 22 8400 8600\n",
      "[IWIP]\tfinal_db2 reading... 23 8600 8800\n",
      "[IWIP]\tfinal_db2 reading... 24 8800 9000\n",
      "[IWIP]\tfinal_db2 reading... 25 9000 9200\n",
      "[INFO]\tfinal_db3 direcotry found.\n",
      "[INFO]\tfinal_db1 direcotry found.\n",
      "[INFO]\tfinal_db2 direcotry found.\n",
      "[INFO]\tfinal_db3 direcotry found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bahk_insung/miniforge3/lib/python3.9/site-packages/scipy/signal/_signaltools.py:1531: UserWarning: kernel_size exceeds volume extent: the volume will be zero-padded.\n",
      "  warnings.warn('kernel_size exceeds volume extent: the volume will be '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Pre-processing is done.\n",
      "[ERRR] Got a issue with create file\n"
     ]
    }
   ],
   "source": [
    "print(\"[MODL] Model main code is starting....\")\n",
    "\n",
    "print(\"[INFO] Read train data, cross-vaildation data and test data from median filtering code\")\n",
    "dataset_db1, dataset_db2, dataset_db3 = mf.ecg_filtering(True)\n",
    "\n",
    "train_dataset = list(mf.list_to_list(dataset_db1)) * 4\n",
    "cross_dataset = list(mf.list_to_list(dataset_db2)) * 4\n",
    "test_dataset = list(mf.list_to_list(dataset_db3))  * 4\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    (train_dataset + cross_dataset), \n",
    "    (test_dataset + cross_dataset),\n",
    "    test_size=0.33,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train length :  9648\n",
      "X_test  length :  4752\n",
      "y_train length :  9648\n",
      "y_test  length :  4752\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(X_train + y_train,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(X_test + y_test,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True)\n",
    "\n",
    "print(\"X_train length : \", len(X_train))\n",
    "print(\"X_test  length : \", len(X_test))\n",
    "print(\"y_train length : \", len(y_train))\n",
    "print(\"y_test  length : \", len(y_test))\n",
    "\n",
    "train_data = torch.FloatTensor(X_train)\n",
    "test_data = torch.FloatTensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model object added\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Model object added\")\n",
    "\n",
    "rbm_first = RBM(n_vis=VISIBLE_UNITS[0], n_hid=HIDDEN_UNITS[0], k=K_FOLD, batch=BATCH_SIZE)\n",
    "rbm_second = RBM(n_vis=VISIBLE_UNITS[1], n_hid=HIDDEN_UNITS[1], k=K_FOLD, batch=BATCH_SIZE)\n",
    "rbm_third = RBM(n_vis=VISIBLE_UNITS[2], n_hid=HIDDEN_UNITS[2], k=K_FOLD, batch=BATCH_SIZE)\n",
    "\n",
    "first_train_op = optim.SGD(rbm_first.parameters(), 0.1)\n",
    "second_train_op = optim.SGD(rbm_second.parameters(), 0.1)\n",
    "third_train_op = optim.SGD(rbm_third.parameters(), 0.1)\n",
    "\n",
    "gb_first_train_op = optim.SGD(rbm_first.parameters(), 0.1)\n",
    "gb_second_train_op = optim.SGD(rbm_second.parameters(), 0.1)\n",
    "gb_third_train_op = optim.SGD(rbm_third.parameters(), 0.1)\n",
    "\n",
    "output_from_first = list()\n",
    "output_from_second = list()\n",
    "output_from_third = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/q_cwh5hn0s1dxsrzq2d040p80000gn/T/ipykernel_11046/3670610706.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
      "/Users/bahk_insung/miniforge3/lib/python3.9/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ST BBrbm_first Training loss for 0 epoch -0.6710752248764038\tEstimate time : 0:00:00.000102\n",
      "1ST BBrbm_first Training loss for 1 epoch -0.3169975280761719\tEstimate time : 0:00:00.000104\n",
      "1ST BBrbm_first Training loss for 2 epoch -0.16297946870326996\tEstimate time : 0:00:00.000104\n",
      "1ST BBrbm_first Training loss for 3 epoch -0.18433928489685059\tEstimate time : 0:00:00.000104\n",
      "1ST BBrbm_first Training loss for 4 epoch -0.249897763133049\tEstimate time : 0:00:00.000104\n",
      "1ST BBrbm_first Training loss for 5 epoch -0.3265415132045746\tEstimate time : 0:00:00.000105\n",
      "1ST BBrbm_first Training loss for 6 epoch -0.3398083746433258\tEstimate time : 0:00:00.000104\n",
      "1ST BBrbm_first Training loss for 7 epoch -0.20567432045936584\tEstimate time : 0:00:00.000104\n",
      "1ST BBrbm_first Training loss for 8 epoch -0.24061204493045807\tEstimate time : 0:00:00.000111\n",
      "1ST BBrbm_first Training loss for 9 epoch -0.20325520634651184\tEstimate time : 0:00:00.000116\n",
      "1ST BBrbm_first Training loss for 10 epoch -0.14647111296653748\tEstimate time : 0:00:00.000200\n",
      "1ST BBrbm_first Training loss for 11 epoch -0.059802450239658356\tEstimate time : 0:00:00.000104\n",
      "1ST BBrbm_first Training loss for 12 epoch -0.04597388207912445\tEstimate time : 0:00:00.000105\n",
      "1ST BBrbm_first Training loss for 13 epoch -0.06523403525352478\tEstimate time : 0:00:00.000103\n",
      "1ST BBrbm_first Training loss for 14 epoch -0.04847034811973572\tEstimate time : 0:00:00.000117\n",
      "1ST BBrbm_first Training loss for 15 epoch -0.009021741338074207\tEstimate time : 0:00:00.000105\n",
      "1ST BBrbm_first Training loss for 16 epoch 0.014701875858008862\tEstimate time : 0:00:00.000104\n",
      "1ST BBrbm_first Training loss for 17 epoch -0.006927789188921452\tEstimate time : 0:00:00.000101\n",
      "1ST BBrbm_first Training loss for 18 epoch -0.0075738015584647655\tEstimate time : 0:00:00.000102\n",
      "1ST BBrbm_first Training loss for 19 epoch 0.008630342781543732\tEstimate time : 0:00:00.000101\n",
      "1ST BBrbm_first Training loss for 20 epoch 0.03360773250460625\tEstimate time : 0:00:00.000112\n",
      "1ST BBrbm_first Training loss for 21 epoch 0.027638671919703484\tEstimate time : 0:00:00.000103\n",
      "1ST BBrbm_first Training loss for 22 epoch 0.029033711180090904\tEstimate time : 0:00:00.000103\n",
      "1ST BBrbm_first Training loss for 23 epoch 0.034547802060842514\tEstimate time : 0:00:00.000103\n",
      "1ST BBrbm_first Training loss for 24 epoch 0.02670823596417904\tEstimate time : 0:00:00.000106\n",
      "1ST BBrbm_first Training loss for 25 epoch 0.029167376458644867\tEstimate time : 0:00:00.000103\n",
      "1ST BBrbm_first Training loss for 26 epoch 0.022288046777248383\tEstimate time : 0:00:00.000108\n",
      "1ST BBrbm_first Training loss for 27 epoch 0.013149496167898178\tEstimate time : 0:00:00.000101\n",
      "1ST BBrbm_first Training loss for 28 epoch 0.011059832759201527\tEstimate time : 0:00:00.000102\n",
      "1ST BBrbm_first Training loss for 29 epoch -0.0044164699502289295\tEstimate time : 0:00:00.000102\n",
      "1ST BBrbm_first Training loss for 30 epoch 0.0034119938500225544\tEstimate time : 0:00:00.000106\n",
      "1ST BBrbm_first Training loss for 31 epoch -0.03993257135152817\tEstimate time : 0:00:00.000103\n",
      "1ST BBrbm_first Training loss for 32 epoch -0.05527317896485329\tEstimate time : 0:00:00.000103\n",
      "1ST BBrbm_first Training loss for 33 epoch -0.07010210305452347\tEstimate time : 0:00:00.000107\n",
      "1ST BBrbm_first Training loss for 34 epoch -0.07656946033239365\tEstimate time : 0:00:00.000109\n",
      "1ST BBrbm_first Training loss for 35 epoch -0.049439962953329086\tEstimate time : 0:00:00.000105\n",
      "1ST BBrbm_first Training loss for 36 epoch -0.024595068767666817\tEstimate time : 0:00:00.000104\n",
      "1ST BBrbm_first Training loss for 37 epoch -0.01905176229774952\tEstimate time : 0:00:00.000102\n",
      "1ST BBrbm_first Training loss for 38 epoch -0.0058988723903894424\tEstimate time : 0:00:00.000105\n",
      "1ST BBrbm_first Training loss for 39 epoch 0.0070046670734882355\tEstimate time : 0:00:00.000109\n",
      "1ST BBrbm_first Training loss for 40 epoch 0.021886592730879784\tEstimate time : 0:00:00.000105\n",
      "1ST BBrbm_first Training loss for 41 epoch 0.030884740874171257\tEstimate time : 0:00:00.000102\n",
      "1ST BBrbm_first Training loss for 42 epoch 0.03484682738780975\tEstimate time : 0:00:00.000102\n",
      "1ST BBrbm_first Training loss for 43 epoch 0.0273304283618927\tEstimate time : 0:00:00.000104\n",
      "1ST BBrbm_first Training loss for 44 epoch 0.03301374241709709\tEstimate time : 0:00:00.000109\n",
      "1ST BBrbm_first Training loss for 45 epoch 0.021239036694169044\tEstimate time : 0:00:00.000105\n",
      "1ST BBrbm_first Training loss for 46 epoch 0.013135707937180996\tEstimate time : 0:00:00.000105\n",
      "1ST BBrbm_first Training loss for 47 epoch 0.0010986605193465948\tEstimate time : 0:00:00.000104\n",
      "1ST BBrbm_first Training loss for 48 epoch 0.0028497111052274704\tEstimate time : 0:00:00.000101\n",
      "1ST BBrbm_first Training loss for 49 epoch 0.007683811709284782\tEstimate time : 0:00:00.000103\n",
      "1ST BBrbm_first Training loss for 50 epoch 0.014581477269530296\tEstimate time : 0:00:00.000102\n",
      "1ST BBrbm_first Training loss for 51 epoch 0.023915927857160568\tEstimate time : 0:00:00.000103\n",
      "1ST BBrbm_first Training loss for 52 epoch 0.004724628757685423\tEstimate time : 0:00:00.000105\n",
      "1ST BBrbm_first Training loss for 53 epoch -0.014829972758889198\tEstimate time : 0:00:00.000602\n",
      "1ST BBrbm_first Training loss for 54 epoch -0.0035160714760422707\tEstimate time : 0:00:00.000102\n",
      "1ST BBrbm_first Training loss for 55 epoch -0.011313061229884624\tEstimate time : 0:00:00.000104\n",
      "1ST BBrbm_first Training loss for 56 epoch -0.0017900815000757575\tEstimate time : 0:00:00.000138\n",
      "1ST BBrbm_first Training loss for 57 epoch -0.014295917935669422\tEstimate time : 0:00:00.000109\n",
      "1ST BBrbm_first Training loss for 58 epoch 0.0014389390125870705\tEstimate time : 0:00:00.000160\n",
      "1ST BBrbm_first Training loss for 59 epoch 0.000494128733407706\tEstimate time : 0:00:00.000206\n",
      "1ST BBrbm_first Training loss for 60 epoch 0.0037141756620258093\tEstimate time : 0:00:00.000159\n",
      "1ST BBrbm_first Training loss for 61 epoch 0.017788633704185486\tEstimate time : 0:00:00.000178\n",
      "1ST BBrbm_first Training loss for 62 epoch 0.011659407056868076\tEstimate time : 0:00:00.000118\n",
      "1ST BBrbm_first Training loss for 63 epoch 0.021119380369782448\tEstimate time : 0:00:00.000104\n",
      "1ST BBrbm_first Training loss for 64 epoch 0.026103461161255836\tEstimate time : 0:00:00.000119\n",
      "1ST BBrbm_first Training loss for 65 epoch 0.027807794511318207\tEstimate time : 0:00:00.000120\n",
      "1ST BBrbm_first Training loss for 66 epoch 0.027297651395201683\tEstimate time : 0:00:00.000123\n",
      "1ST BBrbm_first Training loss for 67 epoch 0.035721130669116974\tEstimate time : 0:00:00.000118\n",
      "1ST BBrbm_first Training loss for 68 epoch 0.035086553543806076\tEstimate time : 0:00:00.000196\n",
      "1ST BBrbm_first Training loss for 69 epoch 0.03242647647857666\tEstimate time : 0:00:00.000103\n",
      "1ST BBrbm_first Training loss for 70 epoch 0.029663287103176117\tEstimate time : 0:00:00.000107\n",
      "1ST BBrbm_first Training loss for 71 epoch 0.01996985822916031\tEstimate time : 0:00:00.000125\n",
      "1ST BBrbm_first Training loss for 72 epoch 0.017169959843158722\tEstimate time : 0:00:00.000120\n",
      "1ST BBrbm_first Training loss for 73 epoch 0.013630430214107037\tEstimate time : 0:00:00.000139\n",
      "1ST BBrbm_first Training loss for 74 epoch 0.016252882778644562\tEstimate time : 0:00:00.000102\n",
      "1ST BBrbm_first Training loss for 75 epoch 0.020011931657791138\tEstimate time : 0:00:00.000107\n",
      "1ST BBrbm_first Training loss for 76 epoch 0.02340685948729515\tEstimate time : 0:00:00.000136\n",
      "1ST BBrbm_first Training loss for 77 epoch 0.01895747520029545\tEstimate time : 0:00:00.000105\n",
      "1ST BBrbm_first Training loss for 78 epoch 0.023873040452599525\tEstimate time : 0:00:00.000104\n",
      "1ST BBrbm_first Training loss for 79 epoch 0.020936734974384308\tEstimate time : 0:00:00.000105\n",
      "1ST BBrbm_first Training loss for 80 epoch 0.012948548421263695\tEstimate time : 0:00:00.000127\n",
      "1ST BBrbm_first Training loss for 81 epoch 0.011397351510822773\tEstimate time : 0:00:00.000120\n",
      "1ST BBrbm_first Training loss for 82 epoch 0.005391470622271299\tEstimate time : 0:00:00.000145\n",
      "1ST BBrbm_first Training loss for 83 epoch 0.006953768897801638\tEstimate time : 0:00:00.000118\n",
      "1ST BBrbm_first Training loss for 84 epoch 0.003296211827546358\tEstimate time : 0:00:00.000113\n",
      "1ST BBrbm_first Training loss for 85 epoch -0.00177474576048553\tEstimate time : 0:00:00.000132\n",
      "1ST BBrbm_first Training loss for 86 epoch 0.000925486208871007\tEstimate time : 0:00:00.000130\n",
      "1ST BBrbm_first Training loss for 87 epoch -0.017991002649068832\tEstimate time : 0:00:00.000106\n",
      "1ST BBrbm_first Training loss for 88 epoch -0.028068125247955322\tEstimate time : 0:00:00.000119\n",
      "1ST BBrbm_first Training loss for 89 epoch -0.0044532353058457375\tEstimate time : 0:00:00.000117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/q_cwh5hn0s1dxsrzq2d040p80000gn/T/ipykernel_11046/3670610706.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ST BBrbm_first Training loss for 0 epoch -0.004643627908080816\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 1 epoch -0.004665154032409191\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 2 epoch -0.0049389866180717945\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 3 epoch -0.004907800350338221\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 4 epoch -0.004961822181940079\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 5 epoch -0.005205153953284025\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 6 epoch -0.005098822992295027\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 7 epoch -0.005274809896945953\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 8 epoch -0.0055115255527198315\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 9 epoch -0.005961737595498562\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 10 epoch -0.0066719562746584415\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 11 epoch -0.007707900833338499\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 12 epoch -0.007630591746419668\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 13 epoch -0.007829474285244942\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 14 epoch -0.007365398574620485\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 15 epoch -0.007729458622634411\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 16 epoch -0.008063966408371925\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 17 epoch -0.00855977926403284\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 18 epoch -0.007647444494068623\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 19 epoch -0.007138173095881939\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 20 epoch -0.007017325144261122\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 21 epoch -0.006173450034111738\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 22 epoch -0.006111296359449625\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 23 epoch -0.005759391002357006\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 24 epoch -0.005357283167541027\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 25 epoch -0.005711089354008436\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 26 epoch -0.005726521834731102\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 27 epoch -0.006111544091254473\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 28 epoch -0.006559923756867647\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 29 epoch -0.006329192314296961\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 30 epoch -0.00696267606690526\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 31 epoch -0.007394049782305956\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 32 epoch -0.007315809838473797\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 33 epoch -0.007516199257224798\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 34 epoch -0.00813605822622776\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 35 epoch -0.007590120192617178\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 36 epoch -0.00868759211152792\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 37 epoch -0.008365722373127937\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 38 epoch -0.008363275788724422\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 39 epoch -0.007669161073863506\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 40 epoch -0.008205183781683445\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 41 epoch -0.007368295919150114\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 42 epoch -0.00776614248752594\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 43 epoch -0.00922127440571785\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 44 epoch -0.008013972081243992\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 45 epoch -0.006790668237954378\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 46 epoch -0.005946802441030741\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 47 epoch -0.005667311605066061\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 48 epoch -0.005985515657812357\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 49 epoch -0.005508276168256998\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 50 epoch -0.005612827371805906\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 51 epoch -0.006118624936789274\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 52 epoch -0.006405928172171116\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 53 epoch -0.006242749746888876\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 54 epoch -0.006972902920097113\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 55 epoch -0.008092343807220459\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 56 epoch -0.007104421034455299\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 57 epoch -0.006660061422735453\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 58 epoch -0.006514832377433777\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 59 epoch -0.00582565413787961\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 60 epoch -0.005088831298053265\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 61 epoch -0.004961499013006687\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 62 epoch -0.0053370026871562\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 63 epoch -0.005184968467801809\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 64 epoch -0.0051825386472046375\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 65 epoch -0.004612290300428867\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 66 epoch -0.004889748990535736\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 67 epoch -0.004541713744401932\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 68 epoch -0.004617347847670317\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 69 epoch -0.004918337799608707\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 70 epoch -0.004778145346790552\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 71 epoch -0.004928471054881811\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 72 epoch -0.005494783166795969\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 73 epoch -0.005725880619138479\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 74 epoch -0.006534778047353029\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 75 epoch -0.007372137159109116\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 76 epoch -0.007322378922253847\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 77 epoch -0.006975159514695406\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 78 epoch -0.007583669386804104\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 79 epoch -0.007364688906818628\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 80 epoch -0.007796367164701223\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 81 epoch -0.008099212311208248\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 82 epoch -0.007420805282890797\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 83 epoch -0.007033655419945717\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 84 epoch -0.007062278687953949\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 85 epoch -0.007574792485684156\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 86 epoch -0.007930992171168327\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 87 epoch -0.00790321733802557\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 88 epoch -0.008536187000572681\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 89 epoch -0.008289038203656673\tEstimate time : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/q_cwh5hn0s1dxsrzq2d040p80000gn/T/ipykernel_11046/3670610706.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3ST BBrbm_first Training loss for 0 epoch -0.008387825451791286\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 1 epoch -0.008607282303273678\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 2 epoch -0.008681281469762325\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 3 epoch -0.00884101539850235\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 4 epoch -0.00907979067414999\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 5 epoch -0.009088007733225822\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 6 epoch -0.008891750127077103\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 7 epoch -0.00905928760766983\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 8 epoch -0.008820286951959133\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 9 epoch -0.008937360718846321\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 10 epoch -0.009136672131717205\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 11 epoch -0.009329350665211678\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 12 epoch -0.009207572788000107\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 13 epoch -0.00920080952346325\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 14 epoch -0.009234883822500706\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 15 epoch -0.009451713413000107\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 16 epoch -0.009170637466013432\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 17 epoch -0.00959773175418377\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 18 epoch -0.01001110952347517\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 19 epoch -0.010372532531619072\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 20 epoch -0.00984842050820589\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 21 epoch -0.009565284475684166\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 22 epoch -0.009324530139565468\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 23 epoch -0.008694984950125217\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 24 epoch -0.008709189482033253\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 25 epoch -0.00880170427262783\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 26 epoch -0.009281487204134464\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 27 epoch -0.009501994587481022\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 28 epoch -0.009214583784341812\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 29 epoch -0.009385812096297741\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 30 epoch -0.009912324137985706\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 31 epoch -0.00952850840985775\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 32 epoch -0.009643360041081905\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 33 epoch -0.010497857816517353\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 34 epoch -0.010768843814730644\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 35 epoch -0.011072301305830479\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 36 epoch -0.012054518796503544\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 37 epoch -0.01181050855666399\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 38 epoch -0.011239323765039444\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 39 epoch -0.012291979044675827\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 40 epoch -0.013627101667225361\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 41 epoch -0.013966226018965244\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 42 epoch -0.013402536511421204\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 43 epoch -0.012324179522693157\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 44 epoch -0.01152004674077034\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 45 epoch -0.011099178344011307\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 46 epoch -0.009671156294643879\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 47 epoch -0.009570459835231304\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 48 epoch -0.009679955430328846\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 49 epoch -0.00959892850369215\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 50 epoch -0.00981355831027031\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 51 epoch -0.010126709006726742\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 52 epoch -0.011485127732157707\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 53 epoch -0.01148502342402935\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 54 epoch -0.011061985045671463\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 55 epoch -0.012075109407305717\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 56 epoch -0.012314979918301105\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 57 epoch -0.012472113594412804\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 58 epoch -0.011858053505420685\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 59 epoch -0.012055384926497936\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 60 epoch -0.012053383514285088\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 61 epoch -0.011371436528861523\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 62 epoch -0.01074199564754963\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 63 epoch -0.010840318165719509\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 64 epoch -0.010328228585422039\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 65 epoch -0.011210828088223934\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 66 epoch -0.009930960834026337\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 67 epoch -0.009999393485486507\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 68 epoch -0.009953436441719532\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 69 epoch -0.01046638935804367\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 70 epoch -0.01034290250390768\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 71 epoch -0.009901502169668674\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 72 epoch -0.009592032991349697\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 73 epoch -0.009404625743627548\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 74 epoch -0.009855014272034168\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 75 epoch -0.01010994054377079\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 76 epoch -0.009333043359220028\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 77 epoch -0.009734694845974445\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 78 epoch -0.00975471455603838\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 79 epoch -0.010123130865395069\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 80 epoch -0.010004609823226929\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 81 epoch -0.01031968742609024\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 82 epoch -0.011074298061430454\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 83 epoch -0.012664140202105045\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 84 epoch -0.013203802518546581\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 85 epoch -0.013805902563035488\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 86 epoch -0.014856991358101368\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 87 epoch -0.01339470874518156\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 88 epoch -0.013126012869179249\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 89 epoch -0.012760265730321407\tEstimate time : \n"
     ]
    }
   ],
   "source": [
    "'''Train Part'''\n",
    "\n",
    "loss_ = []\n",
    "for epoch in range(EPOCH):\n",
    "    '''First bbrbm'''\n",
    "    for _, (data) in enumerate(train_dataloader):\n",
    "        try:\n",
    "            # tnesor float\n",
    "            data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "\n",
    "        sample_data = torch.bernoulli(data)\n",
    "        sample_data = torch.flatten(sample_data.clone())\n",
    "\n",
    "        # tensor binary\n",
    "        vog_first, v1, mt = rbm_first(sample_data)\n",
    "        \n",
    "        loss_first = rbm_first.free_energy(vog_first) - rbm_first.free_energy(v1)\n",
    "        loss_.append(loss_first.data)\n",
    "        \n",
    "        first_train_op.zero_grad()\n",
    "        loss_first.backward()\n",
    "        first_train_op.step()\n",
    "    \n",
    "    output_from_first.append(v1.tolist())\n",
    "    print(\"1ST BBrbm_first Training loss for {0} epoch {1}\\tEstimate time : {2}\".format(epoch, np.mean(loss_), mt))\n",
    "\n",
    "output_from_first = torch.tensor(output_from_first)\n",
    "for epoch in range(EPOCH):\n",
    "    '''Secnd bbrbm'''\n",
    "    for _, (data) in enumerate(output_from_first):\n",
    "        try:\n",
    "            data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "\n",
    "        sample_data = torch.bernoulli(data)\n",
    "        sample_data = torch.flatten(sample_data.clone())\n",
    "\n",
    "        vog_second, v2, mt = rbm_second(sample_data)\n",
    "        \n",
    "        loss_second = rbm_second.free_energy(vog_second) - rbm_second.free_energy(v2)\n",
    "        loss_.append(loss_second.data)\n",
    "        \n",
    "        second_train_op.zero_grad()\n",
    "        loss_second.backward()\n",
    "        second_train_op.step()\n",
    "\n",
    "    output_from_second.append(v2.tolist())\n",
    "    print(\"2ST BBrbm_first Training loss for {0} epoch {1}\\tEstimate time : \".format(epoch, np.mean(loss_), mt))\n",
    "\n",
    "output_from_second = torch.tensor(output_from_second)\n",
    "for epoch in range(EPOCH):\n",
    "    '''Third bbrbm'''\n",
    "    for _, (data) in enumerate(output_from_second):\n",
    "        try:\n",
    "            data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "\n",
    "        sample_data = torch.bernoulli(data)\n",
    "        sample_data = torch.flatten(sample_data.clone())\n",
    "\n",
    "        vog_third, v3, mt = rbm_third(sample_data)\n",
    "        \n",
    "        loss_third = rbm_third.free_energy(vog_third) - rbm_third.free_energy(v3)\n",
    "        loss_.append(loss_third.data)\n",
    "        \n",
    "        third_train_op.zero_grad()\n",
    "        loss_third.backward()\n",
    "        third_train_op.step()\n",
    "\n",
    "    output_from_third.append(v3.tolist())\n",
    "    print(\"3ST BBrbm_first Training loss for {0} epoch {1}\\tEstimate time : \".format(epoch, np.mean(loss_), mt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBRBM is done.\n",
      "GBRBM is start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/q_cwh5hn0s1dxsrzq2d040p80000gn/T/ipykernel_11046/2809123372.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ST GBrbm_first Training loss for 0 epoch -0.012760011479258537\tEstimate time : 0:00:00.000345\n",
      "1ST GBrbm_first Training loss for 1 epoch -0.012763707898557186\tEstimate time : 0:00:00.000103\n",
      "1ST GBrbm_first Training loss for 2 epoch -0.012763953767716885\tEstimate time : 0:00:00.000172\n",
      "1ST GBrbm_first Training loss for 3 epoch -0.012764666229486465\tEstimate time : 0:00:00.000108\n",
      "1ST GBrbm_first Training loss for 4 epoch -0.012765338644385338\tEstimate time : 0:00:00.000150\n",
      "1ST GBrbm_first Training loss for 5 epoch -0.012766029685735703\tEstimate time : 0:00:00.000118\n",
      "1ST GBrbm_first Training loss for 6 epoch -0.012765605933964252\tEstimate time : 0:00:00.000121\n",
      "1ST GBrbm_first Training loss for 7 epoch -0.012764429673552513\tEstimate time : 0:00:00.000117\n",
      "1ST GBrbm_first Training loss for 8 epoch -0.01276499405503273\tEstimate time : 0:00:00.000128\n",
      "1ST GBrbm_first Training loss for 9 epoch -0.012765317223966122\tEstimate time : 0:00:00.000117\n",
      "1ST GBrbm_first Training loss for 10 epoch -0.012765545397996902\tEstimate time : 0:00:00.000309\n",
      "1ST GBrbm_first Training loss for 11 epoch -0.012763946317136288\tEstimate time : 0:00:00.000115\n",
      "1ST GBrbm_first Training loss for 12 epoch -0.012762974947690964\tEstimate time : 0:00:00.000136\n",
      "1ST GBrbm_first Training loss for 13 epoch -0.012762412428855896\tEstimate time : 0:00:00.000358\n",
      "1ST GBrbm_first Training loss for 14 epoch -0.012762896716594696\tEstimate time : 0:00:00.000117\n",
      "1ST GBrbm_first Training loss for 15 epoch -0.012762376107275486\tEstimate time : 0:00:00.000137\n",
      "1ST GBrbm_first Training loss for 16 epoch -0.012762223370373249\tEstimate time : 0:00:00.000119\n",
      "1ST GBrbm_first Training loss for 17 epoch -0.012763806618750095\tEstimate time : 0:00:00.000133\n",
      "1ST GBrbm_first Training loss for 18 epoch -0.012764261104166508\tEstimate time : 0:00:00.000160\n",
      "1ST GBrbm_first Training loss for 19 epoch -0.012765612453222275\tEstimate time : 0:00:00.000116\n",
      "1ST GBrbm_first Training loss for 20 epoch -0.012766617350280285\tEstimate time : 0:00:00.000117\n",
      "1ST GBrbm_first Training loss for 21 epoch -0.01276714913547039\tEstimate time : 0:00:00.000118\n",
      "1ST GBrbm_first Training loss for 22 epoch -0.012769091874361038\tEstimate time : 0:00:00.000162\n",
      "1ST GBrbm_first Training loss for 23 epoch -0.012768777087330818\tEstimate time : 0:00:00.000120\n",
      "1ST GBrbm_first Training loss for 24 epoch -0.012768884189426899\tEstimate time : 0:00:00.000118\n",
      "1ST GBrbm_first Training loss for 25 epoch -0.01276903785765171\tEstimate time : 0:00:00.000118\n",
      "1ST GBrbm_first Training loss for 26 epoch -0.012770619243383408\tEstimate time : 0:00:00.000254\n",
      "1ST GBrbm_first Training loss for 27 epoch -0.01277070865035057\tEstimate time : 0:00:00.000120\n",
      "1ST GBrbm_first Training loss for 28 epoch -0.01277201808989048\tEstimate time : 0:00:00.000119\n",
      "1ST GBrbm_first Training loss for 29 epoch -0.012771996669471264\tEstimate time : 0:00:00.000119\n",
      "1ST GBrbm_first Training loss for 30 epoch -0.012771211564540863\tEstimate time : 0:00:00.000124\n",
      "1ST GBrbm_first Training loss for 31 epoch -0.012772019021213055\tEstimate time : 0:00:00.000126\n",
      "1ST GBrbm_first Training loss for 32 epoch -0.0127736646682024\tEstimate time : 0:00:00.000160\n",
      "1ST GBrbm_first Training loss for 33 epoch -0.012774256989359856\tEstimate time : 0:00:00.000120\n",
      "1ST GBrbm_first Training loss for 34 epoch -0.012773529626429081\tEstimate time : 0:00:00.000138\n",
      "1ST GBrbm_first Training loss for 35 epoch -0.012774338014423847\tEstimate time : 0:00:00.000120\n",
      "1ST GBrbm_first Training loss for 36 epoch -0.01277509331703186\tEstimate time : 0:00:00.000122\n",
      "1ST GBrbm_first Training loss for 37 epoch -0.012774648144841194\tEstimate time : 0:00:00.000121\n",
      "1ST GBrbm_first Training loss for 38 epoch -0.012774095870554447\tEstimate time : 0:00:00.000138\n",
      "1ST GBrbm_first Training loss for 39 epoch -0.012774479575455189\tEstimate time : 0:00:00.000118\n",
      "1ST GBrbm_first Training loss for 40 epoch -0.012774650007486343\tEstimate time : 0:00:00.000119\n",
      "1ST GBrbm_first Training loss for 41 epoch -0.012773903086781502\tEstimate time : 0:00:00.000117\n",
      "1ST GBrbm_first Training loss for 42 epoch -0.012775150127708912\tEstimate time : 0:00:00.000137\n",
      "1ST GBrbm_first Training loss for 43 epoch -0.012775608338415623\tEstimate time : 0:00:00.000130\n",
      "1ST GBrbm_first Training loss for 44 epoch -0.012776137329638004\tEstimate time : 0:00:00.000117\n",
      "1ST GBrbm_first Training loss for 45 epoch -0.012776322662830353\tEstimate time : 0:00:00.000197\n",
      "1ST GBrbm_first Training loss for 46 epoch -0.012775351293385029\tEstimate time : 0:00:00.000166\n",
      "1ST GBrbm_first Training loss for 47 epoch -0.012775945477187634\tEstimate time : 0:00:00.000118\n",
      "1ST GBrbm_first Training loss for 48 epoch -0.012776706367731094\tEstimate time : 0:00:00.000117\n",
      "1ST GBrbm_first Training loss for 49 epoch -0.012776951305568218\tEstimate time : 0:00:00.000260\n",
      "1ST GBrbm_first Training loss for 50 epoch -0.012775639072060585\tEstimate time : 0:00:00.000154\n",
      "1ST GBrbm_first Training loss for 51 epoch -0.012775647453963757\tEstimate time : 0:00:00.000166\n",
      "1ST GBrbm_first Training loss for 52 epoch -0.012776868417859077\tEstimate time : 0:00:00.000137\n",
      "1ST GBrbm_first Training loss for 53 epoch -0.012776829302310944\tEstimate time : 0:00:00.000170\n",
      "1ST GBrbm_first Training loss for 54 epoch -0.012776902876794338\tEstimate time : 0:00:00.000119\n",
      "1ST GBrbm_first Training loss for 55 epoch -0.012777038849890232\tEstimate time : 0:00:00.000118\n",
      "1ST GBrbm_first Training loss for 56 epoch -0.0127754807472229\tEstimate time : 0:00:00.000152\n",
      "1ST GBrbm_first Training loss for 57 epoch -0.012774654664099216\tEstimate time : 0:00:00.000123\n",
      "1ST GBrbm_first Training loss for 58 epoch -0.01277550496160984\tEstimate time : 0:00:00.000159\n",
      "1ST GBrbm_first Training loss for 59 epoch -0.012776250950992107\tEstimate time : 0:00:00.000119\n",
      "1ST GBrbm_first Training loss for 60 epoch -0.01277686282992363\tEstimate time : 0:00:00.000134\n",
      "1ST GBrbm_first Training loss for 61 epoch -0.012777283787727356\tEstimate time : 0:00:00.000149\n",
      "1ST GBrbm_first Training loss for 62 epoch -0.01277872733771801\tEstimate time : 0:00:00.000125\n",
      "1ST GBrbm_first Training loss for 63 epoch -0.012779658660292625\tEstimate time : 0:00:00.000142\n",
      "1ST GBrbm_first Training loss for 64 epoch -0.012780477292835712\tEstimate time : 0:00:00.000123\n",
      "1ST GBrbm_first Training loss for 65 epoch -0.012780527584254742\tEstimate time : 0:00:00.000132\n",
      "1ST GBrbm_first Training loss for 66 epoch -0.012783168815076351\tEstimate time : 0:00:00.000135\n",
      "1ST GBrbm_first Training loss for 67 epoch -0.012780874036252499\tEstimate time : 0:00:00.000123\n",
      "1ST GBrbm_first Training loss for 68 epoch -0.012781353667378426\tEstimate time : 0:00:00.000137\n",
      "1ST GBrbm_first Training loss for 69 epoch -0.0127823855727911\tEstimate time : 0:00:00.000178\n",
      "1ST GBrbm_first Training loss for 70 epoch -0.012783891521394253\tEstimate time : 0:00:00.000138\n",
      "1ST GBrbm_first Training loss for 71 epoch -0.012783825397491455\tEstimate time : 0:00:00.000159\n",
      "1ST GBrbm_first Training loss for 72 epoch -0.012784052640199661\tEstimate time : 0:00:00.000122\n",
      "1ST GBrbm_first Training loss for 73 epoch -0.012784190475940704\tEstimate time : 0:00:00.000131\n",
      "1ST GBrbm_first Training loss for 74 epoch -0.01278570294380188\tEstimate time : 0:00:00.000147\n",
      "1ST GBrbm_first Training loss for 75 epoch -0.01278526522219181\tEstimate time : 0:00:00.000118\n",
      "1ST GBrbm_first Training loss for 76 epoch -0.012784876860678196\tEstimate time : 0:00:00.000118\n",
      "1ST GBrbm_first Training loss for 77 epoch -0.012786016799509525\tEstimate time : 0:00:00.000125\n",
      "1ST GBrbm_first Training loss for 78 epoch -0.012785842642188072\tEstimate time : 0:00:00.000121\n",
      "1ST GBrbm_first Training loss for 79 epoch -0.012787182815372944\tEstimate time : 0:00:00.000118\n",
      "1ST GBrbm_first Training loss for 80 epoch -0.012788861058652401\tEstimate time : 0:00:00.000135\n",
      "1ST GBrbm_first Training loss for 81 epoch -0.012788825668394566\tEstimate time : 0:00:00.000164\n",
      "1ST GBrbm_first Training loss for 82 epoch -0.012788765132427216\tEstimate time : 0:00:00.000203\n",
      "1ST GBrbm_first Training loss for 83 epoch -0.012789684347808361\tEstimate time : 0:00:00.000117\n",
      "1ST GBrbm_first Training loss for 84 epoch -0.012790185399353504\tEstimate time : 0:00:00.000135\n",
      "1ST GBrbm_first Training loss for 85 epoch -0.012791174463927746\tEstimate time : 0:00:00.000119\n",
      "1ST GBrbm_first Training loss for 86 epoch -0.012791003100574017\tEstimate time : 0:00:00.000126\n",
      "1ST GBrbm_first Training loss for 87 epoch -0.012791300192475319\tEstimate time : 0:00:00.000157\n",
      "1ST GBrbm_first Training loss for 88 epoch -0.012791712768375874\tEstimate time : 0:00:00.000118\n",
      "1ST GBrbm_first Training loss for 89 epoch -0.012790879234671593\tEstimate time : 0:00:00.000116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/q_cwh5hn0s1dxsrzq2d040p80000gn/T/ipykernel_11046/2809123372.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ST GBrbm_first Training loss for 0 epoch -0.012768907472491264\tEstimate time : 0:00:00.000134\n",
      "2ST GBrbm_first Training loss for 1 epoch -0.012749078683555126\tEstimate time : 0:00:00.000122\n",
      "2ST GBrbm_first Training loss for 2 epoch -0.012727544642984867\tEstimate time : 0:00:00.000141\n",
      "2ST GBrbm_first Training loss for 3 epoch -0.012705552391707897\tEstimate time : 0:00:00.000170\n",
      "2ST GBrbm_first Training loss for 4 epoch -0.012682677246630192\tEstimate time : 0:00:00.000176\n",
      "2ST GBrbm_first Training loss for 5 epoch -0.012663254514336586\tEstimate time : 0:00:00.000118\n",
      "2ST GBrbm_first Training loss for 6 epoch -0.012640295550227165\tEstimate time : 0:00:00.000156\n",
      "2ST GBrbm_first Training loss for 7 epoch -0.012616780586540699\tEstimate time : 0:00:00.000306\n",
      "2ST GBrbm_first Training loss for 8 epoch -0.012592016719281673\tEstimate time : 0:00:00.000136\n",
      "2ST GBrbm_first Training loss for 9 epoch -0.012569621205329895\tEstimate time : 0:00:00.000162\n",
      "2ST GBrbm_first Training loss for 10 epoch -0.012549933046102524\tEstimate time : 0:00:00.000116\n",
      "2ST GBrbm_first Training loss for 11 epoch -0.012530174106359482\tEstimate time : 0:00:00.000117\n",
      "2ST GBrbm_first Training loss for 12 epoch -0.012511548586189747\tEstimate time : 0:00:00.000238\n",
      "2ST GBrbm_first Training loss for 13 epoch -0.012490755878388882\tEstimate time : 0:00:00.000135\n",
      "2ST GBrbm_first Training loss for 14 epoch -0.012467109598219395\tEstimate time : 0:00:00.000137\n",
      "2ST GBrbm_first Training loss for 15 epoch -0.012450947426259518\tEstimate time : 0:00:00.000158\n",
      "2ST GBrbm_first Training loss for 16 epoch -0.012430676259100437\tEstimate time : 0:00:00.000118\n",
      "2ST GBrbm_first Training loss for 17 epoch -0.012410121038556099\tEstimate time : 0:00:00.000139\n",
      "2ST GBrbm_first Training loss for 18 epoch -0.012388821691274643\tEstimate time : 0:00:00.000127\n",
      "2ST GBrbm_first Training loss for 19 epoch -0.012367771938443184\tEstimate time : 0:00:00.000116\n",
      "2ST GBrbm_first Training loss for 20 epoch -0.01234445534646511\tEstimate time : 0:00:00.000137\n",
      "2ST GBrbm_first Training loss for 21 epoch -0.012325641699135303\tEstimate time : 0:00:00.000133\n",
      "2ST GBrbm_first Training loss for 22 epoch -0.012303449213504791\tEstimate time : 0:00:00.000136\n",
      "2ST GBrbm_first Training loss for 23 epoch -0.012282727286219597\tEstimate time : 0:00:00.000137\n",
      "2ST GBrbm_first Training loss for 24 epoch -0.012260755524039268\tEstimate time : 0:00:00.000136\n",
      "2ST GBrbm_first Training loss for 25 epoch -0.012239494360983372\tEstimate time : 0:00:00.000265\n",
      "2ST GBrbm_first Training loss for 26 epoch -0.012215529568493366\tEstimate time : 0:00:00.000119\n",
      "2ST GBrbm_first Training loss for 27 epoch -0.012192058376967907\tEstimate time : 0:00:00.000232\n",
      "2ST GBrbm_first Training loss for 28 epoch -0.01217503473162651\tEstimate time : 0:00:00.000122\n",
      "2ST GBrbm_first Training loss for 29 epoch -0.012154084630310535\tEstimate time : 0:00:00.000125\n",
      "2ST GBrbm_first Training loss for 30 epoch -0.012134648859500885\tEstimate time : 0:00:00.000139\n",
      "2ST GBrbm_first Training loss for 31 epoch -0.012115832418203354\tEstimate time : 0:00:00.000159\n",
      "2ST GBrbm_first Training loss for 32 epoch -0.012098219245672226\tEstimate time : 0:00:00.000134\n",
      "2ST GBrbm_first Training loss for 33 epoch -0.012078152038156986\tEstimate time : 0:00:00.000161\n",
      "2ST GBrbm_first Training loss for 34 epoch -0.012058686465024948\tEstimate time : 0:00:00.000121\n",
      "2ST GBrbm_first Training loss for 35 epoch -0.012038610875606537\tEstimate time : 0:00:00.000139\n",
      "2ST GBrbm_first Training loss for 36 epoch -0.012018691748380661\tEstimate time : 0:00:00.000119\n",
      "2ST GBrbm_first Training loss for 37 epoch -0.011998615227639675\tEstimate time : 0:00:00.000121\n",
      "2ST GBrbm_first Training loss for 38 epoch -0.011980347335338593\tEstimate time : 0:00:00.000139\n",
      "2ST GBrbm_first Training loss for 39 epoch -0.01196061447262764\tEstimate time : 0:00:00.000135\n",
      "2ST GBrbm_first Training loss for 40 epoch -0.011940198950469494\tEstimate time : 0:00:00.000162\n",
      "2ST GBrbm_first Training loss for 41 epoch -0.011918991804122925\tEstimate time : 0:00:00.000162\n",
      "2ST GBrbm_first Training loss for 42 epoch -0.011898930184543133\tEstimate time : 0:00:00.000138\n",
      "2ST GBrbm_first Training loss for 43 epoch -0.011878401041030884\tEstimate time : 0:00:00.000120\n",
      "2ST GBrbm_first Training loss for 44 epoch -0.011857646517455578\tEstimate time : 0:00:00.000118\n",
      "2ST GBrbm_first Training loss for 45 epoch -0.011835548095405102\tEstimate time : 0:00:00.000123\n",
      "2ST GBrbm_first Training loss for 46 epoch -0.011818259954452515\tEstimate time : 0:00:00.000117\n",
      "2ST GBrbm_first Training loss for 47 epoch -0.011794733814895153\tEstimate time : 0:00:00.000165\n",
      "2ST GBrbm_first Training loss for 48 epoch -0.01177154015749693\tEstimate time : 0:00:00.000136\n",
      "2ST GBrbm_first Training loss for 49 epoch -0.011749712750315666\tEstimate time : 0:00:00.000135\n",
      "2ST GBrbm_first Training loss for 50 epoch -0.0117298299446702\tEstimate time : 0:00:00.000175\n",
      "2ST GBrbm_first Training loss for 51 epoch -0.011704246513545513\tEstimate time : 0:00:00.000135\n",
      "2ST GBrbm_first Training loss for 52 epoch -0.011683177202939987\tEstimate time : 0:00:00.000266\n",
      "2ST GBrbm_first Training loss for 53 epoch -0.011667659506201744\tEstimate time : 0:00:00.000118\n",
      "2ST GBrbm_first Training loss for 54 epoch -0.011645824648439884\tEstimate time : 0:00:00.000119\n",
      "2ST GBrbm_first Training loss for 55 epoch -0.011622882448136806\tEstimate time : 0:00:00.000115\n",
      "2ST GBrbm_first Training loss for 56 epoch -0.011602426879107952\tEstimate time : 0:00:00.000160\n",
      "2ST GBrbm_first Training loss for 57 epoch -0.011581024155020714\tEstimate time : 0:00:00.000157\n",
      "2ST GBrbm_first Training loss for 58 epoch -0.011558647267520428\tEstimate time : 0:00:00.000297\n",
      "2ST GBrbm_first Training loss for 59 epoch -0.011537548154592514\tEstimate time : 0:00:00.000177\n",
      "2ST GBrbm_first Training loss for 60 epoch -0.01151931844651699\tEstimate time : 0:00:00.000148\n",
      "2ST GBrbm_first Training loss for 61 epoch -0.011497468687593937\tEstimate time : 0:00:00.000267\n",
      "2ST GBrbm_first Training loss for 62 epoch -0.011477014981210232\tEstimate time : 0:00:00.000331\n",
      "2ST GBrbm_first Training loss for 63 epoch -0.01146027073264122\tEstimate time : 0:00:00.000163\n",
      "2ST GBrbm_first Training loss for 64 epoch -0.01144107710570097\tEstimate time : 0:00:00.000290\n",
      "2ST GBrbm_first Training loss for 65 epoch -0.011420931667089462\tEstimate time : 0:00:00.000137\n",
      "2ST GBrbm_first Training loss for 66 epoch -0.011400101706385612\tEstimate time : 0:00:00.000139\n",
      "2ST GBrbm_first Training loss for 67 epoch -0.011379037983715534\tEstimate time : 0:00:00.000136\n",
      "2ST GBrbm_first Training loss for 68 epoch -0.011358329094946384\tEstimate time : 0:00:00.000127\n",
      "2ST GBrbm_first Training loss for 69 epoch -0.011339234188199043\tEstimate time : 0:00:00.000117\n",
      "2ST GBrbm_first Training loss for 70 epoch -0.011318841017782688\tEstimate time : 0:00:00.000126\n",
      "2ST GBrbm_first Training loss for 71 epoch -0.01129744853824377\tEstimate time : 0:00:00.000118\n",
      "2ST GBrbm_first Training loss for 72 epoch -0.011278164573013783\tEstimate time : 0:00:00.000140\n",
      "2ST GBrbm_first Training loss for 73 epoch -0.011259851045906544\tEstimate time : 0:00:00.000134\n",
      "2ST GBrbm_first Training loss for 74 epoch -0.011242598295211792\tEstimate time : 0:00:00.000141\n",
      "2ST GBrbm_first Training loss for 75 epoch -0.011224678717553616\tEstimate time : 0:00:00.000137\n",
      "2ST GBrbm_first Training loss for 76 epoch -0.011202673427760601\tEstimate time : 0:00:00.000234\n",
      "2ST GBrbm_first Training loss for 77 epoch -0.011184054426848888\tEstimate time : 0:00:00.000117\n",
      "2ST GBrbm_first Training loss for 78 epoch -0.011165736243128777\tEstimate time : 0:00:00.000134\n",
      "2ST GBrbm_first Training loss for 79 epoch -0.01114767324179411\tEstimate time : 0:00:00.000118\n",
      "2ST GBrbm_first Training loss for 80 epoch -0.011126024648547173\tEstimate time : 0:00:00.000121\n",
      "2ST GBrbm_first Training loss for 81 epoch -0.011107130907475948\tEstimate time : 0:00:00.000138\n",
      "2ST GBrbm_first Training loss for 82 epoch -0.01108349859714508\tEstimate time : 0:00:00.000139\n",
      "2ST GBrbm_first Training loss for 83 epoch -0.01106276549398899\tEstimate time : 0:00:00.000137\n",
      "2ST GBrbm_first Training loss for 84 epoch -0.01104584988206625\tEstimate time : 0:00:00.000140\n",
      "2ST GBrbm_first Training loss for 85 epoch -0.011028015054762363\tEstimate time : 0:00:00.000163\n",
      "2ST GBrbm_first Training loss for 86 epoch -0.011013418436050415\tEstimate time : 0:00:00.000135\n",
      "2ST GBrbm_first Training loss for 87 epoch -0.010994309559464455\tEstimate time : 0:00:00.000138\n",
      "2ST GBrbm_first Training loss for 88 epoch -0.010974938981235027\tEstimate time : 0:00:00.000219\n",
      "2ST GBrbm_first Training loss for 89 epoch -0.010956889018416405\tEstimate time : 0:00:00.000157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/q_cwh5hn0s1dxsrzq2d040p80000gn/T/ipykernel_11046/2809123372.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3ST GBrbm_first Training loss for 0 epoch -0.010940632782876492\tEstimate time : 0:00:00.000117\n",
      "3ST GBrbm_first Training loss for 1 epoch -0.010931865312159061\tEstimate time : 0:00:00.000158\n",
      "3ST GBrbm_first Training loss for 2 epoch -0.010921316221356392\tEstimate time : 0:00:00.000135\n",
      "3ST GBrbm_first Training loss for 3 epoch -0.010906017385423183\tEstimate time : 0:00:00.000160\n",
      "3ST GBrbm_first Training loss for 4 epoch -0.010889747180044651\tEstimate time : 0:00:00.000135\n",
      "3ST GBrbm_first Training loss for 5 epoch -0.010871723294258118\tEstimate time : 0:00:00.000289\n",
      "3ST GBrbm_first Training loss for 6 epoch -0.010852908715605736\tEstimate time : 0:00:00.000126\n",
      "3ST GBrbm_first Training loss for 7 epoch -0.010843056254088879\tEstimate time : 0:00:00.000116\n",
      "3ST GBrbm_first Training loss for 8 epoch -0.010828875005245209\tEstimate time : 0:00:00.000140\n",
      "3ST GBrbm_first Training loss for 9 epoch -0.010812941007316113\tEstimate time : 0:00:00.000135\n",
      "3ST GBrbm_first Training loss for 10 epoch -0.010798519477248192\tEstimate time : 0:00:00.000138\n",
      "3ST GBrbm_first Training loss for 11 epoch -0.010787774808704853\tEstimate time : 0:00:00.000146\n",
      "3ST GBrbm_first Training loss for 12 epoch -0.010777547955513\tEstimate time : 0:00:00.000134\n",
      "3ST GBrbm_first Training loss for 13 epoch -0.010763421654701233\tEstimate time : 0:00:00.000134\n",
      "3ST GBrbm_first Training loss for 14 epoch -0.010752758011221886\tEstimate time : 0:00:00.000135\n",
      "3ST GBrbm_first Training loss for 15 epoch -0.010740415193140507\tEstimate time : 0:00:00.000119\n",
      "3ST GBrbm_first Training loss for 16 epoch -0.010724241845309734\tEstimate time : 0:00:00.000117\n",
      "3ST GBrbm_first Training loss for 17 epoch -0.010710046626627445\tEstimate time : 0:00:00.000255\n",
      "3ST GBrbm_first Training loss for 18 epoch -0.01069943979382515\tEstimate time : 0:00:00.000138\n",
      "3ST GBrbm_first Training loss for 19 epoch -0.010686242021620274\tEstimate time : 0:00:00.000134\n",
      "3ST GBrbm_first Training loss for 20 epoch -0.010674107819795609\tEstimate time : 0:00:00.000195\n",
      "3ST GBrbm_first Training loss for 21 epoch -0.010661968030035496\tEstimate time : 0:00:00.000168\n",
      "3ST GBrbm_first Training loss for 22 epoch -0.01064409501850605\tEstimate time : 0:00:00.000134\n",
      "3ST GBrbm_first Training loss for 23 epoch -0.010631722398102283\tEstimate time : 0:00:00.000116\n",
      "3ST GBrbm_first Training loss for 24 epoch -0.010621068067848682\tEstimate time : 0:00:00.000117\n",
      "3ST GBrbm_first Training loss for 25 epoch -0.010609923861920834\tEstimate time : 0:00:00.000115\n",
      "3ST GBrbm_first Training loss for 26 epoch -0.010596397332847118\tEstimate time : 0:00:00.000135\n",
      "3ST GBrbm_first Training loss for 27 epoch -0.010585617274045944\tEstimate time : 0:00:00.000136\n",
      "3ST GBrbm_first Training loss for 28 epoch -0.010574943386018276\tEstimate time : 0:00:00.000134\n",
      "3ST GBrbm_first Training loss for 29 epoch -0.010558961890637875\tEstimate time : 0:00:00.000156\n",
      "3ST GBrbm_first Training loss for 30 epoch -0.010548521764576435\tEstimate time : 0:00:00.000136\n",
      "3ST GBrbm_first Training loss for 31 epoch -0.01053706370294094\tEstimate time : 0:00:00.000136\n",
      "3ST GBrbm_first Training loss for 32 epoch -0.010531037114560604\tEstimate time : 0:00:00.000118\n",
      "3ST GBrbm_first Training loss for 33 epoch -0.010519297793507576\tEstimate time : 0:00:00.000122\n",
      "3ST GBrbm_first Training loss for 34 epoch -0.010504461824893951\tEstimate time : 0:00:00.000219\n",
      "3ST GBrbm_first Training loss for 35 epoch -0.01049100887030363\tEstimate time : 0:00:00.000135\n",
      "3ST GBrbm_first Training loss for 36 epoch -0.01047831866890192\tEstimate time : 0:00:00.000191\n",
      "3ST GBrbm_first Training loss for 37 epoch -0.010470734909176826\tEstimate time : 0:00:00.000274\n",
      "3ST GBrbm_first Training loss for 38 epoch -0.010458523407578468\tEstimate time : 0:00:00.000121\n",
      "3ST GBrbm_first Training loss for 39 epoch -0.010446476750075817\tEstimate time : 0:00:00.000120\n",
      "3ST GBrbm_first Training loss for 40 epoch -0.010438087396323681\tEstimate time : 0:00:00.000119\n",
      "3ST GBrbm_first Training loss for 41 epoch -0.010431624948978424\tEstimate time : 0:00:00.000137\n",
      "3ST GBrbm_first Training loss for 42 epoch -0.01041659526526928\tEstimate time : 0:00:00.000118\n",
      "3ST GBrbm_first Training loss for 43 epoch -0.010403602384030819\tEstimate time : 0:00:00.000124\n",
      "3ST GBrbm_first Training loss for 44 epoch -0.010392244905233383\tEstimate time : 0:00:00.000135\n",
      "3ST GBrbm_first Training loss for 45 epoch -0.010382498614490032\tEstimate time : 0:00:00.000135\n",
      "3ST GBrbm_first Training loss for 46 epoch -0.010371057316660881\tEstimate time : 0:00:00.000136\n",
      "3ST GBrbm_first Training loss for 47 epoch -0.010357881896197796\tEstimate time : 0:00:00.000136\n",
      "3ST GBrbm_first Training loss for 48 epoch -0.010343999601900578\tEstimate time : 0:00:00.000120\n",
      "3ST GBrbm_first Training loss for 49 epoch -0.010330990888178349\tEstimate time : 0:00:00.000132\n",
      "3ST GBrbm_first Training loss for 50 epoch -0.010320505127310753\tEstimate time : 0:00:00.000120\n",
      "3ST GBrbm_first Training loss for 51 epoch -0.010306249372661114\tEstimate time : 0:00:00.000131\n",
      "3ST GBrbm_first Training loss for 52 epoch -0.010293052531778812\tEstimate time : 0:00:00.000139\n",
      "3ST GBrbm_first Training loss for 53 epoch -0.010278095491230488\tEstimate time : 0:00:00.000144\n",
      "3ST GBrbm_first Training loss for 54 epoch -0.010262273252010345\tEstimate time : 0:00:00.000134\n",
      "3ST GBrbm_first Training loss for 55 epoch -0.010249163024127483\tEstimate time : 0:00:00.000135\n",
      "3ST GBrbm_first Training loss for 56 epoch -0.010233926586806774\tEstimate time : 0:00:00.000136\n",
      "3ST GBrbm_first Training loss for 57 epoch -0.010220905765891075\tEstimate time : 0:00:00.000139\n",
      "3ST GBrbm_first Training loss for 58 epoch -0.010210859589278698\tEstimate time : 0:00:00.000135\n",
      "3ST GBrbm_first Training loss for 59 epoch -0.010200182907283306\tEstimate time : 0:00:00.000117\n",
      "3ST GBrbm_first Training loss for 60 epoch -0.010186743922531605\tEstimate time : 0:00:00.000122\n",
      "3ST GBrbm_first Training loss for 61 epoch -0.01017485186457634\tEstimate time : 0:00:00.000134\n",
      "3ST GBrbm_first Training loss for 62 epoch -0.010164273902773857\tEstimate time : 0:00:00.000133\n",
      "3ST GBrbm_first Training loss for 63 epoch -0.010150576010346413\tEstimate time : 0:00:00.000138\n",
      "3ST GBrbm_first Training loss for 64 epoch -0.010142846032977104\tEstimate time : 0:00:00.000136\n",
      "3ST GBrbm_first Training loss for 65 epoch -0.010130483657121658\tEstimate time : 0:00:00.000117\n",
      "3ST GBrbm_first Training loss for 66 epoch -0.01011624839156866\tEstimate time : 0:00:00.000122\n",
      "3ST GBrbm_first Training loss for 67 epoch -0.010104499757289886\tEstimate time : 0:00:00.000125\n",
      "3ST GBrbm_first Training loss for 68 epoch -0.010092207230627537\tEstimate time : 0:00:00.000146\n",
      "3ST GBrbm_first Training loss for 69 epoch -0.010080944746732712\tEstimate time : 0:00:00.000158\n",
      "3ST GBrbm_first Training loss for 70 epoch -0.010071001946926117\tEstimate time : 0:00:00.000134\n",
      "3ST GBrbm_first Training loss for 71 epoch -0.010064219124615192\tEstimate time : 0:00:00.000176\n",
      "3ST GBrbm_first Training loss for 72 epoch -0.010056176222860813\tEstimate time : 0:00:00.000144\n",
      "3ST GBrbm_first Training loss for 73 epoch -0.010048545897006989\tEstimate time : 0:00:00.000116\n",
      "3ST GBrbm_first Training loss for 74 epoch -0.010036238469183445\tEstimate time : 0:00:00.000135\n",
      "3ST GBrbm_first Training loss for 75 epoch -0.010024439543485641\tEstimate time : 0:00:00.000135\n",
      "3ST GBrbm_first Training loss for 76 epoch -0.010014230385422707\tEstimate time : 0:00:00.000145\n",
      "3ST GBrbm_first Training loss for 77 epoch -0.010006632655858994\tEstimate time : 0:00:00.000158\n",
      "3ST GBrbm_first Training loss for 78 epoch -0.009995940141379833\tEstimate time : 0:00:00.000139\n",
      "3ST GBrbm_first Training loss for 79 epoch -0.009980401024222374\tEstimate time : 0:00:00.000117\n",
      "3ST GBrbm_first Training loss for 80 epoch -0.009970889426767826\tEstimate time : 0:00:00.000129\n",
      "3ST GBrbm_first Training loss for 81 epoch -0.00995683390647173\tEstimate time : 0:00:00.000118\n",
      "3ST GBrbm_first Training loss for 82 epoch -0.009944753721356392\tEstimate time : 0:00:00.000117\n",
      "3ST GBrbm_first Training loss for 83 epoch -0.009932608343660831\tEstimate time : 0:00:00.000135\n",
      "3ST GBrbm_first Training loss for 84 epoch -0.009920880198478699\tEstimate time : 0:00:00.000117\n",
      "3ST GBrbm_first Training loss for 85 epoch -0.009909531101584435\tEstimate time : 0:00:00.000117\n",
      "3ST GBrbm_first Training loss for 86 epoch -0.009898503310978413\tEstimate time : 0:00:00.000124\n",
      "3ST GBrbm_first Training loss for 87 epoch -0.009884553961455822\tEstimate time : 0:00:00.000158\n",
      "3ST GBrbm_first Training loss for 88 epoch -0.00987087469547987\tEstimate time : 0:00:00.000133\n",
      "3ST GBrbm_first Training loss for 89 epoch -0.009856553748250008\tEstimate time : 0:00:00.000134\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "print(\"BBRBM is done.\")\n",
    "print(\"GBRBM is start\")\n",
    "\n",
    "output_from_first = list()\n",
    "output_from_second = list()\n",
    "output_from_third = torch.tensor(output_from_third)\n",
    "\n",
    "rbm_first = RBM(n_vis=VISIBLE_UNITS[0], n_hid=HIDDEN_UNITS[0], k=K_FOLD, batch=BATCH_SIZE)\n",
    "rbm_second = RBM(n_vis=VISIBLE_UNITS[1], n_hid=HIDDEN_UNITS[1], k=K_FOLD, batch=BATCH_SIZE)\n",
    "rbm_third = RBM(n_vis=VISIBLE_UNITS[2], n_hid=HIDDEN_UNITS[2], k=K_FOLD, batch=BATCH_SIZE)\n",
    "\n",
    "# print(output_from_third.size(), output_from_third.dim(), \"\\n\", output_from_third)\n",
    "gaussian_std = torch.arange(1, 0, -0.1)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    '''First gbrbm'''\n",
    "    for _, (data) in enumerate(output_from_third):\n",
    "        try:\n",
    "            data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "        \n",
    "        # CHANGED to GAUSSIAN\n",
    "        sample_data = torch.normal(mean=data, std=gaussian_std)\n",
    "        sample_data = torch.flatten(sample_data.clone())\n",
    "\n",
    "        gb_vog_first, gb_v1, mt = rbm_first(sample_data)\n",
    "        \n",
    "        gb_loss_first = rbm_first.free_energy(gb_vog_first) - rbm_first.free_energy(gb_v1)\n",
    "        loss_.append(gb_loss_first.data)\n",
    "        \n",
    "        gb_first_train_op.zero_grad()\n",
    "        gb_loss_first.backward()\n",
    "        gb_first_train_op.step()\n",
    "\n",
    "    output_from_first.append(gb_v1.tolist())\n",
    "    print(\"1ST GBrbm_first Training loss for {0} epoch {1}\\tEstimate time : {2}\".format(epoch, np.mean(loss_), mt))\n",
    "\n",
    "output_from_first = torch.tensor(output_from_first)\n",
    "for epoch in range(EPOCH):\n",
    "    '''Second gbrbm'''\n",
    "    for _, (data) in enumerate(output_from_first):\n",
    "        try:\n",
    "            data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "        \n",
    "        # CHANGED to GAUSSIAN\n",
    "        sample_data = torch.normal(mean=data, std=gaussian_std)\n",
    "        sample_data = torch.flatten(sample_data.clone())\n",
    "\n",
    "        gb_vog_second, gb_v2, mt = rbm_second(sample_data)\n",
    "        \n",
    "        gb_loss_second = rbm_second.free_energy(gb_vog_second) - rbm_second.free_energy(gb_v2)\n",
    "        loss_.append(gb_loss_second.data)\n",
    "        \n",
    "        gb_second_train_op.zero_grad()\n",
    "        gb_loss_second.backward()\n",
    "        gb_second_train_op.step()\n",
    "\n",
    "    output_from_second.append(gb_v2.tolist())\n",
    "    print(\"2ST GBrbm_first Training loss for {0} epoch {1}\\tEstimate time : {2}\".format(epoch, np.mean(loss_), mt))\n",
    "\n",
    "output_from_second = torch.tensor(output_from_second)\n",
    "for epoch in range(EPOCH):\n",
    "    '''Third gbrbm'''\n",
    "    for _, (data) in enumerate(output_from_second):\n",
    "        try:\n",
    "            data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "        \n",
    "        # CHANGED to GAUSSIAN\n",
    "        sample_data = torch.normal(mean=data, std=gaussian_std)\n",
    "        sample_data = torch.flatten(sample_data.clone())\n",
    "\n",
    "        gb_vog_third, gb_v3, mt = rbm_third(sample_data)\n",
    "        \n",
    "        gb_loss_third = rbm_third.free_energy(gb_vog_third) - rbm_second.free_energy(gb_v3)\n",
    "        loss_.append(gb_loss_third.data)\n",
    "        \n",
    "        gb_third_train_op.zero_grad()\n",
    "        gb_loss_third.backward()\n",
    "        gb_third_train_op.step()\n",
    "\n",
    "    print(\"3ST GBrbm_first Training loss for {0} epoch {1}\\tEstimate time : {2}\".format(epoch, np.mean(loss_), mt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0045, -0.0011, -0.0021, -0.0074, -0.0234, -0.0010, -0.0086,  0.0098,\n",
       "          0.0212, -0.0058]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nprst = gb_v3.detach().numpy()\n",
    "print(nprst)\n",
    "\n",
    "rbm_first.get_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_8/q_cwh5hn0s1dxsrzq2d040p80000gn/T/ipykernel_11046/200555237.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
      "/var/folders/_8/q_cwh5hn0s1dxsrzq2d040p80000gn/T/ipykernel_11046/200555237.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_data = torch.tensor((Variable(train_data[train_cnt:train_cnt + 10])).uniform_(0, 1), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : tensor(0.0002, grad_fn=<DivBackward0>)\n",
      "Train - test : tensor(-0.2345, grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "train_loss = 0\n",
    "train_cnt = 0\n",
    "summary_c = 0\n",
    "\n",
    "for _, test_data in enumerate(test_dataloader):\n",
    "    try:\n",
    "        test_data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "        train_data = torch.tensor((Variable(train_data[train_cnt:train_cnt + 10])).uniform_(0, 1), dtype=torch.float32)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    \n",
    "    testing_data = torch.flatten(torch.bernoulli(test_data))\n",
    "    training_data = torch.flatten(torch.bernoulli(train_data))\n",
    "    \n",
    "    vt, vt1, _ = rbm_first(testing_data)\n",
    "    test_loss = rbm_first.free_energy(vt) - rbm_first.free_energy(vt1)    \n",
    "    \n",
    "    vs, vs1, _ = rbm_first(training_data)\n",
    "    train_loss = rbm_first.free_energy(vs) - rbm_first.free_energy(vs1)\n",
    "\n",
    "    \n",
    "    test_loss += torch.mean(torch.abs(vt1[vt1 >= 0] - vt[vt1 >= 0]))\n",
    "    # print(vt1[vt1 >= 0] - vt[vt1 >= 0])\n",
    "    summary_c += 1\n",
    "\n",
    "print('Test loss : ' + str(test_loss / summary_c))\n",
    "print('Train - test : ' + str(train_loss - test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Test code'''\n",
    "rbm_first = RBM(n_vis=VISIBLE_UNITS[0], n_hid=HIDDEN_UNITS[0], k=K_FOLD, batch=BATCH_SIZE)\n",
    "rbm_second = RBM(n_vis=VISIBLE_UNITS[1], n_hid=HIDDEN_UNITS[1], k=K_FOLD, batch=BATCH_SIZE)\n",
    "rbm_third = RBM(n_vis=VISIBLE_UNITS[2], n_hid=HIDDEN_UNITS[2], k=K_FOLD, batch=BATCH_SIZE)\n",
    "\n",
    "output_from_first = list()\n",
    "output_from_second = list()\n",
    "output_from_third = list()\n",
    "\n",
    "test_loss = 0\n",
    "epoch_cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBBRBM_First_layer test loss :  tensor(-0.0086, grad_fn=<DivBackward0>)\n",
      "\tBBRBM_Second_layer test loss :  tensor(-0.0082, grad_fn=<DivBackward0>)\n",
      "\tBBRBM_Third_layer test loss :  tensor(-0.0138, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "'''First BBRBM Guide Line'''\n",
    "\n",
    "for _, data in enumerate(test_dataloader):\n",
    "    try:\n",
    "        test_data = torch.tensor(Variable(data.clone().detach().requires_grad_(True).view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    \n",
    "    data = torch.flatten(torch.bernoulli(test_data))\n",
    "    \n",
    "    v1, vt1, _ = rbm_first(data)\n",
    "    test_loss += rbm_first.free_energy(v1) - rbm_first.free_energy(vt1)\n",
    "    epoch_cnt += 1\n",
    "    output_from_first.append(vt1.tolist())\n",
    "print('\\tBBRBM_First_layer test loss : ', str(test_loss / epoch_cnt))\n",
    "\n",
    "'''Second BBRBM Guide Line'''\n",
    "\n",
    "for _, data in enumerate(torch.tensor(output_from_first)):\n",
    "    try:\n",
    "        test_data = torch.tensor(Variable(data.clone().detach().requires_grad_(True).view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    \n",
    "    data = torch.flatten(torch.bernoulli(test_data))\n",
    "    \n",
    "    v2, vt2, _ = rbm_second(data)\n",
    "    test_loss += rbm_second.free_energy(v2) - rbm_second.free_energy(vt2)\n",
    "    epoch_cnt += 1\n",
    "    output_from_second.append(vt2.tolist())\n",
    "print('\\tBBRBM_Second_layer test loss : ', str(test_loss / epoch_cnt))\n",
    "\n",
    "'''Third BBRBM Guide Line'''\n",
    "\n",
    "for _, data in enumerate(torch.tensor(output_from_second)):\n",
    "    try:\n",
    "        test_data = torch.tensor(Variable(data.clone().detach().requires_grad_(True).view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    \n",
    "    data = torch.flatten(torch.bernoulli(test_data))\n",
    "    \n",
    "    v3, vt3, _ = rbm_third(data)\n",
    "    test_loss += rbm_third.free_energy(v3) - rbm_third.free_energy(vt3)\n",
    "    epoch_cnt += 1\n",
    "    output_from_third.append(vt3.tolist())\n",
    "print('\\tBBRBM_Third_layer test loss : ', str(test_loss / epoch_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm_first = RBM(n_vis=VISIBLE_UNITS[0], n_hid=HIDDEN_UNITS[0], k=K_FOLD, batch=BATCH_SIZE)\n",
    "rbm_second = RBM(n_vis=VISIBLE_UNITS[1], n_hid=HIDDEN_UNITS[1], k=K_FOLD, batch=BATCH_SIZE)\n",
    "rbm_third = RBM(n_vis=VISIBLE_UNITS[2], n_hid=HIDDEN_UNITS[2], k=K_FOLD, batch=BATCH_SIZE)\n",
    "\n",
    "output_from_first = list()\n",
    "output_from_second = list()\n",
    "\n",
    "test_loss = 0\n",
    "epoch_cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGBRBM_First_layer test loss :  tensor(-0.0014, grad_fn=<DivBackward0>)\n",
      "\tGBRBM_Second_layer test loss :  tensor(-0.0006, grad_fn=<DivBackward0>)\n",
      "\tGBRBM_Third_layer test loss :  tensor(-8.9733e-05, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "'''First GBRBM Guide Line'''\n",
    "epoch_cnt = 0\n",
    "for _, data in enumerate(torch.tensor(output_from_third)):\n",
    "    try:\n",
    "        test_data = torch.tensor(Variable(data.clone().detach().requires_grad_(True).view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    \n",
    "    sample_data = torch.flatten(torch.normal(mean=data, std=gaussian_std))\n",
    "\n",
    "    v1, vt1, _ = rbm_first(sample_data)\n",
    "    test_loss += rbm_first.free_energy(v1) - rbm_first.free_energy(vt1)\n",
    "    epoch_cnt += 1\n",
    "    output_from_first.append(vt1.tolist())\n",
    "print('\\tGBRBM_First_layer test loss : ', str(test_loss / epoch_cnt))\n",
    "\n",
    "'''Second BBRBM Guide Line'''\n",
    "\n",
    "for _, data in enumerate(torch.tensor(output_from_first)):\n",
    "    try:\n",
    "        test_data = torch.tensor(Variable(data.clone().detach().requires_grad_(True).view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    \n",
    "    sample_data = torch.flatten(torch.normal(mean=data, std=gaussian_std))\n",
    "    \n",
    "    v2, vt2, _ = rbm_second(sample_data)\n",
    "    test_loss += rbm_second.free_energy(v2) - rbm_second.free_energy(vt2)\n",
    "    epoch_cnt += 1\n",
    "    output_from_second.append(vt2.tolist())\n",
    "print('\\tGBRBM_Second_layer test loss : ', str(test_loss / epoch_cnt))\n",
    "\n",
    "'''Third BBRBM Guide Line'''\n",
    "\n",
    "output_from_third = []\n",
    "for _, data in enumerate(torch.tensor(output_from_second)):\n",
    "    try:\n",
    "        test_data = torch.tensor(Variable(data.clone().detach().requires_grad_(True).view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    \n",
    "    sample_data = torch.flatten(torch.bernoulli(test_data))\n",
    "    \n",
    "    v3, vt3, _ = rbm_third(sample_data)\n",
    "    test_loss += rbm_third.free_energy(v3) - rbm_third.free_energy(vt3)\n",
    "    epoch_cnt += 1\n",
    "    output_from_third.append(vt3.tolist())\n",
    "print('\\tGBRBM_Third_layer test loss : ', str(test_loss / epoch_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = nn.Linear(len(output_from_third), 4)\n",
    "# print(\"Linear_in size : {}, Linear_in dim : {}\".format(linear_in.size(), linear_in.dim()))\n",
    "\n",
    "# print(lin(linear_in.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 248 is out of bounds for dimension 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_8/q_cwh5hn0s1dxsrzq2d040p80000gn/T/ipykernel_11046/2157323121.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msvm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Github/ecg-dbn/SVM.py\u001b[0m in \u001b[0;36msvm_model\u001b[0;34m(X, Y, model, epoch, batch, c)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msum_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 248 is out of bounds for dimension 0 with size 10"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(output_from_third)\n",
    "\n",
    "X = (X - X.mean()) / X.std()\n",
    "print(X.T.dim())\n",
    "svm_model(X.T, X, lin, EPOCH, BATCH_SIZE)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "155d6f2e0f64686ab4bfd14ea62d28fe51bc71031495ea0caf798feb858e6597"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
