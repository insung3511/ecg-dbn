{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-26 00:37:42.177071 model.py code start\n"
     ]
    }
   ],
   "source": [
    "from ignite.contrib.metrics.regression import *\n",
    "from ignite.contrib.metrics import *\n",
    "from ignite.handlers import *\n",
    "from ignite.metrics import *\n",
    "from ignite.engine import *\n",
    "from ignite.utils import *\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import data.read_samples as rs\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import OrderedDict\n",
    "from scipy import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "\n",
    "print(datetime.datetime.now(), \"model.py code start\")\n",
    "\n",
    "BATCH_SIZE = 107\n",
    "EPOCH = 400\n",
    "LEARNING_RATE = 0.2\n",
    "ANNEALING_RATE = 0.999\n",
    "HIDDEN_UNITS = [180, 200, 250, 80, 100, 120]\n",
    "K_FOLD = 1\n",
    "MAT_PATH = \"C:/Users/HILAB_Labtop_02/Desktop/insung/ecg-dbn/data/mit.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3080 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "print(torch.cuda.get_device_name(device))\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM(nn.Module): \n",
    "    with torch.cuda.device(0):\n",
    "        def __init__(self, n_vis, n_hid, k, batch):\n",
    "            super(RBM, self).__init__()\n",
    "            self.W      = nn.Parameter(torch.randn(1, batch, device=device) * 1e-2)\n",
    "            self.n_vis  = n_vis\n",
    "            self.n_hid  = n_hid\n",
    "            self.k      = k\n",
    "            self.batch  = batch\n",
    "            self.v_bias = nn.Parameter(torch.zeros(n_vis, 1, device=device))\n",
    "            self.h_bias = nn.Parameter(torch.zeros(n_hid, 1, device=device))\n",
    "        \n",
    "        def sample_from_p(self, p):\n",
    "            return F.relu(\n",
    "                torch.sign(\n",
    "                    p - Variable(torch.randn(p.size(), device=device))\n",
    "                )\n",
    "            ).to(device=device)\n",
    "\n",
    "        ''' ISSUE PART '''\n",
    "        def v_to_h(self, v):\n",
    "            w = (self.W.clone())\n",
    "\n",
    "            p_h = F.sigmoid(\n",
    "                F.linear(v, w)\n",
    "            ).to(device=device)\n",
    "\n",
    "            sample_h = self.sample_from_p(p_h)\n",
    "            return p_h, sample_h\n",
    "\n",
    "        def h_to_v(self, h):\n",
    "            w = self.W.t().clone()\n",
    "\n",
    "            p_v = F.sigmoid(\n",
    "                F.linear(h, w)\n",
    "            ).to(device=device)\n",
    "\n",
    "            sample_v = self.sample_from_p(p_v)\n",
    "            return p_v, sample_v\n",
    "        \n",
    "        def forward(self, v):\n",
    "            pre_h1, h1 = self.v_to_h(v)\n",
    "            h_ = h1\n",
    "\n",
    "            for _ in range(self.k):\n",
    "                pre_v_, v_ = self.h_to_v(h_)\n",
    "                pre_h_, h_ = self.v_to_h(v_)\n",
    "            return v, v_\n",
    "        \n",
    "        def get_weight(self):\n",
    "            return self.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM(nn.Module):\n",
    "    with torch.cuda.device(0):\n",
    "        def __init__(self, lr, n_x):\n",
    "            super(SVM, self).__init__()\n",
    "            self.lr = lr\n",
    "            self.fully = nn.Linear(n_x, 1).to(device=device)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            fwd = self.fully(x)\n",
    "            return fwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes):\n",
    "    return np.eye(num_classes, dtype='uint8')[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    89921\n",
      "3.0     6999\n",
      "2.0     2777\n",
      "4.0      801\n",
      "1.0       15\n",
      "Name: 428, dtype: int64 \n",
      "\n",
      "X_train shape:  (70359, 428, 1)\n",
      "Y_train shape:  (70359, 5)\n",
      "X_val shape:  (30154, 428, 1)\n",
      "Y_val shape:  (30154, 5)\n"
     ]
    }
   ],
   "source": [
    "mit = io.loadmat(MAT_PATH)\n",
    "mit = mit['mit']\n",
    "df_mit = pd.DataFrame(data = mit)\n",
    "\n",
    "print(df_mit[428].value_counts(), '\\n')\n",
    "# 0 = N\n",
    "# 1 = Q\n",
    "# 2 = S\n",
    "# 3 = V\n",
    "# 4 = F\n",
    "\n",
    "Y = np.array(df_mit[428].values).astype(np.int8)\n",
    "X = np.array(df_mit[list(range(428))].values)[..., np.newaxis]\n",
    "\n",
    "oneHot = LabelEncoder()\n",
    "oneHot.fit(Y)\n",
    "Y = oneHot.transform(Y)\n",
    "\n",
    "X = X.reshape(-1, 428, 1)\n",
    "Y = to_categorical(Y, 5)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y,\n",
    "                                                test_size=0.3,\n",
    "                                                random_state=42,\n",
    "                                                stratify=Y)\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"Y_train shape: \", Y_train.shape)\n",
    "print(\"X_val shape: \", X_val.shape)\n",
    "print(\"Y_val shape: \", Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(X_train,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              num_workers=0,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(X_val,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             num_workers=0,\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(engine, batch):\n",
    "    return batch\n",
    "\n",
    "default_model = nn.Sequential(OrderedDict([\n",
    "    ('base', nn.Linear(4, 2)),\n",
    "    ('fc', nn.Linear(2, 1))\n",
    "]))\n",
    "\n",
    "default_evaluator = Engine(eval_step)\n",
    "\n",
    "def get_acc(y_true, y_pred):\n",
    "    metric = Accuracy()\n",
    "    metric.attach(default_evaluator, \"accuracy\")\n",
    "    state = default_evaluator.run([[y_pred, y_true]])\n",
    "    return state.metrics[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([107])\n"
     ]
    }
   ],
   "source": [
    "bbrbm_first = RBM(n_vis=187, n_hid=HIDDEN_UNITS[0], k=K_FOLD, batch=BATCH_SIZE).to(device=device)\n",
    "bbrbm_second = RBM(n_vis=187, n_hid=HIDDEN_UNITS[1], k=K_FOLD, batch=BATCH_SIZE).to(device=device)\n",
    "bbrbm_third = RBM(n_vis=187, n_hid=HIDDEN_UNITS[2], k=K_FOLD, batch=BATCH_SIZE).to(device=device)\n",
    "\n",
    "gbrbm_first = RBM(n_vis=187, n_hid=HIDDEN_UNITS[3], k=K_FOLD, batch=BATCH_SIZE).to(device=device)\n",
    "gbrbm_second = RBM(n_vis=187, n_hid=HIDDEN_UNITS[4], k=K_FOLD, batch=BATCH_SIZE).to(device=device)\n",
    "gbrbm_third = RBM(n_vis=187, n_hid=HIDDEN_UNITS[5], k=K_FOLD, batch=BATCH_SIZE).to(device=device)\n",
    "\n",
    "first_train_op = optim.Adagrad(bbrbm_first.parameters(), LEARNING_RATE)\n",
    "second_train_op = optim.Adagrad(bbrbm_second.parameters(), LEARNING_RATE)\n",
    "third_train_op = optim.Adagrad(bbrbm_third.parameters(), LEARNING_RATE)\n",
    "\n",
    "gb_first_train_op = optim.Adagrad(gbrbm_first.parameters(), LEARNING_RATE)\n",
    "gb_second_train_op = optim.Adagrad(gbrbm_second.parameters(), LEARNING_RATE)\n",
    "gb_third_train_op = optim.Adagrad(gbrbm_third.parameters(), LEARNING_RATE)\n",
    "\n",
    "omse_loss = list()\n",
    "output_gb = list()\n",
    "best_acc = float()\n",
    "svm_best_acc = float()\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "# gaussian_std = torch.arange(1, 0, -0.00537, device=device)\n",
    "gaussian_std = torch.arange(1, 0, -0.0094, device=device)\n",
    "print(gaussian_std.size())\n",
    "\n",
    "svm_model = SVM(lr=LEARNING_RATE, n_x=107)\n",
    "svm_optimizer = optim.Adagrad(svm_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_6104/2187820300.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(data, dtype=torch.float32)\n",
      "c:\\Users\\HILAB_Labtop_02\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model:  ./say_cheese/ahh_saveMode_through_107_80.37383177570094GBRBM.pth\n",
      "Acc :  0.5023901600601568\n"
     ]
    }
   ],
   "source": [
    "LOAD_PATH = \"./say_cheese/ahh_saveMode_through_107_80.37383177570094GBRBM.pth\"\n",
    "\n",
    "load_model = RBM(n_vis=187, n_hid=120, k=K_FOLD, batch=BATCH_SIZE)\n",
    "load_model.load_state_dict((torch.load(LOAD_PATH)))\n",
    "load_model.to(device=device)\n",
    "\n",
    "for i, (data) in enumerate(test_dataloader):\n",
    "    if i == 939:\n",
    "        continue\n",
    "\n",
    "    data = Variable(\n",
    "            torch.tensor(data, dtype=torch.float32)\n",
    "    ).uniform_(0, 1)\n",
    "    \n",
    "    sample_data = torch.bernoulli(data).view(-1, 107).to(device=device)\n",
    "    \n",
    "    # tensor binary\n",
    "    vog_first, v1 = load_model(sample_data)\n",
    "    omse_loss = mse_loss(vog_first, v1)\n",
    "    \n",
    "    first_train_op.zero_grad()\n",
    "    first_train_op.step()\n",
    "    omse_loss.backward()\n",
    "\n",
    "print(\"Load model: \", LOAD_PATH)\n",
    "print(\"Acc : \", get_acc(vog_first, v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVM(\n",
       "  (fully): Linear(in_features=143, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_LOAD_PATH = \"./mat_svm_model/7_Train_svm_model_acc__.pth\"\n",
    "\n",
    "svm_model_load = SVM(lr=LEARNING_RATE, n_x=143)\n",
    "svm_model_load.load_state_dict(torch.load(SVM_LOAD_PATH))\n",
    "svm_model_load.to(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_6104/474829753.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  svm_X = torch.tensor(v1, dtype=torch.float32, device=device)\n",
      "C:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_6104/474829753.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(svm_X.clone().detach(), device=device)\n",
      "C:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_6104/474829753.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(svm_Y.clone().detach(), device=device)\n",
      "C:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_6104/474829753.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  predicted = torch.tensor(output.data >= 0, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Predicted:  tensor(0.0115, device='cuda:0') Accuracy:  tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "svm_X = torch.tensor(v1, dtype=torch.float32, device=device)\n",
    "svm_Y = torch.tensor(Y, dtype=torch.float32, device=device)\n",
    "N = len(svm_Y)\n",
    "\n",
    "# model predict\n",
    "for i in range(0, N, BATCH_SIZE):\n",
    "        correct = float()\n",
    "\n",
    "        x = torch.tensor(svm_X.clone().detach(), device=device)\n",
    "        y = torch.tensor(svm_Y.clone().detach(), device=device)\n",
    "\n",
    "        # Forward\n",
    "        output = svm_model(x)\n",
    "        \n",
    "        # Backward\n",
    "        svm_optimizer.zero_grad()        \n",
    "        svm_optimizer.step()\n",
    "\n",
    "        predicted = torch.tensor(output.data >= 0, dtype=torch.float32)\n",
    "        svm_acc = (output.data >= predicted).int()\n",
    "        \n",
    "print(\"SVM Model Predicted: \", predicted.sum() / predicted.size()[0], \"Accuracy: \", svm_acc.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.flatten(predicted, end_dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348\n"
     ]
    }
   ],
   "source": [
    "new_y = []\n",
    "# for val in np.array(torch.tensor(Y[:348]).unsqueeze(1)):\n",
    "for val in output.data:\n",
    "    max = 0\n",
    "    cnt = 0\n",
    "    for idx, num in enumerate(val):\n",
    "        if max < num.any():\n",
    "            max = num\n",
    "            cnt = idx + 1\n",
    "    new_y.append(cnt)\n",
    "print(len(new_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_pred = []\n",
    "for val in predicted:\n",
    "    max = 0\n",
    "    cnt = 0\n",
    "    for idx, num in enumerate(val):\n",
    "        if max < num:\n",
    "            max = num\n",
    "            cnt = idx + 1\n",
    "    new_y_pred.append(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "cm2 = confusion_matrix(new_y, new_y_pred)\n",
    "sns.heatmap(cm2, annot = True, fmt = 'd', cmap= 'Greens')\n",
    "plt.xlabel('predict')\n",
    "plt.ylabel('real')\n",
    "plt.xticks([0.5, 1.5], ['V', 'N, S, F'])\n",
    "plt.yticks([0.5, 1.5], ['V', 'N, S, F'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0],\n",
       "       [344,   4]], dtype=int64)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(new_y, new_y_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c3cabcf2f29820bdd7faae982b59d335e0d215fb5382d93f3312fa3292e9b7f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
