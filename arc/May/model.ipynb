{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 19:48:54.968343 model.py code start\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import torch.distributions.distribution as D\n",
    "import data.medain_filtering_class as mf\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from RBM import RBM\n",
    "from SVM import SVM\n",
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "\n",
    "print(datetime.datetime.now(), \"model.py code start\")\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "EPOCH = 90\n",
    "LEARNING_RATE = 0.2\n",
    "ANNEALING_RATE = 0.999\n",
    "VISIBLE_UNITS = [180, 200, 250]\n",
    "HIDDEN_UNITS = [80, 100, 120]\n",
    "K_FOLD = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODL] Model main code is starting....\n",
      "[INFO] Read train data, cross-vaildation data and test data from median filtering code\n",
      "[INFO] Read file and indexing start...\n",
      "[INFO]\tfinal_db1 direcotry found.\n",
      "......\t...................i\tCurrent_Index\tFrom_Index\n",
      "[IWIP]\tfinal_db1 reading... 0 0 200\n",
      "[IWIP]\tfinal_db1 reading... 1 200 400\n",
      "[IWIP]\tfinal_db1 reading... 2 400 600\n",
      "[IWIP]\tfinal_db1 reading... 3 600 800\n",
      "[IWIP]\tfinal_db1 reading... 4 800 1000\n",
      "[IWIP]\tfinal_db1 reading... 5 1000 1200\n",
      "[IWIP]\tfinal_db1 reading... 6 1200 1400\n",
      "[IWIP]\tfinal_db1 reading... 7 1400 1600\n",
      "[IWIP]\tfinal_db1 reading... 8 1600 1800\n",
      "[IWIP]\tfinal_db1 reading... 9 1800 2000\n",
      "[IWIP]\tfinal_db1 reading... 10 2000 2200\n",
      "[IWIP]\tfinal_db1 reading... 11 2200 2400\n",
      "[IWIP]\tfinal_db1 reading... 12 2400 2600\n",
      "[IWIP]\tfinal_db1 reading... 13 2600 2800\n",
      "[IWIP]\tfinal_db1 reading... 14 2800 3000\n",
      "[IWIP]\tfinal_db1 reading... 15 3000 3200\n",
      "[IWIP]\tfinal_db1 reading... 16 3200 3400\n",
      "[IWIP]\tfinal_db1 reading... 17 3400 3600\n",
      "[IWIP]\tfinal_db1 reading... 18 3600 3800\n",
      "[IWIP]\tfinal_db1 reading... 19 3800 4000\n",
      "[IWIP]\tfinal_db1 reading... 20 4000 4200\n",
      "[IWIP]\tfinal_db1 reading... 21 4200 4400\n",
      "[INFO]\tfinal_db2 direcotry found.\n",
      "....\t...................i Current_Index From_Index\n",
      "[IWIP]\tfinal_db2 reading... 0 4400 4600\n",
      "[ERRR]\t\t\t1th RECORD is not work. Maybe problem with columns stuff.\n",
      "[IWIP]\tfinal_db2 reading... 2 4600 4800\n",
      "[ERRR]\t\t\t3th RECORD is not work. Maybe problem with columns stuff.\n",
      "[IWIP]\tfinal_db2 reading... 4 4800 5000\n",
      "[IWIP]\tfinal_db2 reading... 5 5000 5200\n",
      "[IWIP]\tfinal_db2 reading... 6 5200 5400\n",
      "[IWIP]\tfinal_db2 reading... 7 5400 5600\n",
      "[IWIP]\tfinal_db2 reading... 8 5600 5800\n",
      "[IWIP]\tfinal_db2 reading... 9 5800 6000\n",
      "[IWIP]\tfinal_db2 reading... 10 6000 6200\n",
      "[IWIP]\tfinal_db2 reading... 11 6200 6400\n",
      "[IWIP]\tfinal_db2 reading... 12 6400 6600\n",
      "[IWIP]\tfinal_db2 reading... 13 6600 6800\n",
      "[IWIP]\tfinal_db2 reading... 14 6800 7000\n",
      "[IWIP]\tfinal_db2 reading... 15 7000 7200\n",
      "[IWIP]\tfinal_db2 reading... 16 7200 7400\n",
      "[IWIP]\tfinal_db2 reading... 17 7400 7600\n",
      "[IWIP]\tfinal_db2 reading... 18 7600 7800\n",
      "[IWIP]\tfinal_db2 reading... 19 7800 8000\n",
      "[IWIP]\tfinal_db2 reading... 20 8000 8200\n",
      "[IWIP]\tfinal_db2 reading... 21 8200 8400\n",
      "[IWIP]\tfinal_db2 reading... 22 8400 8600\n",
      "[IWIP]\tfinal_db2 reading... 23 8600 8800\n",
      "[IWIP]\tfinal_db2 reading... 24 8800 9000\n",
      "[IWIP]\tfinal_db2 reading... 25 9000 9200\n",
      "[INFO]\tfinal_db3 direcotry found.\n",
      "[INFO]\tfinal_db1 direcotry found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HILAB_Labtop_02\\anaconda3\\lib\\site-packages\\scipy\\signal\\signaltools.py:1531: UserWarning: kernel_size exceeds volume extent: the volume will be zero-padded.\n",
      "  warnings.warn('kernel_size exceeds volume extent: the volume will be '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]\tfinal_db2 direcotry found.\n",
      "[INFO]\tfinal_db3 direcotry found.\n",
      "[DONE] Pre-processing is done.\n"
     ]
    }
   ],
   "source": [
    "print(\"[MODL] Model main code is starting....\")\n",
    "\n",
    "print(\"[INFO] Read train data, cross-vaildation data and test data from median filtering code\")\n",
    "dataset_db1, dataset_db2 = mf.ecg_filtering(True)\n",
    "\n",
    "train_dataset = list(mf.list_to_list(dataset_db1)) * 4\n",
    "cross_dataset = list(mf.list_to_list(dataset_db2)) * 4\n",
    "test_dataset = list(mf.list_to_list(dataset_db2))  * 4\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    (train_dataset + cross_dataset), \n",
    "    (test_dataset + cross_dataset),\n",
    "    test_size=0.33,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train length :  6432\n",
      "X_test  length :  3168\n",
      "y_train length :  6432\n",
      "y_test  length :  3168\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(X_train + y_train,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(X_test + y_test,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True)\n",
    "\n",
    "print(\"X_train length : \", len(X_train))\n",
    "print(\"X_test  length : \", len(X_test))\n",
    "print(\"y_train length : \", len(y_train))\n",
    "print(\"y_test  length : \", len(y_test))\n",
    "\n",
    "train_data = torch.FloatTensor(X_train)\n",
    "test_data = torch.FloatTensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model object added\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Model object added\")\n",
    "\n",
    "rbm_first = RBM(n_vis=VISIBLE_UNITS[0], n_hid=HIDDEN_UNITS[0], k=K_FOLD, batch=BATCH_SIZE)\n",
    "rbm_second = RBM(n_vis=VISIBLE_UNITS[1], n_hid=HIDDEN_UNITS[1], k=K_FOLD, batch=BATCH_SIZE)\n",
    "rbm_third = RBM(n_vis=VISIBLE_UNITS[2], n_hid=HIDDEN_UNITS[2], k=K_FOLD, batch=BATCH_SIZE)\n",
    "\n",
    "# first_train_op = optim.SGD(rbm_first.parameters(), 0.1)\n",
    "# second_train_op = optim.SGD(rbm_second.parameters(), 0.1)\n",
    "# third_train_op = optim.SGD(rbm_third.parameters(), 0.1)\n",
    "\n",
    "# gb_first_train_op = optim.SGD(rbm_first.parameters(), 0.1)\n",
    "# gb_second_train_op = optim.SGD(rbm_second.parameters(), 0.1)\n",
    "# gb_third_train_op = optim.SGD(rbm_third.parameters(), 0.1)\n",
    "\n",
    "first_train_op = optim.Adagrad(rbm_first.parameters(), 0.1)\n",
    "second_train_op = optim.Adagrad(rbm_second.parameters(), 0.1)\n",
    "third_train_op = optim.Adagrad(rbm_third.parameters(), 0.1)\n",
    "\n",
    "gb_first_train_op = optim.Adagrad(rbm_first.parameters(), 0.1)\n",
    "gb_second_train_op = optim.Adagrad(rbm_second.parameters(), 0.1)\n",
    "gb_third_train_op = optim.Adagrad(rbm_third.parameters(), 0.1)\n",
    "\n",
    "output_from_first = list()\n",
    "output_from_second = list()\n",
    "output_from_third = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_9488/3670610706.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
      "c:\\Users\\HILAB_Labtop_02\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ST BBrbm_first Training loss for 0 epoch -0.10423406958580017\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 1 epoch -0.1129562109708786\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 2 epoch -0.14847776293754578\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 3 epoch -0.1572754681110382\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 4 epoch -0.11718638241291046\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 5 epoch -0.08992911875247955\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 6 epoch -0.10892117768526077\tEstimate time : 0:00:00.001051\n",
      "1ST BBrbm_first Training loss for 7 epoch -0.09430204331874847\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 8 epoch -0.0955905020236969\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 9 epoch -0.08443785458803177\tEstimate time : 0:00:00.000976\n",
      "1ST BBrbm_first Training loss for 10 epoch -0.09081360697746277\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 11 epoch -0.07697375863790512\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 12 epoch -0.08482848107814789\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 13 epoch -0.06735281646251678\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 14 epoch -0.0851837545633316\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 15 epoch -0.088283471763134\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 16 epoch -0.09150761365890503\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 17 epoch -0.10247178375720978\tEstimate time : 0:00:00.000996\n",
      "1ST BBrbm_first Training loss for 18 epoch -0.09700348228216171\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 19 epoch -0.11176161468029022\tEstimate time : 0:00:00.000999\n",
      "1ST BBrbm_first Training loss for 20 epoch -0.12478554993867874\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 21 epoch -0.1467800885438919\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 22 epoch -0.14841093122959137\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 23 epoch -0.14269804954528809\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 24 epoch -0.14466029405593872\tEstimate time : 0:00:00.000997\n",
      "1ST BBrbm_first Training loss for 25 epoch -0.13798773288726807\tEstimate time : 0:00:00.001001\n",
      "1ST BBrbm_first Training loss for 26 epoch -0.13741403818130493\tEstimate time : 0:00:00.000995\n",
      "1ST BBrbm_first Training loss for 27 epoch -0.12527261674404144\tEstimate time : 0:00:00.000997\n",
      "1ST BBrbm_first Training loss for 28 epoch -0.13338527083396912\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 29 epoch -0.1335160881280899\tEstimate time : 0:00:00.000997\n",
      "1ST BBrbm_first Training loss for 30 epoch -0.12842780351638794\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 31 epoch -0.11982396245002747\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 32 epoch -0.12143650650978088\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 33 epoch -0.12200995534658432\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 34 epoch -0.1167227029800415\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 35 epoch -0.10448693484067917\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 36 epoch -0.10287570208311081\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 37 epoch -0.10532921552658081\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 38 epoch -0.0920240581035614\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 39 epoch -0.08517780900001526\tEstimate time : 0:00:00.001006\n",
      "1ST BBrbm_first Training loss for 40 epoch -0.0793667733669281\tEstimate time : 0:00:00.000998\n",
      "1ST BBrbm_first Training loss for 41 epoch -0.08924271911382675\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 42 epoch -0.08168020099401474\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 43 epoch -0.07502369582653046\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 44 epoch -0.07672623544931412\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 45 epoch -0.07318920642137527\tEstimate time : 0:00:00.000997\n",
      "1ST BBrbm_first Training loss for 46 epoch -0.07007496803998947\tEstimate time : 0:00:00.000996\n",
      "1ST BBrbm_first Training loss for 47 epoch -0.06844211369752884\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 48 epoch -0.06464532017707825\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 49 epoch -0.06711829453706741\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 50 epoch -0.062467653304338455\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 51 epoch -0.07191057503223419\tEstimate time : 0:00:00.000997\n",
      "1ST BBrbm_first Training loss for 52 epoch -0.07433315366506577\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 53 epoch -0.07143010199069977\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 54 epoch -0.07341690361499786\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 55 epoch -0.07887262105941772\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 56 epoch -0.07606344670057297\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 57 epoch -0.07042068243026733\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 58 epoch -0.07482276856899261\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 59 epoch -0.07573460042476654\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 60 epoch -0.07430905103683472\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 61 epoch -0.07326742261648178\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 62 epoch -0.07147025316953659\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 63 epoch -0.07062716037034988\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 64 epoch -0.07077617943286896\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 65 epoch -0.06997015327215195\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 66 epoch -0.0695406049489975\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 67 epoch -0.06816086173057556\tEstimate time : 0:00:00.001041\n",
      "1ST BBrbm_first Training loss for 68 epoch -0.06157635897397995\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 69 epoch -0.058289557695388794\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 70 epoch -0.05912972614169121\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 71 epoch -0.0550098717212677\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 72 epoch -0.053089458495378494\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 73 epoch -0.05639068782329559\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 74 epoch -0.05631916970014572\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 75 epoch -0.0581975132226944\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 76 epoch -0.053564511239528656\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 77 epoch -0.05678866431117058\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 78 epoch -0.05744680389761925\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 79 epoch -0.05685178190469742\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 80 epoch -0.05743400752544403\tEstimate time : 0:00:00.000994\n",
      "1ST BBrbm_first Training loss for 81 epoch -0.05417728051543236\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 82 epoch -0.05379876494407654\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 83 epoch -0.05801912397146225\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 84 epoch -0.05822957679629326\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 85 epoch -0.05647128447890282\tEstimate time : 0:00:00.000996\n",
      "1ST BBrbm_first Training loss for 86 epoch -0.0569978728890419\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 87 epoch -0.05947857350111008\tEstimate time : 0:00:00.000997\n",
      "1ST BBrbm_first Training loss for 88 epoch -0.0632559135556221\tEstimate time : 0:00:00\n",
      "1ST BBrbm_first Training loss for 89 epoch -0.059328943490982056\tEstimate time : 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_9488/3670610706.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ST BBrbm_first Training loss for 0 epoch -0.05965328961610794\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 1 epoch -0.05970938503742218\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 2 epoch -0.05966382473707199\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 3 epoch -0.06029503792524338\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 4 epoch -0.06029493734240532\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 5 epoch -0.06062810868024826\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 6 epoch -0.06083003804087639\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 7 epoch -0.0606277771294117\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 8 epoch -0.060756292194128036\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 9 epoch -0.06146038696169853\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 10 epoch -0.061489831656217575\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 11 epoch -0.062301356345415115\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 12 epoch -0.06272821873426437\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 13 epoch -0.06289342790842056\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 14 epoch -0.06287744641304016\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 15 epoch -0.0630449652671814\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 16 epoch -0.06280956417322159\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 17 epoch -0.06244905665516853\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 18 epoch -0.06275986135005951\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 19 epoch -0.06256276369094849\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 20 epoch -0.06269384175539017\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 21 epoch -0.06282641738653183\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 22 epoch -0.06392762809991837\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 23 epoch -0.06381795555353165\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 24 epoch -0.06359294801950455\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 25 epoch -0.06289929896593094\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 26 epoch -0.06222310662269592\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 27 epoch -0.06235486641526222\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 28 epoch -0.06235982105135918\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 29 epoch -0.06258571892976761\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 30 epoch -0.06259076297283173\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 31 epoch -0.06325270980596542\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 32 epoch -0.0637764111161232\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 33 epoch -0.06409460306167603\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 34 epoch -0.06461615115404129\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 35 epoch -0.0641292855143547\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 36 epoch -0.06382422149181366\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 37 epoch -0.06480064243078232\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 38 epoch -0.06472858041524887\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 39 epoch -0.06477724760770798\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 40 epoch -0.0641290694475174\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 41 epoch -0.0639202669262886\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 42 epoch -0.06482402235269547\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 43 epoch -0.06473219394683838\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 44 epoch -0.06396511942148209\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 45 epoch -0.06391530483961105\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 46 epoch -0.06382545828819275\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 47 epoch -0.06454938650131226\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 48 epoch -0.06461907923221588\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 49 epoch -0.0648103728890419\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 50 epoch -0.06471943855285645\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 51 epoch -0.06481025367975235\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 52 epoch -0.06459863483905792\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 53 epoch -0.06487058848142624\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 54 epoch -0.06453778594732285\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 55 epoch -0.06442750990390778\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 56 epoch -0.06443765759468079\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 57 epoch -0.06497299671173096\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 58 epoch -0.0648614838719368\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 59 epoch -0.065403051674366\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 60 epoch -0.06636864691972733\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 61 epoch -0.06673829257488251\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 62 epoch -0.06702554225921631\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 63 epoch -0.06752954423427582\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 64 epoch -0.0680818110704422\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 65 epoch -0.06826847046613693\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 66 epoch -0.06843416392803192\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 67 epoch -0.0690188780426979\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 68 epoch -0.06817673146724701\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 69 epoch -0.06847315281629562\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 70 epoch -0.0691913515329361\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 71 epoch -0.06936073303222656\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 72 epoch -0.06973154842853546\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 73 epoch -0.06956677883863449\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 74 epoch -0.06975987553596497\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 75 epoch -0.06903932243585587\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 76 epoch -0.06931941956281662\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 77 epoch -0.06913363933563232\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 78 epoch -0.07024408131837845\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 79 epoch -0.07082538306713104\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 80 epoch -0.07061290740966797\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 81 epoch -0.07078707963228226\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 82 epoch -0.0707111805677414\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 83 epoch -0.07081669569015503\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 84 epoch -0.0714726522564888\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 85 epoch -0.07107452303171158\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 86 epoch -0.07205742597579956\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 87 epoch -0.07216561585664749\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 88 epoch -0.07276496291160583\tEstimate time : \n",
      "2ST BBrbm_first Training loss for 89 epoch -0.07398543506860733\tEstimate time : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_9488/3670610706.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3ST BBrbm_first Training loss for 0 epoch -0.07462213188409805\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 1 epoch -0.07476483285427094\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 2 epoch -0.07530436664819717\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 3 epoch -0.0751611664891243\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 4 epoch -0.07506802678108215\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 5 epoch -0.07524630427360535\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 6 epoch -0.07533258944749832\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 7 epoch -0.07511084526777267\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 8 epoch -0.07521293312311172\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 9 epoch -0.0752677321434021\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 10 epoch -0.07562724500894547\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 11 epoch -0.07572095841169357\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 12 epoch -0.07595566660165787\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 13 epoch -0.07519438862800598\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 14 epoch -0.0748550295829773\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 15 epoch -0.0753822922706604\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 16 epoch -0.0761948898434639\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 17 epoch -0.07644212990999222\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 18 epoch -0.0769876018166542\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 19 epoch -0.07700364291667938\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 20 epoch -0.07700119912624359\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 21 epoch -0.07644552737474442\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 22 epoch -0.07739236205816269\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 23 epoch -0.07691990584135056\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 24 epoch -0.07658346742391586\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 25 epoch -0.0760689452290535\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 26 epoch -0.07622984796762466\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 27 epoch -0.07711943238973618\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 28 epoch -0.07728894799947739\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 29 epoch -0.07740351557731628\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 30 epoch -0.07776859402656555\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 31 epoch -0.07802183926105499\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 32 epoch -0.07773043215274811\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 33 epoch -0.07782847434282303\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 34 epoch -0.07816218584775925\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 35 epoch -0.07771266996860504\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 36 epoch -0.0776161476969719\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 37 epoch -0.07806683331727982\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 38 epoch -0.07785143703222275\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 39 epoch -0.07769685983657837\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 40 epoch -0.07682917267084122\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 41 epoch -0.07688707113265991\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 42 epoch -0.07654522359371185\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 43 epoch -0.0774872750043869\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 44 epoch -0.07752779126167297\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 45 epoch -0.07847711443901062\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 46 epoch -0.07850001752376556\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 47 epoch -0.07810425013303757\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 48 epoch -0.07812685519456863\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 49 epoch -0.07822887599468231\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 50 epoch -0.07797319442033768\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 51 epoch -0.07765986025333405\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 52 epoch -0.0773487538099289\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 53 epoch -0.07766555994749069\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 54 epoch -0.07814396917819977\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 55 epoch -0.07826701551675797\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 56 epoch -0.0789552852511406\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 57 epoch -0.07877687364816666\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 58 epoch -0.07937115430831909\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 59 epoch -0.07900775969028473\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 60 epoch -0.07919560372829437\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 61 epoch -0.07942570000886917\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 62 epoch -0.0791846290230751\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 63 epoch -0.07955845445394516\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 64 epoch -0.08035267144441605\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 65 epoch -0.08019069582223892\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 66 epoch -0.08038441091775894\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 67 epoch -0.08026415854692459\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 68 epoch -0.0799141377210617\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 69 epoch -0.0795665830373764\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 70 epoch -0.07955105602741241\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 71 epoch -0.07951433211565018\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 72 epoch -0.07925176620483398\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 73 epoch -0.0787857249379158\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 74 epoch -0.07856689393520355\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 75 epoch -0.07895989716053009\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 76 epoch -0.07756878435611725\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 77 epoch -0.07723487168550491\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 78 epoch -0.07694258540868759\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 79 epoch -0.07678967714309692\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 80 epoch -0.07667631655931473\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 81 epoch -0.07685868442058563\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 82 epoch -0.07710124552249908\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 83 epoch -0.07714592665433884\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 84 epoch -0.07703197002410889\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 85 epoch -0.0767010971903801\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 86 epoch -0.07664694637060165\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 87 epoch -0.07637681066989899\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 88 epoch -0.07589352130889893\tEstimate time : \n",
      "3ST BBrbm_first Training loss for 89 epoch -0.07593777030706406\tEstimate time : \n"
     ]
    }
   ],
   "source": [
    "'''Train Part'''\n",
    "\n",
    "loss_ = []\n",
    "for epoch in range(EPOCH):\n",
    "    '''First bbrbm'''\n",
    "    for _, (data) in enumerate(train_dataloader):\n",
    "        try:\n",
    "            # tnesor float\n",
    "            data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "\n",
    "        sample_data = torch.bernoulli(data)\n",
    "        sample_data = torch.flatten(sample_data.clone())\n",
    "\n",
    "        # tensor binary\n",
    "        vog_first, v1, mt = rbm_first(sample_data)\n",
    "        \n",
    "        loss_first = rbm_first.free_energy(vog_first) - rbm_first.free_energy(v1)\n",
    "        loss_.append(loss_first.data)\n",
    "        \n",
    "        first_train_op.zero_grad()\n",
    "        loss_first.backward()\n",
    "        first_train_op.step()\n",
    "    \n",
    "    output_from_first.append(v1.tolist())\n",
    "    print(\"1ST BBrbm_first Training loss for {0} epoch {1}\\tEstimate time : {2}\".format(epoch, np.mean(loss_), mt))\n",
    "\n",
    "output_from_first = torch.tensor(output_from_first)\n",
    "for epoch in range(EPOCH):\n",
    "    '''Secnd bbrbm'''\n",
    "    for _, (data) in enumerate(output_from_first):\n",
    "        try:\n",
    "            data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "\n",
    "        sample_data = torch.bernoulli(data)\n",
    "        sample_data = torch.flatten(sample_data.clone())\n",
    "\n",
    "        vog_second, v2, mt = rbm_second(sample_data)\n",
    "        \n",
    "        loss_second = rbm_second.free_energy(vog_second) - rbm_second.free_energy(v2)\n",
    "        loss_.append(loss_second.data)\n",
    "        \n",
    "        second_train_op.zero_grad()\n",
    "        loss_second.backward()\n",
    "        second_train_op.step()\n",
    "\n",
    "    output_from_second.append(v2.tolist())\n",
    "    print(\"2ST BBrbm_first Training loss for {0} epoch {1}\\tEstimate time : \".format(epoch, np.mean(loss_), mt))\n",
    "\n",
    "output_from_second = torch.tensor(output_from_second)\n",
    "for epoch in range(EPOCH):\n",
    "    '''Third bbrbm'''\n",
    "    for _, (data) in enumerate(output_from_second):\n",
    "        try:\n",
    "            data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "\n",
    "        sample_data = torch.bernoulli(data)\n",
    "        sample_data = torch.flatten(sample_data.clone())\n",
    "\n",
    "        vog_third, v3, mt = rbm_third(sample_data)\n",
    "        \n",
    "        loss_third = rbm_third.free_energy(vog_third) - rbm_third.free_energy(v3)\n",
    "        loss_.append(loss_third.data)\n",
    "        \n",
    "        third_train_op.zero_grad()\n",
    "        loss_third.backward()\n",
    "        third_train_op.step()\n",
    "\n",
    "    output_from_third.append(v3.tolist())\n",
    "    print(\"3ST BBrbm_first Training loss for {0} epoch {1}\\tEstimate time : \".format(epoch, np.mean(loss_), mt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBRBM is done.\n",
      "GBRBM is start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_9488/2809123372.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ST GBrbm_first Training loss for 0 epoch -0.07587048411369324\tEstimate time : 0:00:00.000996\n",
      "1ST GBrbm_first Training loss for 1 epoch -0.07580403238534927\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 2 epoch -0.0757375955581665\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 3 epoch -0.07567139714956284\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 4 epoch -0.07560500502586365\tEstimate time : 0:00:00.000997\n",
      "1ST GBrbm_first Training loss for 5 epoch -0.07554247975349426\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 6 epoch -0.07547547668218613\tEstimate time : 0:00:00.001001\n",
      "1ST GBrbm_first Training loss for 7 epoch -0.07541342824697495\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 8 epoch -0.07534836232662201\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 9 epoch -0.07528682053089142\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 10 epoch -0.07522326707839966\tEstimate time : 0:00:00.000998\n",
      "1ST GBrbm_first Training loss for 11 epoch -0.07515770196914673\tEstimate time : 0:00:00.000996\n",
      "1ST GBrbm_first Training loss for 12 epoch -0.07509243488311768\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 13 epoch -0.07502754777669907\tEstimate time : 0:00:00.000997\n",
      "1ST GBrbm_first Training loss for 14 epoch -0.07496437430381775\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 15 epoch -0.07490339130163193\tEstimate time : 0:00:00.000993\n",
      "1ST GBrbm_first Training loss for 16 epoch -0.07483451813459396\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 17 epoch -0.07477004081010818\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 18 epoch -0.07470446079969406\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 19 epoch -0.07463790476322174\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 20 epoch -0.07457034289836884\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 21 epoch -0.0745043084025383\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 22 epoch -0.07443686574697495\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 23 epoch -0.07437173277139664\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 24 epoch -0.07430246472358704\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 25 epoch -0.07423990219831467\tEstimate time : 0:00:00.001003\n",
      "1ST GBrbm_first Training loss for 26 epoch -0.07417688518762589\tEstimate time : 0:00:00.000997\n",
      "1ST GBrbm_first Training loss for 27 epoch -0.0741109624505043\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 28 epoch -0.0740438774228096\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 29 epoch -0.07398086786270142\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 30 epoch -0.07391577959060669\tEstimate time : 0:00:00.000996\n",
      "1ST GBrbm_first Training loss for 31 epoch -0.07384943217039108\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 32 epoch -0.07378364354372025\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 33 epoch -0.07371890544891357\tEstimate time : 0:00:00.001044\n",
      "1ST GBrbm_first Training loss for 34 epoch -0.07365304976701736\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 35 epoch -0.07359068840742111\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 36 epoch -0.0735258013010025\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 37 epoch -0.07346045970916748\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 38 epoch -0.07339593023061752\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 39 epoch -0.07332759350538254\tEstimate time : 0:00:00.000997\n",
      "1ST GBrbm_first Training loss for 40 epoch -0.07326354086399078\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 41 epoch -0.0731997862458229\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 42 epoch -0.07314027845859528\tEstimate time : 0:00:00.000993\n",
      "1ST GBrbm_first Training loss for 43 epoch -0.07307569682598114\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 44 epoch -0.07301288098096848\tEstimate time : 0:00:00.001018\n",
      "1ST GBrbm_first Training loss for 45 epoch -0.07294876128435135\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 46 epoch -0.07288819551467896\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 47 epoch -0.07282180339097977\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 48 epoch -0.07276132702827454\tEstimate time : 0:00:00.000999\n",
      "1ST GBrbm_first Training loss for 49 epoch -0.0727008506655693\tEstimate time : 0:00:00.000998\n",
      "1ST GBrbm_first Training loss for 50 epoch -0.07263511419296265\tEstimate time : 0:00:00.000999\n",
      "1ST GBrbm_first Training loss for 51 epoch -0.07256985455751419\tEstimate time : 0:00:00.000996\n",
      "1ST GBrbm_first Training loss for 52 epoch -0.0725085437297821\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 53 epoch -0.07244601845741272\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 54 epoch -0.07238399982452393\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 55 epoch -0.07232248783111572\tEstimate time : 0:00:00.000999\n",
      "1ST GBrbm_first Training loss for 56 epoch -0.07225851714611053\tEstimate time : 0:00:00.001000\n",
      "1ST GBrbm_first Training loss for 57 epoch -0.07219669222831726\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 58 epoch -0.07213254272937775\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 59 epoch -0.07207079231739044\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 60 epoch -0.07201383262872696\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 61 epoch -0.07194823026657104\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 62 epoch -0.0718841627240181\tEstimate time : 0:00:00.000995\n",
      "1ST GBrbm_first Training loss for 63 epoch -0.07182526588439941\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 64 epoch -0.07176360487937927\tEstimate time : 0:00:00.000980\n",
      "1ST GBrbm_first Training loss for 65 epoch -0.07170403003692627\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 66 epoch -0.07164403796195984\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 67 epoch -0.07158147543668747\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 68 epoch -0.07151731848716736\tEstimate time : 0:00:00.000997\n",
      "1ST GBrbm_first Training loss for 69 epoch -0.0714515820145607\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 70 epoch -0.07139363139867783\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 71 epoch -0.07133350521326065\tEstimate time : 0:00:00.000997\n",
      "1ST GBrbm_first Training loss for 72 epoch -0.07127638161182404\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 73 epoch -0.07121311128139496\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 74 epoch -0.07115329056978226\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 75 epoch -0.07109193503856659\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 76 epoch -0.07103481888771057\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 77 epoch -0.0709751546382904\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 78 epoch -0.07091759145259857\tEstimate time : 0:00:00.000997\n",
      "1ST GBrbm_first Training loss for 79 epoch -0.07085856795310974\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 80 epoch -0.07079605013132095\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 81 epoch -0.07073210924863815\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 82 epoch -0.07066972553730011\tEstimate time : 0:00:00.000997\n",
      "1ST GBrbm_first Training loss for 83 epoch -0.07061079144477844\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 84 epoch -0.07054950296878815\tEstimate time : 0:00:00.000997\n",
      "1ST GBrbm_first Training loss for 85 epoch -0.07048631459474564\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 86 epoch -0.07042722404003143\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 87 epoch -0.07036632299423218\tEstimate time : 0:00:00.000995\n",
      "1ST GBrbm_first Training loss for 88 epoch -0.07030259072780609\tEstimate time : 0:00:00\n",
      "1ST GBrbm_first Training loss for 89 epoch -0.07024438679218292\tEstimate time : 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_9488/2809123372.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ST GBrbm_first Training loss for 0 epoch -0.07019393891096115\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 1 epoch -0.07014285027980804\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 2 epoch -0.0700925812125206\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 3 epoch -0.07004337757825851\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 4 epoch -0.06999409943819046\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 5 epoch -0.06994382292032242\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 6 epoch -0.06989458203315735\tEstimate time : 0:00:00.001000\n",
      "2ST GBrbm_first Training loss for 7 epoch -0.06984402239322662\tEstimate time : 0:00:00.001002\n",
      "2ST GBrbm_first Training loss for 8 epoch -0.0697929635643959\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 9 epoch -0.06974325329065323\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 10 epoch -0.06969403475522995\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 11 epoch -0.06964488327503204\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 12 epoch -0.06959503889083862\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 13 epoch -0.06954511255025864\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 14 epoch -0.0694962814450264\tEstimate time : 0:00:00.000997\n",
      "2ST GBrbm_first Training loss for 15 epoch -0.06944756209850311\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 16 epoch -0.06939913332462311\tEstimate time : 0:00:00.000996\n",
      "2ST GBrbm_first Training loss for 17 epoch -0.06934912502765656\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 18 epoch -0.06930156797170639\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 19 epoch -0.06925304234027863\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 20 epoch -0.06920474022626877\tEstimate time : 0:00:00.000997\n",
      "2ST GBrbm_first Training loss for 21 epoch -0.06915581971406937\tEstimate time : 0:00:00.000997\n",
      "2ST GBrbm_first Training loss for 22 epoch -0.0691061019897461\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 23 epoch -0.06905627250671387\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 24 epoch -0.06900810450315475\tEstimate time : 0:00:00.000996\n",
      "2ST GBrbm_first Training loss for 25 epoch -0.0689597949385643\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 26 epoch -0.0689115822315216\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 27 epoch -0.06886409223079681\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 28 epoch -0.06881535053253174\tEstimate time : 0:00:00.000997\n",
      "2ST GBrbm_first Training loss for 29 epoch -0.06876657158136368\tEstimate time : 0:00:00.000992\n",
      "2ST GBrbm_first Training loss for 30 epoch -0.06871870160102844\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 31 epoch -0.06867017596960068\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 32 epoch -0.06862057000398636\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 33 epoch -0.06857166439294815\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 34 epoch -0.06852337718009949\tEstimate time : 0:00:00.000997\n",
      "2ST GBrbm_first Training loss for 35 epoch -0.06847570091485977\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 36 epoch -0.06842789798974991\tEstimate time : 0:00:00.000997\n",
      "2ST GBrbm_first Training loss for 37 epoch -0.06837973743677139\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 38 epoch -0.0683329850435257\tEstimate time : 0:00:00.000997\n",
      "2ST GBrbm_first Training loss for 39 epoch -0.06828594207763672\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 40 epoch -0.06823857873678207\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 41 epoch -0.06819131225347519\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 42 epoch -0.06814239174127579\tEstimate time : 0:00:00.000992\n",
      "2ST GBrbm_first Training loss for 43 epoch -0.0680944174528122\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 44 epoch -0.06804758310317993\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 45 epoch -0.06799999624490738\tEstimate time : 0:00:00.000992\n",
      "2ST GBrbm_first Training loss for 46 epoch -0.06795236468315125\tEstimate time : 0:00:00.000996\n",
      "2ST GBrbm_first Training loss for 47 epoch -0.06790464371442795\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 48 epoch -0.06785782426595688\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 49 epoch -0.06781093776226044\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 50 epoch -0.06776256114244461\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 51 epoch -0.06771554052829742\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 52 epoch -0.06766827404499054\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 53 epoch -0.06762092560529709\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 54 epoch -0.06757242232561111\tEstimate time : 0:00:00.000994\n",
      "2ST GBrbm_first Training loss for 55 epoch -0.06752457469701767\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 56 epoch -0.06747625768184662\tEstimate time : 0:00:00.000994\n",
      "2ST GBrbm_first Training loss for 57 epoch -0.06742978096008301\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 58 epoch -0.06738395243883133\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 59 epoch -0.06733781099319458\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 60 epoch -0.06729187071323395\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 61 epoch -0.06724461913108826\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 62 epoch -0.06719758361577988\tEstimate time : 0:00:00.000998\n",
      "2ST GBrbm_first Training loss for 63 epoch -0.06715161353349686\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 64 epoch -0.06710436195135117\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 65 epoch -0.06705788522958755\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 66 epoch -0.06701144576072693\tEstimate time : 0:00:00.000992\n",
      "2ST GBrbm_first Training loss for 67 epoch -0.06696441024541855\tEstimate time : 0:00:00.001002\n",
      "2ST GBrbm_first Training loss for 68 epoch -0.06691839545965195\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 69 epoch -0.06687207520008087\tEstimate time : 0:00:00.000997\n",
      "2ST GBrbm_first Training loss for 70 epoch -0.06682679057121277\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 71 epoch -0.0667802020907402\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 72 epoch -0.06673316657543182\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 73 epoch -0.06668797880411148\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 74 epoch -0.06664174050092697\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 75 epoch -0.06659521907567978\tEstimate time : 0:00:00.001055\n",
      "2ST GBrbm_first Training loss for 76 epoch -0.06654897332191467\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 77 epoch -0.0665040910243988\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 78 epoch -0.06645861268043518\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 79 epoch -0.06641379743814468\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 80 epoch -0.06636931747198105\tEstimate time : 0:00:00.000995\n",
      "2ST GBrbm_first Training loss for 81 epoch -0.0663238987326622\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 82 epoch -0.06627880036830902\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 83 epoch -0.06623376160860062\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 84 epoch -0.06618838757276535\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 85 epoch -0.066143698990345\tEstimate time : 0:00:00.000965\n",
      "2ST GBrbm_first Training loss for 86 epoch -0.06609877198934555\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 87 epoch -0.06605227291584015\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 88 epoch -0.06600704044103622\tEstimate time : 0:00:00\n",
      "2ST GBrbm_first Training loss for 89 epoch -0.06596262753009796\tEstimate time : 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_9488/2809123372.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3ST GBrbm_first Training loss for 0 epoch -0.06586959958076477\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 1 epoch -0.06578019261360168\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 2 epoch -0.06569096446037292\tEstimate time : 0:00:00.001020\n",
      "3ST GBrbm_first Training loss for 3 epoch -0.06560123711824417\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 4 epoch -0.06551044434309006\tEstimate time : 0:00:00.001000\n",
      "3ST GBrbm_first Training loss for 5 epoch -0.06541945040225983\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 6 epoch -0.0653304010629654\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 7 epoch -0.06523957848548889\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 8 epoch -0.06515282392501831\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 9 epoch -0.06506530940532684\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 10 epoch -0.06497836858034134\tEstimate time : 0:00:00.000997\n",
      "3ST GBrbm_first Training loss for 11 epoch -0.06488896906375885\tEstimate time : 0:00:00.000998\n",
      "3ST GBrbm_first Training loss for 12 epoch -0.06479863822460175\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 13 epoch -0.06471079587936401\tEstimate time : 0:00:00.000999\n",
      "3ST GBrbm_first Training loss for 14 epoch -0.06462264060974121\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 15 epoch -0.06453681737184525\tEstimate time : 0:00:00.000993\n",
      "3ST GBrbm_first Training loss for 16 epoch -0.06444726884365082\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 17 epoch -0.06436142325401306\tEstimate time : 0:00:00.000996\n",
      "3ST GBrbm_first Training loss for 18 epoch -0.06426981836557388\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 19 epoch -0.06418365240097046\tEstimate time : 0:00:00.000998\n",
      "3ST GBrbm_first Training loss for 20 epoch -0.06409405916929245\tEstimate time : 0:00:00.000996\n",
      "3ST GBrbm_first Training loss for 21 epoch -0.06400859355926514\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 22 epoch -0.06392114609479904\tEstimate time : 0:00:00.000996\n",
      "3ST GBrbm_first Training loss for 23 epoch -0.06383492052555084\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 24 epoch -0.06374483555555344\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 25 epoch -0.06365462392568588\tEstimate time : 0:00:00.000996\n",
      "3ST GBrbm_first Training loss for 26 epoch -0.06356891244649887\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 27 epoch -0.06348295509815216\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 28 epoch -0.06339537352323532\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 29 epoch -0.06330636143684387\tEstimate time : 0:00:00.000997\n",
      "3ST GBrbm_first Training loss for 30 epoch -0.06321853399276733\tEstimate time : 0:00:00.000997\n",
      "3ST GBrbm_first Training loss for 31 epoch -0.06313358247280121\tEstimate time : 0:00:00.001001\n",
      "3ST GBrbm_first Training loss for 32 epoch -0.06304735690355301\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 33 epoch -0.06295950710773468\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 34 epoch -0.06287537515163422\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 35 epoch -0.06278577446937561\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 36 epoch -0.06269741803407669\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 37 epoch -0.06261217594146729\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 38 epoch -0.062528595328331\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 39 epoch -0.06244305521249771\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 40 epoch -0.0623585470020771\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 41 epoch -0.06227467581629753\tEstimate time : 0:00:00.000997\n",
      "3ST GBrbm_first Training loss for 42 epoch -0.062190692871809006\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 43 epoch -0.06210434064269066\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 44 epoch -0.06202090159058571\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 45 epoch -0.06193545088171959\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 46 epoch -0.061847977340221405\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 47 epoch -0.06176290288567543\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 48 epoch -0.06167704239487648\tEstimate time : 0:00:00.000997\n",
      "3ST GBrbm_first Training loss for 49 epoch -0.061594292521476746\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 50 epoch -0.06151064485311508\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 51 epoch -0.06142604351043701\tEstimate time : 0:00:00.002989\n",
      "3ST GBrbm_first Training loss for 52 epoch -0.061339735984802246\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 53 epoch -0.06125359237194061\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 54 epoch -0.061172980815172195\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 55 epoch -0.06108847260475159\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 56 epoch -0.06100419536232948\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 57 epoch -0.06092296168208122\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 58 epoch -0.06083975359797478\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 59 epoch -0.06075584888458252\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 60 epoch -0.06067263334989548\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 61 epoch -0.060588475316762924\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 62 epoch -0.060505371540784836\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 63 epoch -0.06042279675602913\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 64 epoch -0.06034158542752266\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 65 epoch -0.060255635529756546\tEstimate time : 0:00:00.000996\n",
      "3ST GBrbm_first Training loss for 66 epoch -0.06016943231225014\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 67 epoch -0.060085639357566833\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 68 epoch -0.05999996140599251\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 69 epoch -0.05991619452834129\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 70 epoch -0.059832826256752014\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 71 epoch -0.0597459077835083\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 72 epoch -0.05966399237513542\tEstimate time : 0:00:00.000996\n",
      "3ST GBrbm_first Training loss for 73 epoch -0.05957816168665886\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 74 epoch -0.05949493870139122\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 75 epoch -0.05941103771328926\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 76 epoch -0.0593286007642746\tEstimate time : 0:00:00.000997\n",
      "3ST GBrbm_first Training loss for 77 epoch -0.059248968958854675\tEstimate time : 0:00:00.000996\n",
      "3ST GBrbm_first Training loss for 78 epoch -0.059165507555007935\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 79 epoch -0.059084538370370865\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 80 epoch -0.05900217592716217\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 81 epoch -0.05891929566860199\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 82 epoch -0.05883587896823883\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 83 epoch -0.058748744428157806\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 84 epoch -0.058664243668317795\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 85 epoch -0.058582328259944916\tEstimate time : 0:00:00.001143\n",
      "3ST GBrbm_first Training loss for 86 epoch -0.05850087106227875\tEstimate time : 0:00:00.000997\n",
      "3ST GBrbm_first Training loss for 87 epoch -0.05841829255223274\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 88 epoch -0.058338463306427\tEstimate time : 0:00:00\n",
      "3ST GBrbm_first Training loss for 89 epoch -0.058255746960639954\tEstimate time : 0:00:00\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "print(\"BBRBM is done.\")\n",
    "print(\"GBRBM is start\")\n",
    "\n",
    "output_from_first = list()\n",
    "output_from_second = list()\n",
    "output_from_third = torch.tensor(output_from_third)\n",
    "\n",
    "rbm_first = RBM(n_vis=VISIBLE_UNITS[0], n_hid=HIDDEN_UNITS[0], k=K_FOLD, batch=BATCH_SIZE)\n",
    "rbm_second = RBM(n_vis=VISIBLE_UNITS[1], n_hid=HIDDEN_UNITS[1], k=K_FOLD, batch=BATCH_SIZE)\n",
    "rbm_third = RBM(n_vis=VISIBLE_UNITS[2], n_hid=HIDDEN_UNITS[2], k=K_FOLD, batch=BATCH_SIZE)\n",
    "\n",
    "# print(output_from_third.size(), output_from_third.dim(), \"\\n\", output_from_third)\n",
    "gaussian_std = torch.arange(1, 0, -0.1)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    '''First gbrbm'''\n",
    "    for _, (data) in enumerate(output_from_third):\n",
    "        try:\n",
    "            data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "        \n",
    "        # CHANGED to GAUSSIAN\n",
    "        sample_data = torch.normal(mean=data, std=gaussian_std)\n",
    "        sample_data = torch.flatten(sample_data.clone())\n",
    "\n",
    "        gb_vog_first, gb_v1, mt = rbm_first(sample_data)\n",
    "        \n",
    "        gb_loss_first = rbm_first.free_energy(gb_vog_first) - rbm_first.free_energy(gb_v1)\n",
    "        loss_.append(gb_loss_first.data)\n",
    "        \n",
    "        gb_first_train_op.zero_grad()\n",
    "        gb_loss_first.backward()\n",
    "        gb_first_train_op.step()\n",
    "\n",
    "    output_from_first.append(gb_v1.tolist())\n",
    "    print(\"1ST GBrbm_first Training loss for {0} epoch {1}\\tEstimate time : {2}\".format(epoch, np.mean(loss_), mt))\n",
    "\n",
    "output_from_first = torch.tensor(output_from_first)\n",
    "for epoch in range(EPOCH):\n",
    "    '''Second gbrbm'''\n",
    "    for _, (data) in enumerate(output_from_first):\n",
    "        try:\n",
    "            data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "        \n",
    "        # CHANGED to GAUSSIAN\n",
    "        sample_data = torch.normal(mean=data, std=gaussian_std)\n",
    "        sample_data = torch.flatten(sample_data.clone())\n",
    "\n",
    "        gb_vog_second, gb_v2, mt = rbm_second(sample_data)\n",
    "        \n",
    "        gb_loss_second = rbm_second.free_energy(gb_vog_second) - rbm_second.free_energy(gb_v2)\n",
    "        loss_.append(gb_loss_second.data)\n",
    "        \n",
    "        gb_second_train_op.zero_grad()\n",
    "        gb_loss_second.backward()\n",
    "        gb_second_train_op.step()\n",
    "\n",
    "    output_from_second.append(gb_v2.tolist())\n",
    "    print(\"2ST GBrbm_first Training loss for {0} epoch {1}\\tEstimate time : {2}\".format(epoch, np.mean(loss_), mt))\n",
    "\n",
    "output_from_second = torch.tensor(output_from_second)\n",
    "for epoch in range(EPOCH):\n",
    "    '''Third gbrbm'''\n",
    "    for _, (data) in enumerate(output_from_second):\n",
    "        try:\n",
    "            data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "        \n",
    "        # CHANGED to GAUSSIAN\n",
    "        sample_data = torch.normal(mean=data, std=gaussian_std)\n",
    "        sample_data = torch.flatten(sample_data.clone())\n",
    "\n",
    "        gb_vog_third, gb_v3, mt = rbm_third(sample_data)\n",
    "        \n",
    "        gb_loss_third = rbm_third.free_energy(gb_vog_third) - rbm_second.free_energy(gb_v3)\n",
    "        loss_.append(gb_loss_third.data)\n",
    "        \n",
    "        gb_third_train_op.zero_grad()\n",
    "        gb_loss_third.backward()\n",
    "        gb_third_train_op.step()\n",
    "\n",
    "    print(\"3ST GBrbm_first Training loss for {0} epoch {1}\\tEstimate time : {2}\".format(epoch, np.mean(loss_), mt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.4071e-02, -7.9139e-03, -7.6073e-03,  4.3864e-03,  1.2376e-05,\n",
       "         -4.9374e-03,  2.7339e-02, -7.3691e-03, -6.2183e-03,  1.1650e-02]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nprst = gb_v3.detach().numpy()\n",
    "print(nprst)\n",
    "\n",
    "rbm_first.get_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_9488/200555237.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
      "C:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_9488/200555237.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_data = torch.tensor((Variable(train_data[train_cnt:train_cnt + 10])).uniform_(0, 1), dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : tensor(0.0008, grad_fn=<DivBackward0>)\n",
      "Train - test : tensor(-0.5118, grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "train_loss = 0\n",
    "train_cnt = 0\n",
    "summary_c = 0\n",
    "\n",
    "for _, test_data in enumerate(test_dataloader):\n",
    "    try:\n",
    "        test_data = torch.tensor(Variable(data.view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "        train_data = torch.tensor((Variable(train_data[train_cnt:train_cnt + 10])).uniform_(0, 1), dtype=torch.float32)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    \n",
    "    testing_data = torch.flatten(torch.bernoulli(test_data))\n",
    "    training_data = torch.flatten(torch.bernoulli(train_data))\n",
    "    \n",
    "    vt, vt1, _ = rbm_first(testing_data)\n",
    "    test_loss = rbm_first.free_energy(vt) - rbm_first.free_energy(vt1)    \n",
    "    \n",
    "    vs, vs1, _ = rbm_first(training_data)\n",
    "    train_loss = rbm_first.free_energy(vs) - rbm_first.free_energy(vs1)\n",
    "\n",
    "    \n",
    "    test_loss += torch.mean(torch.abs(vt1[vt1 >= 0] - vt[vt1 >= 0]))\n",
    "    # print(vt1[vt1 >= 0] - vt[vt1 >= 0])\n",
    "    summary_c += 1\n",
    "\n",
    "print('Test loss : ' + str(test_loss / summary_c))\n",
    "print('Train - test : ' + str(train_loss - test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Test code'''\n",
    "rbm_first = RBM(n_vis=VISIBLE_UNITS[0], n_hid=HIDDEN_UNITS[0], k=K_FOLD, batch=BATCH_SIZE)\n",
    "rbm_second = RBM(n_vis=VISIBLE_UNITS[1], n_hid=HIDDEN_UNITS[1], k=K_FOLD, batch=BATCH_SIZE)\n",
    "rbm_third = RBM(n_vis=VISIBLE_UNITS[2], n_hid=HIDDEN_UNITS[2], k=K_FOLD, batch=BATCH_SIZE)\n",
    "\n",
    "output_from_first = list()\n",
    "output_from_second = list()\n",
    "output_from_third = list()\n",
    "\n",
    "test_loss = 0\n",
    "epoch_cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBBRBM_First_layer test loss :  tensor(-0.0074, grad_fn=<DivBackward0>)\n",
      "\tBBRBM_Second_layer test loss :  tensor(-0.0335, grad_fn=<DivBackward0>)\n",
      "\tBBRBM_Third_layer test loss :  tensor(-0.0348, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "'''First BBRBM Guide Line'''\n",
    "\n",
    "for _, data in enumerate(test_dataloader):\n",
    "    try:\n",
    "        test_data = torch.tensor(Variable(data.clone().detach().requires_grad_(True).view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    \n",
    "    data = torch.flatten(torch.bernoulli(test_data))\n",
    "    \n",
    "    v1, vt1, _ = rbm_first(data)\n",
    "    test_loss += rbm_first.free_energy(v1) - rbm_first.free_energy(vt1)\n",
    "    epoch_cnt += 1\n",
    "    output_from_first.append(vt1.tolist())\n",
    "print('\\tBBRBM_First_layer test loss : ', str(test_loss / epoch_cnt))\n",
    "\n",
    "'''Second BBRBM Guide Line'''\n",
    "\n",
    "for _, data in enumerate(torch.tensor(output_from_first)):\n",
    "    try:\n",
    "        test_data = torch.tensor(Variable(data.clone().detach().requires_grad_(True).view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    \n",
    "    data = torch.flatten(torch.bernoulli(test_data))\n",
    "    \n",
    "    v2, vt2, _ = rbm_second(data)\n",
    "    test_loss += rbm_second.free_energy(v2) - rbm_second.free_energy(vt2)\n",
    "    epoch_cnt += 1\n",
    "    output_from_second.append(vt2.tolist())\n",
    "print('\\tBBRBM_Second_layer test loss : ', str(test_loss / epoch_cnt))\n",
    "\n",
    "'''Third BBRBM Guide Line'''\n",
    "\n",
    "for _, data in enumerate(torch.tensor(output_from_second)):\n",
    "    try:\n",
    "        test_data = torch.tensor(Variable(data.clone().detach().requires_grad_(True).view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    \n",
    "    data = torch.flatten(torch.bernoulli(test_data))\n",
    "    \n",
    "    v3, vt3, _ = rbm_third(data)\n",
    "    test_loss += rbm_third.free_energy(v3) - rbm_third.free_energy(vt3)\n",
    "    epoch_cnt += 1\n",
    "    output_from_third.append(vt3.tolist())\n",
    "print('\\tBBRBM_Third_layer test loss : ', str(test_loss / epoch_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm_first = RBM(n_vis=VISIBLE_UNITS[0], n_hid=HIDDEN_UNITS[0], k=K_FOLD, batch=BATCH_SIZE)\n",
    "rbm_second = RBM(n_vis=VISIBLE_UNITS[1], n_hid=HIDDEN_UNITS[1], k=K_FOLD, batch=BATCH_SIZE)\n",
    "rbm_third = RBM(n_vis=VISIBLE_UNITS[2], n_hid=HIDDEN_UNITS[2], k=K_FOLD, batch=BATCH_SIZE)\n",
    "\n",
    "output_from_first = list()\n",
    "output_from_second = list()\n",
    "\n",
    "test_loss = 0\n",
    "epoch_cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGBRBM_First_layer test loss :  tensor(-0.0013, grad_fn=<DivBackward0>)\n",
      "\tGBRBM_Second_layer test loss :  tensor(-0.0003, grad_fn=<DivBackward0>)\n",
      "\tGBRBM_Third_layer test loss :  tensor(-0.0074, grad_fn=<DivBackward0>)\n",
      "tensor(-14.1685, grad_fn=<AddBackward0>)\n",
      "1902\n"
     ]
    }
   ],
   "source": [
    "'''First GBRBM Guide Line'''\n",
    "epoch_cnt = 0\n",
    "for _, data in enumerate(torch.tensor(output_from_third)):\n",
    "    try:\n",
    "        test_data = torch.tensor(Variable(data.clone().detach().requires_grad_(True).view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    \n",
    "    sample_data = torch.flatten(torch.normal(mean=data, std=gaussian_std))\n",
    "\n",
    "    v1, vt1, _ = rbm_first(sample_data)\n",
    "    test_loss += rbm_first.free_energy(v1) - rbm_first.free_energy(vt1)\n",
    "    epoch_cnt += 1\n",
    "    output_from_first.append(vt1.tolist())\n",
    "print('\\tGBRBM_First_layer test loss : ', str(test_loss / epoch_cnt))\n",
    "\n",
    "'''Second BBRBM Guide Line'''\n",
    "\n",
    "for _, data in enumerate(torch.tensor(output_from_first)):\n",
    "    try:\n",
    "        test_data = torch.tensor(Variable(data.clone().detach().requires_grad_(True).view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    \n",
    "    sample_data = torch.flatten(torch.normal(mean=data, std=gaussian_std))\n",
    "    \n",
    "    v2, vt2, _ = rbm_second(sample_data)\n",
    "    test_loss += rbm_second.free_energy(v2) - rbm_second.free_energy(vt2)\n",
    "    epoch_cnt += 1\n",
    "    output_from_second.append(vt2.tolist())\n",
    "print('\\tGBRBM_Second_layer test loss : ', str(test_loss / epoch_cnt))\n",
    "\n",
    "'''Third BBRBM Guide Line'''\n",
    "\n",
    "output_from_third = []\n",
    "for _, data in enumerate(torch.tensor(output_from_second)):\n",
    "    try:\n",
    "        test_data = torch.tensor(Variable(data.clone().detach().requires_grad_(True).view(-1, BATCH_SIZE).uniform_(0, 1)), dtype=torch.float32)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    \n",
    "    sample_data = torch.flatten(torch.bernoulli(test_data))\n",
    "    \n",
    "    v3, vt3, _ = rbm_third(sample_data)\n",
    "    test_loss += rbm_third.free_energy(v3) - rbm_third.free_energy(vt3)\n",
    "    epoch_cnt += 1\n",
    "    output_from_third.append(vt3.tolist())\n",
    "print('\\tGBRBM_Third_layer test loss : ', str(test_loss / epoch_cnt))\n",
    "print(test_loss)\n",
    "print(epoch_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randperm() received an invalid combination of arguments - got (), but expected one of:\n * (int n, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int n, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_9488/1873118038.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mperm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandperm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0msum_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: randperm() received an invalid combination of arguments - got (), but expected one of:\n * (int n, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int n, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVM()\n",
    "optimizer = optim.SGD(svm_model.parameters(), lr=LEARNING_RATE)\n",
    "svm_model.train()\n",
    "\n",
    "X = test_loss\n",
    "N = EPOCH\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    perm = torch.randperm(EPOCH)\n",
    "    sum_loss = 0\n",
    "\n",
    "    for i in range(0, N, BATCH_SIZE):\n",
    "        x = X[perm[i : i + BATCH_SIZE]]\n",
    "        y = X[perm[i : i + BATCH_SIZE]]\n",
    "\n",
    "        x = Variable(x)\n",
    "        y = Variable(x)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = svm_model(x)\n",
    "\n",
    "        loss = torch.mean(torch.clamp(1 - output * y, min=0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sum_loss += loss[0].data.cpu().numpy()\n",
    "    print(\"Epoch : {}\\tLoss : {}\".format(epoch, sum_loss[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c3cabcf2f29820bdd7faae982b59d335e0d215fb5382d93f3312fa3292e9b7f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
