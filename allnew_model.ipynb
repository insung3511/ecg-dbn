{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Pre-processing for make clean\n",
      "2022-05-13 14:04:07.917878 model.py code start\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import torch.distributions.distribution as D\n",
    "import data.medain_filtering_class as mf\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from new_RBM import new_RBM as RBM\n",
    "import matplotlib.pyplot as plt\n",
    "import data.read_samples as rs\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "\n",
    "print(datetime.datetime.now(), \"model.py code start\")\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "EPOCH = 100\n",
    "LEARNING_RATE = 0.2\n",
    "ANNEALING_RATE = 0.999\n",
    "VISIBLE_UNITS = [180, 200, 250]\n",
    "HIDDEN_UNITS = [80, 100, 120]\n",
    "K_FOLD = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODL] Model main code is starting....\n",
      "[INFO] Read train data, cross-vaildation data and test data from median filtering code\n",
      "[INFO] Read records file from  ./data/db1/\n",
      "[RSLT]\t\t\t Export records ...\n",
      "\t\t ['100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '111', '112', '113', '114', '115', '116', '117', '118', '119', '121', '122', '123', '124']\n",
      "[INFO]./rdsamp commending start\n",
      "[IWIP]\t\trdsamp Converting 100\n",
      "[IWIP]\t\trdsamp Converting 101\n",
      "[IWIP]\t\trdsamp Converting 102\n",
      "[IWIP]\t\trdsamp Converting 103\n",
      "[IWIP]\t\trdsamp Converting 104\n",
      "[IWIP]\t\trdsamp Converting 105\n",
      "[IWIP]\t\trdsamp Converting 106\n",
      "[IWIP]\t\trdsamp Converting 107\n",
      "[IWIP]\t\trdsamp Converting 108\n",
      "[IWIP]\t\trdsamp Converting 109\n",
      "[IWIP]\t\trdsamp Converting 111\n",
      "[IWIP]\t\trdsamp Converting 112\n",
      "[IWIP]\t\trdsamp Converting 113\n",
      "[IWIP]\t\trdsamp Converting 114\n",
      "[IWIP]\t\trdsamp Converting 115\n",
      "[IWIP]\t\trdsamp Converting 116\n",
      "[IWIP]\t\trdsamp Converting 117\n",
      "[IWIP]\t\trdsamp Converting 118\n",
      "[IWIP]\t\trdsamp Converting 119\n",
      "[IWIP]\t\trdsamp Converting 121\n",
      "[IWIP]\t\trdsamp Converting 122\n",
      "[IWIP]\t\trdsamp Converting 123\n",
      "[IWIP]\t\trdsamp Converting 124\n",
      "[INFO] Read records file from  ./data/db2/\n",
      "[RSLT]\t\t\t Export records ...\n",
      "\t\t ['200', '201', '202', '203', '205', '207', '208', '209', '210', '212', '213', '214', '215', '217', '219', '220', '221', '222', '223', '228', '230', '231', '232', '233', '234']\n",
      "[INFO]./rdsamp commending start\n",
      "[IWIP]\t\trdsamp Converting 200 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 201 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 202 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 203 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 205 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 207 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 208 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 209 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 210 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 212 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 213 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 214 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 215 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 217 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 219 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 220 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 221 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 222 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 223 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 228 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 230 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 231 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 232 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 233 ./data/db2/\n",
      "[IWIP]\t\trdsamp Converting 234 ./data/db2/\n",
      "[INFO] Read records file from  ./data/db3/svdb/\n",
      "[RSLT]\t\t\t Export records ...\n",
      "\t\t ['800', '801', '802', '803', '804', '805', '806', '807', '808', '809', '810', '811', '812', '820', '821', '822', '823', '824', '825', '826', '827', '828', '829', '840', '841', '842', '843', '844', '845', '846', '847', '848', '849', '850', '851', '852', '853', '854', '855', '856', '857', '858', '859', '860', '861', '862', '863', '864', '865', '866', '867', '868', '869', '870', '871', '872', '873', '874', '875', '876', '877', '878', '879', '880', '881', '882', '883', '884', '885', '886', '887', '888', '889', '890', '891', '892', '893', '894']\n",
      "[INFO]./rdsamp commending start\n",
      "[IWIP]\t\trdsamp Converting 800 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 801 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 802 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 803 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 804 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 805 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 806 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 807 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 808 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 809 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 810 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 811 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 812 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 820 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 821 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 822 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 823 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 824 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 825 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 826 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 827 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 828 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 829 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 840 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 841 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 842 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 843 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 844 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 845 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 846 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 847 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 848 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 849 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 850 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 851 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 852 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 853 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 854 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 855 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 856 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 857 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 858 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 859 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 860 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 861 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 862 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 863 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 864 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 865 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 866 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 867 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 868 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 869 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 870 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 871 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 872 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 873 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 874 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 875 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 876 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 877 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 878 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 879 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 880 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 881 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 882 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 883 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 884 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 885 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 886 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 887 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 888 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 889 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 890 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 891 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 892 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 893 ./data/db3/svdb/\n",
      "[IWIP]\t\trdsamp Converting 894 ./data/db3/svdb/\n",
      "[INFO] DB1 Filtering...\n",
      "[INFO] DB2 Filtering...\n",
      "[INFO] DB3 Filtering...\n",
      "DB1 butter size : 23, DB1 Anno size : 23\n",
      " DB2 butter size : 25, DB2 Anno size : 25\n",
      " DB3 butter size : 78, DB3 Anno size : 78\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[MODL] Model main code is starting....\")\n",
    "\n",
    "print(\"[INFO] Read train data, cross-vaildation data and test data from median filtering code\")\n",
    "db1_sig, db1_label, db2_sig, db2_label, db3_sig, db3_label = rs.return_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(db1_sig + db2_sig,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              num_workers=0, \n",
    "                              collate_fn=lambda x: x,\n",
    "                              shuffle=True)\n",
    "                              \n",
    "test_dataloader = DataLoader(db2_sig + db3_sig,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             num_workers=0, \n",
    "                             collate_fn=lambda x: x,\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm_first = RBM(n_vis=VISIBLE_UNITS[0], n_hid=HIDDEN_UNITS[0], k=K_FOLD, batch=BATCH_SIZE).to(device=device)\n",
    "rbm_second = RBM(n_vis=VISIBLE_UNITS[1], n_hid=HIDDEN_UNITS[1], k=K_FOLD, batch=BATCH_SIZE).to(device=device)\n",
    "rbm_third = RBM(n_vis=VISIBLE_UNITS[2], n_hid=HIDDEN_UNITS[2], k=K_FOLD, batch=BATCH_SIZE).to(device=device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    first_train_op = optim.Adagrad(rbm_first.parameters(), 0.1)\n",
    "    second_train_op = optim.Adagrad(rbm_second.parameters(), 0.1)\n",
    "    third_train_op = optim.Adagrad(rbm_third.parameters(), 0.1)\n",
    "\n",
    "    gb_first_train_op = optim.Adagrad(rbm_first.parameters(), 0.1)\n",
    "    gb_second_train_op = optim.Adagrad(rbm_second.parameters(), 0.1)\n",
    "    gb_third_train_op = optim.Adagrad(rbm_third.parameters(), 0.1)\n",
    "\n",
    "else:\n",
    "    first_train_op = optim.SGD(rbm_first.parameters(), 0.1)\n",
    "    second_train_op = optim.SGD(rbm_second.parameters(), 0.1)\n",
    "    third_train_op = optim.SGD(rbm_third.parameters(), 0.1)\n",
    "\n",
    "    gb_first_train_op = optim.SGD(rbm_first.parameters(), 0.1)\n",
    "    gb_second_train_op = optim.SGD(rbm_second.parameters(), 0.1)\n",
    "    gb_third_train_op = optim.SGD(rbm_third.parameters(), 0.1)\n",
    "\n",
    "output_from_first = list()\n",
    "output_from_second = list()\n",
    "output_from_third = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_14660/1971335250.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:210.)\n",
      "  torch.tensor(data, dtype=torch.float32, device=device)\n",
      "c:\\Users\\HILAB_Labtop_02\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "torch.Size([1300000, 10])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "vector + matrix @ vector expected, got 1, 2, 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_14660/1971335250.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mvog_first\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrbm_first\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mloss_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrbm_first\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfree_energy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvog_first\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mrbm_first\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfree_energy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mloss_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_first\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\HILAB_Labtop_02\\Desktop\\insung\\ecg-dbn\\new_RBM.py\u001b[0m in \u001b[0;36mfree_energy\u001b[1;34m(self, v)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv_bias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mv_bias_term\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1300000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv_bias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mwx_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: vector + matrix @ vector expected, got 1, 2, 2"
     ]
    }
   ],
   "source": [
    "'''Train Part'''\n",
    "\n",
    "loss_ = []\n",
    "for epoch in range(EPOCH):\n",
    "    '''First bbrbm'''\n",
    "    for i, (data) in enumerate(train_dataloader):\n",
    "        if i == 4:\n",
    "            continue\n",
    "        data = Variable(\n",
    "                torch.tensor(data, dtype=torch.float32, device=device)\n",
    "        ).uniform_(0, 1)\n",
    "        \n",
    "        sample_data = torch.bernoulli(data).view(-1, 10)\n",
    "\n",
    "        # tensor binary\n",
    "        vog_first, v1, mt = rbm_first(sample_data)\n",
    "        \n",
    "        loss_first = rbm_first.free_energy(vog_first) - rbm_first.free_energy(v1)\n",
    "        loss_.append(loss_first.data)\n",
    "        \n",
    "        first_train_op.zero_grad()\n",
    "        loss_first.backward()\n",
    "        first_train_op.step()\n",
    "    \n",
    "    output_from_first.append(v1.tolist())\n",
    "    print(\"1ST BBrbm_first Training loss for {0} epoch {1}\\tEstimate time : {2}\".format(epoch, np.mean(loss_), mt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(output_from_first))\n",
    "print(output_from_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_from_first.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_from_first = torch.tensor(output_from_first)\n",
    "print(output_from_first)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    '''Secnd bbrbm'''\n",
    "    for _, (data) in enumerate(output_from_first): \n",
    "        if i == 4:\n",
    "            continue\n",
    "        data = Variable(\n",
    "                torch.tensor(data, dtype=torch.float32)\n",
    "        ).uniform_(0, 1)\n",
    "\n",
    "        sample_data = torch.bernoulli(data).view(-1, 10)\n",
    "\n",
    "        # tensor binary\n",
    "        vog_second, v2, mt = rbm_second(sample_data)\n",
    "        \n",
    "        loss_second = rbm_second.free_energy(vog_second) - rbm_second.free_energy(v2)\n",
    "        loss_.append(loss_second.data)\n",
    "        \n",
    "        second_train_op.zero_grad()\n",
    "        loss_second.backward()\n",
    "        second_train_op.step()\n",
    "\n",
    "    # output_from_second.append(v2)\n",
    "    print(\"2ST BBrbm_first Training loss for {0} epoch {1}\\tEstimate time : \".format(epoch, np.mean(loss_), mt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_from_second = torch.tensor(output_from_second)\n",
    "for epoch in range(EPOCH):\n",
    "    '''Secnd bbrbm'''\n",
    "    for _, (data) in enumerate(output_from_second):\n",
    "        if i == 4:\n",
    "            continue\n",
    "        data = Variable(\n",
    "                torch.tensor(data, dtype=torch.float32)\n",
    "        ).uniform_(0, 1)\n",
    "\n",
    "        sample_data = torch.bernoulli(data)\n",
    "        sample_data = torch.flatten(sample_data.clone())\n",
    "\n",
    "        vog_third, v3, mt = rbm_third(sample_data)\n",
    "        \n",
    "        loss_third = rbm_third.free_energy(vog_third) - rbm_third.free_energy(v3)\n",
    "        loss_.append(loss_second.data)\n",
    "        \n",
    "        third_train_op.zero_grad()\n",
    "        loss_third.backward()\n",
    "        third_train_op.step()\n",
    "\n",
    "    output_from_third.append(v3)\n",
    "    print(\"3ST BBrbm_first Training loss for {0} epoch {1}\\tEstimate time : \".format(epoch, np.mean(loss_), mt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c3cabcf2f29820bdd7faae982b59d335e0d215fb5382d93f3312fa3292e9b7f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
